<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[books]]></title><description><![CDATA[Obsidian digital garden]]></description><link>https://cmj7271.github.io/cs-app-organize/</link><image><url>https://cmj7271.github.io/cs-app-organize/lib/media/favicon.png</url><title>books</title><link>https://cmj7271.github.io/cs-app-organize/</link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Sat, 07 Jun 2025 04:49:32 GMT</lastBuildDate><atom:link href="https://cmj7271.github.io/cs-app-organize/lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Sat, 07 Jun 2025 04:49:08 GMT</pubDate><copyright><![CDATA[cmj7271]]></copyright><ttl>60</ttl><dc:creator>cmj7271</dc:creator><item><title><![CDATA[1.1 정보는 비트와 컨텍스트로 이루어진다]]></title><description><![CDATA[ 
 <br><br>텍스트는 비트로 이루어지며, 그 내용은 해석에 따라 달라진다.<br>
즉, 컨텍스트에 따라 달라진다.<br>예시를 들자면, 숫자에 대한 해석이 있다. 일련의 비트를 "정수"로 해석하는지, "실수"로 해석하는지에 따라 그 값이 달라진다. 텍스트의 경우에는 아스키코드로 해석하거나, 유니코드로 해석하냐에 따라 달라질 수 있다.<br>간단하게, 0000...1000001 는 무엇인가?<br>
가장 간단하게는 65, 또는 "A", 소수라고 생각하고 부동소수점으로도 생각해볼 수 있다.<br>JS의 실행 컨텍스트<br>
<a rel="noopener nofollow" class="external-link" href="https://inpa.tistory.com/entry/JS-%F0%9F%93%9A-%EC%8B%A4%ED%96%89-%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8" target="_blank">https://inpa.tistory.com/entry/JS-%F0%9F%93%9A-%EC%8B%A4%ED%96%89-%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8</a>]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.1-info=bits+context.html</link><guid isPermaLink="false">articles/chapter1/1.1-Info=Bits+Context.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[1.2 프로그램은 다른 프로그램에 의해 다른 형태로 번역된다]]></title><description><![CDATA[ 
 <br><br>C 프로그램의 "hello world" 를 예시로 들자면,<br>전처리 단계(pre-processor)<br>
먼저, .c 파일은 전처리기(pre-processor)을 통한 전처리 과정을 거친다. 이 과정에서는 # 으로 시작하는 문장을 실행한다. 대표적으로 #include &lt;stdio.h&gt; 가 있다. 이 과정을 거치고 나서는 .i 로 끝나는 새로운 파일이 생성된다.<br>컴파일 단계(compiler)<br>
.i 파일을 .s 파일로 변환한다. 즉, 어셈블리어로 변환된다. 여기까지는 사람이 해석할 수 있는 텍스트 파일이다. 이후 과정부터 생성되는 파일은 사람이 해석할 수 없는 바이너리 파일이 생성된다.<br>어셈블리 단계(assembler)<br>
변환된 어셈블리어 텍스트 파일을 재배치 가능한 목적프로그램 으로 변환한다. 여기서부턴 바이너리 파일로 사람이 해석할 수 없다. 재배치 가능한 이 어떤 의미인지 추측해보자면, 전체를 함수화하여 여러 곳에서 호출 가능하게 만드는 과정으로 예상된다. 예를 들어 printf.o 파일을 통해 어디서든 printf 를 사용하는 것과 유사하지 않을까?<br>링크 단계(linker) 필요한 여러 목적파일(.o) 을 합치는 과정이다. hello 프로그램에서는 hello.o 와 printf.o 가 합쳐진다.<br>이렇게 만들어진 실행파일 hello 파일은 메모리에 적재되어 시스템에 의해 실행된다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.2-translate_program.html</link><guid isPermaLink="false">articles/chapter1/1.2-Translate_Program.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[1.3 컴파일 시스템이 어떻게 동작하는지 이해하는 것은 중요하다.]]></title><description><![CDATA[ 
 <br><br>
<br>프로그램 성능 최적화하기
<br>링크 에러 이해하기
<br>보안 약점 피하기
]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.3-importance_of_understanding_compiler.html</link><guid isPermaLink="false">articles/chapter1/1.3-Importance_of_Understanding_Compiler.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[1.4 프로세서는 메모리에 저장된 인스트럭션을 읽고 해석한다.]]></title><description><![CDATA[ 
 <br><br>hello 라는 바이너리 파일은 디스크에 저장되어 있다.<br>
다음의 명령어를 통해 우리는 파일을 실행시킨다.<br>linux&gt; ./hello  
hello world  
linux&gt;
<br>shell 은 커맨드라인 인터프리터로 명령어를 입력받고 그 명령을 실행한다.<br>
내장 shell 명령어가 아니라면, 실행파일의 이름으로 판단하여 그 파일을 로딩하여 실행시켜준다.<br><br><br>컴포넌트 간의 정보를 전달한다. word 라는 고정 크기의 바이트 단위로 전송하게 된다.<br>
한 개의 워드가 가지는 바이트 수는 시스템 마다 가지는 기본 시스템 변수이다.<br>
대부분은 4바이트 또는 8바이트를 가진다.<br><br>입출력 장치는 외부세계와 시스템 간의 연결을 담당한다. 키보드, 마우스, 디스플레이 등등의 예시가 있다.<br>
입출력 장치는 입출력 버스, 컨트롤러 나 어댑터 를 통해 연결된다.<br>
컨트롤러와 어댑터의 차이는 패키징(packaging) 에 있다.<br>
컨트롤러는 그 자체가 칩셋이거나 머더보드(시스템의 인쇄기판)에 장착되어 있지만,<br>
어댑터는 머더보드에 장착되는 일종의 카드이다.<br>
하지만, 이 둘은 입출력 버스와 입출력 장치간의 정보를 주고받도록 도와준다.<br><br>프로세서가 프로그램을 실행하는 동안 데이터와 프로그램을 모두 저장하는 임시 저장장치이다.<br>
물리적으로는 DRAM(Dynamic Ramdom Access Memory) 로 구성되어 있다.<br>
논리적으로는 연속적인 바이트들의 배열로 0부터 시작해서 고유의 주소를 가진다.<br>
프로그램을 구성하는 기계어 인스트럭션은 다양한 바이트를 가진다.<br>
데이터 또한 그 타입에 따라 크기가 다양하다. C 언어의 short, int, long long 등을 예시로 들 수 있다.<br><br>주처리장치(CPU) 라고도 불리는 이 장치는 <a class="internal-link" data-href="#메인 메모리" href="https://cmj7271.github.io/cs-app-organize/about:blank#메인_메모리" target="_self" rel="noopener nofollow">메인 메모리</a> 에 저장된 명령어를 해독(실행)하는 엔진이다.<br>
중심에는 워드 크기의 저장장치(레지스터) 인 프로그램 카운터(PC) 가 존재한다.<br>
PC 는 기계어 명령어를 가리키고 있다.<br>
프로세서는 전원이 공급되는 순간부터 계속 다음과 같은 행위를 반복한다.<br>
<br>PC 가 가르키는 명령어를 수행한다.
<br>PC 값을 다음으로 업데이트한다.
<br>PC가 가르키는 명령어, 즉 인스트럭션은 인스트럭션 집합 구조(Instruction Set Architecture) 로 정의된다.<a data-footref="isa_각주" href="https://cmj7271.github.io/cs-app-organize/about:blank#fn-1-b58849f9f3dc8242" class="footnote-link" target="_self" rel="noopener nofollow">[1]</a><br>
하나의 인스트럭션은 규칙적으로 실행되며, 여러 단계를 거칠 수도 있다.<br>
업데이트되는 다음의 PC 값은 메모리상 연속일수도, 아닐수도 있다.<br>
프로세서가 실행하는 인스트럭션을 쪼갠 단순한 동작은 메인 메모리, 레지스터 파일, 수식/논리 처리기(ALU) 을 순환한다.<br>
레지스터 파일은 고유의 이름을 갖는 각각의 워드 크기의 레지스터 집합으로 이루어진다.<br>
ALU는 새 데이터와 주소 값을 계산한다.<br>다음은 단순한 동작의 예시이다.<br>
<br>적재(Load): 메인 메모리에서 레지스터로 바이트 또는 워드의 값을 복사한다.
<br>저장(Store): 레지스터에서 메인 메모리로 바이트 또는 워드의 값을 복사한다.
<br>작업(Operate): 두 레지스터의 값을 ALU로 복사해서 수식연산을 시행한 뒤, 결과를 레지스터에 저장한다.
<br>점프(Jump): 인스트럭션 자신으로부터 한 개의 워드를 추출하고, 이것을 PC에 복사한다.
<br>최신 프로세서는 실행 속도를 위해 복잡한 방식을 사용한다.<br>
이런 점에서 인스트럭션의 효과 와 실제 구현 으로 인스트럭션 집합 구조 와 프로세서의 마이크로구조 를 구별할 수 있다.<br><br><br><br>각 하드웨어 조직에서 조직으로 이동할 때는 bus 통해 이동하게 된다.<br>
bus 간의 중간 역할로 I/O bridge, Bus Interface 등 연결 조직이 존재한다.<br>
즉, 조직에서 조직으로 이동하는 과정에는 bus 가 존재한다고 생각하면 된다.<br>
<br>
./hello 입력한다<br>
./hello 라는 문자열이 CPU의 레지스터로 이동한다.<br>
그 후 다시 메인 메모리로 이동한다,

<br>
enter 키를 누른다(= 명령 입력이 끝났음을 알린다)<br>
인스트럭션에 따라 hello 실행파일과 "hello world!\n" 을 포함하는 데이터를 디스크에서 메모리로 이동한다.<br>
디스크에서 메모리로 바로 이동하는 것을 직접 메모리 접근(DMA) 라고 한다.

<br>
hello 실행파일을 실행한다<br>
메모리의 main 루틴의 기계어를 처리한다.<br>
이는 메모리에 있는 "hello world!\n" 을 레지스터로 가져오고, 다시 출력장치로 보내는 것을 포함한다.

<br>실행 과정을 살펴보며 알 수 있는 점은 단순한 프로그램에도 하드웨어 간의 이동이 굉장히 많다. 라는 것이다.<br>
<br>
<br>ISA는 마이크로프로세서가 인식할 수 있는 기계어 명령어들의 집합을 의미하며, CPU 같이 ISA 에 규정된 명령어를 실행하는 물리적 장치를 ISA 의 구현체라고 불린다. <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Instruction_set_architecture" rel="noopener nofollow" class="external-link" href="https://en.wikipedia.org/wiki/Instruction_set_architecture" target="_blank">wikipedia 참고</a><a href="https://cmj7271.github.io/cs-app-organize/about:blank#fnref-1-b58849f9f3dc8242" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.4-proccessor_reads_instruction_in_memory.html</link><guid isPermaLink="false">articles/chapter1/1.4-Proccessor_reads_Instruction_in_Memory.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[1.5 캐시가 중요하다]]></title><description><![CDATA[ 
 <br><br><a data-href="PARA/Project/CS_APP_organize/chapter1/1.4-Proccessor_reads_Instruction_in_Memory#1.4.2 `hello` 프로그램의 실행" href="https://cmj7271.github.io/cs-app-organize/para/project/cs_app_organize/chapter1/1.4-proccessor_reads_instruction_in_memory.html#1.4.2_`hello`_프로그램의_실행" class="internal-link" target="_self" rel="noopener nofollow">PARA/Project/CS_APP_organize/chapter1/1.4-Proccessor_reads_Instruction_in_Memory &gt; 1.4.2 `hello` 프로그램의 실행</a> 의 마지막 내용처럼<br>Cation
하드웨어 간의 이동에 많은 시간을 사용한다는 것이다.
<br>이를 위해 더 빠르고 가까운 위치에 자주 사용하는 데이터를 저장한다.<br>
이를 통해 복사 과정을 보다 빠르게 만든다.<br>
이러한 저장장치를 캐시 메모리 라고 한다.<br>큰 것보다는 작은 것이, 먼 곳보다 가까운 곳에 있는 것이 빠르다는 점을 이용한다.<br>
대표적으로 L1 캐시, L2 캐시, 심지어 L3 캐시도 존재한다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.5-cache_is_important.html</link><guid isPermaLink="false">articles/chapter1/1.5-Cache_is_important.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[1.6 저장장치는 계층 구조를 이룬다]]></title><description><![CDATA[ 
 <br><br>위의 캐시의 개념을 확장하여, 메모리 간의 계층구조 를 구성할 수 있다.<br>
레지스터를 L0, 1차 캐시를 L1 등등으로 L3까지 존재하며,<br>
그 다음엔 메인 메모리, 보조저장장치, 네트워크 분산 시스템 등등이 있다.<br>Important
하위 저장장치의 캐시는 상위 저장장치이다.
<br>예를 들어, L2 캐시의 캐시는 L1 캐시가 관리한다.<br>
하위 메모리에 대한 접근을 줄이기 위해 상위 메모리에 저장하는 것이다.<br>이게 응용된 분야라면, Redis 같은 데이터베이스가 있지 않을까<br>redis 가 캐시로서 작동하는 이유:<br>
인메모리 형식으로 작동하는 No-SQL 로 메모리에서 사용되기 때문에,<br>
스토리지나 디스크에 비해 빠른 속도로 동작할 수 있다.<br>
따라서, 다른 데이터베이스에 대한 캐시 역할을 수행할 수 있다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.6-hierarchy_of_memory.html</link><guid isPermaLink="false">articles/chapter1/1.6-Hierarchy_of_Memory.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[1.7 OS는 하드웨어를 관리한다]]></title><description><![CDATA[ 
 <br><br><br>소프트웨어(Application Programs) 가 하드웨어(Processor, Main Memory, I/O Device) 를 이용하기 위해서는 OS 를 반드시 거쳐야 한다.<br>
<br>하드웨어에 대한 접근을 제한하기 때문에, 잘못된 하드웨어 사용을 막을 수 있다.
<br>Application Programs 에서 간단하고 일관된 방법으로 하드웨어를 사용하게 할 수 있다.
<br>위의 목적을 이루기 위해, 아래와 같은 추상화가 이루어진다.<br>
<img alt="PARA/Project/CS_APP_organize/chapter1/imgs/abstractions_provided_by_os.png" src="https://cmj7271.github.io/cs-app-organize/lib/media/abstractions_provided_by_os.png"><br>즉, files 는 I/O devices 의 추상화이고,<br>
Virtual Memory 는 Main Memory, I/O devices 의 추상화,<br>
Processes 는 Processor, Main Memory, I/O devices 의 추상화이다.<br><br>현대의 OS는 프로그램에 대해 다음과 같은 환상 을 준다.<br>
<br>프로세서(CPU), 메인 메모리, I/O device 에 대한 독자적인 이용하는 것처럼 보인다.
<br>프로세서가 단 하나의 프로그램의 순서를 철저히 지키는 것처럼 보인다. 간섭없이
<br>해당 프로그램의 코드와 관련 데이터가 현재 메모리에 있는 유일한 정보인 것처럼 보인다.
<br>
"프로세서" 라는 개념을 통해 위와 같은 착각을 일으킬 수 있었다.<br>
즉, "프로세서" 와 "프로그램" 은 다른 개념이다.
<br><br>프로세스는 서로 배타적으로 하드웨어를 이용하면서, 동시에 여러개의 프로세스가 작동하는 것처럼<br>
"보인다." "동시에" 라는 의미는 사실 한 프로세스의 명령어가 다른 프로세스의 명령어들 사이에 끼어들어서 작동하는 것으로 구현된다.<br>
실제로, 보통 프로세스는 CPU의 개수보다 많이 돌아간다.<br>위의 "동시에" 작동하는 것처럼 보이기 위해 사용하는 각 프로세스간의 명령어 간 움직임은<br>
라고 알려진 메카니즘에 의해 동작한다.<br>멀티프로세서() 는 물리적으로 여러 프로그램을 동시에 돌릴 수 있지만,<br>
남은 논의에서는 일단 배제한다.(1.9.2 절에서 다시 언급된다.)<br>OS는  을 위해,  의 상태 정보를 수집하고, 추적한다.<br>
이 상태정보를  라고 부른다.<br>
이 상태 정보에는 PC(), 레지스터 파일, 메인 메모리의 내용 등이 있다.<br>
여러 프로세스를 동시에 작동시키기 위해,<br>
프로세스에서 필요한 다음 명령어 사이사이에 다른 프로세스의 명령어를 실행한다.<br>
이 때 온전한 실행을 위해, 프로세스의 상태 정보를 수집, 추적하는데, 이를  라고 한다.
<br>해당 내용을 hello 프로그램 실행에 적용해보자.<br>
처음에는 shell 프로세스가 동작중이다. ./hello 를 통해 실행시키면,<br>
./hello 에 대한 프로세스가 생성되며 해당 프로세스가 종료되면 다시 shell 프로세스로 돌아온다.<br>프로세스 간의 전환은  이 담당하게 된다.<br>
 은 OS 코드의 일부로 항상 메모리 위에 존재한다.<br>프로세스가 OS에게 특정한 요청을 할 때는  에게 제어를 넘기는  라는 특수한 함수를 호출한다.<br> 은 분리된 프로세스가 아닌, 시스템이 프로세스를 제어하기 위해 사용하는 코드와 자료 구조의 모음이다.<br>
시스템이 프로세스를 제어하기 위해 사용하는 코드와 자료구조의 모음.<br>
프로세스가 아닌 운영체제의 일부이다.<br>
프로세스는  을 통해 운영체제를 거쳐 하드웨어 자원을 이용하게 된다.
<br> 는 컴퓨터과학 분야 뿐만 아니라 개발에서도 종종 보인다.<br>
JS: 실행 컨텍스트, golang: context 패키지<br>
JS에서는 실행 엔진이 코드를 실행하기 위해 필요하며, golang 은 다른 고루틴에게 정보 전달용이다.<br>
즉, 다른 함수나 엔진 등 외부에 정보를 전달하는 목적으로 사용된다.<br>OS 에서도 마찬가지로, 다른 프로세스로 넘어가기 위해 기존의 프로세스를 보존하기 위한 정보를  로 저장한다.<br>비슷한 느낌의 용어로  가 있다.<br>참고자료: <a data-tooltip-position="top" aria-label="https://inpa.tistory.com/entry/%F0%9F%91%A9%E2%80%8D%F0%9F%92%BB-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%E2%9A%94%EF%B8%8F-%EC%93%B0%EB%A0%88%EB%93%9C-%EC%B0%A8%EC%9D%B4" rel="noopener nofollow" class="external-link" href="https://inpa.tistory.com/entry/%F0%9F%91%A9%E2%80%8D%F0%9F%92%BB-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%E2%9A%94%EF%B8%8F-%EC%93%B0%EB%A0%88%EB%93%9C-%EC%B0%A8%EC%9D%B4" target="_blank">inpa 찬양해</a><br>
잦은  은 오버헤드로 인해 오히려 성능 하락을 일으킬 수 있다.<br>
 를 위해 해당 프로세스에 대한 정보가 담긴  을 프로세스 생성과 동시에 메모리에 저장한다.<br>
프로세스 전환을 위해서는 해당하는 프로세스의  를 읽어야하기 때문에 작업에 비해 너무 많은 프로세스는 오히려 성능 하락을 일으킬 수 있다.<br>비슷하게 스레드에서도  라는게 존재하여 비슷한 역할을 한다.<br>
스레드에서는  등의 동기화 기법을 사용한다.<br>
 에서는 공유된 자원에 대한 동시 접근에 의한 문제점이 발생할 수 있다.<br>
이는 프로세스와는 달리(프로세스도 공유하는 방법이 존재하긴한다.) 스레드는 자원을 공유하기 때문에,<br>
이에 대한 동시 접근이 가능하며, 이로 인해 잘못 업데이트 된 경우,  이라고 부른다.<br><br>프로세스를 여러개의 실행 단위로 나눈 것을  라고 부른다.<br>
하나의 프로세스에서  는 코드와 전역 데이터를 공유한다.<br>
여러 프로세스보다 데이터를 공유하기 편하기 때문에, 효율적이며 점점 중요도가 올라가고 있다.<br>
 를 여러 개로 나눈 실행 단위.<br>
 끼리는 코드와 데이터 등 프로세스의 자원을 공유한다.
<br><br> 가  에 온전한 접근을 하는 것처럼 보이게 만드는 추상화를  라고 한다.<br>
이를 통해 각각의  는 통일된 메모리에 대한 "시각"을 가진다.<br>
이는  라고 한다.<br> 에서는 아래의 그림과 같다. (다른  계열 시스템도 비슷하다.)<br>
<img alt="PARA/Project/CS_APP_organize/chapter1/imgs/process_virtual_address_space.png" src="https://cmj7271.github.io/cs-app-organize/lib/media/process_virtual_address_space.png"><br>
(주소는 "아래에서 위" 방향으로 증가한다.)<br>가장 위는 모든 프로세스에서 공통인 OS의 코드와 데이터가 존재한다.<br>
아래 쪽에는 유저에 의해 정의된 코드와 데이터가 존재한다. <br>이러한 추상화를 통해, 프로세스는 메모리를 특정한 목적으로 분리된 영역으로 이루어진 것처럼 본다.<br>
후에 자세히 다루지만, 여기서 간단하게 다룬다. (밑에서 위 방향으로 살펴본다.)<br>
<br>
<br>
코드는 모든 프로세스가 동일한 고정된 주소에서 시작된다.<br>
그 다음으로 데이터 구역으로 C언어의 전역변수에 대응되는 영역이 존재한다.
모든 프로세스가 동일한 고정된 주소를 가지면, 충돌이 나지 않을까?<br>
이를 방지해주는 것이  의 역할로, 각 프로세스가 보는 주소는 같지만,<br>
실제 메모리상의 주소는 다르다. 프로세스가 보는 주소와 실제 메모리상의 주소를,  가 맵핑해준다고 볼 수도 있다. (7장-linking 에서 더 살펴본다.)

<br>
<br>
 으로  는 고정된 것과는 다르게, 런타임에 동적으로 늘어나고 줄어들 수 있다. C언어에서는 malloc, free 함수를 통해 조절한다. (9장 - virtual memory에서 다룬다.)

<br>
<br>
중간에는  가 존재한다. C언어에서는 예를 들어, 기본 라이브러리와 수학 라이브러리 등이 있다. 이 개념은 강력하지만, 꽤 어려운 개념으로 7장-dynamic linking에서 더 배운다.

<br>
<br>
 과 유사하게 동적으로 늘어나고 줄어든다.<br>
단,  에 이용된다. 각 함수가 호출될 때 늘어나며, 함수가 반환할 때 줄어든다.<br>
3장에서 자세히 다루게 된다.

<br>
<br>
 이 사용하는 영역으로 프로그램은 사용할 수 없다.<br>
이 곳에 있는 내용은  에게 요청하여 간접적으로 접근해야만 한다.

<br> 는 하드웨어와 OS 소프트웨어의 정교한 상호작용이 필요하다.<br>
예를 들어, 물리적 주소와 가상의 주소간의 관계는 디스크에 저장되고,  를  로서 사용하게 된다. 9장에서 어떻게, 이것이 왜 중요한지 설명한다.<br><br>은 "단순한 bytes 의 조합, 그이상 그이하도 아니다."<br>
모든 I/O 장치, 네트워크는 file 로 모델링 된다.<br>
모든 Input, Output 은 단순히 파일을 읽고, 쓰는 것에 대응된다.<br>이 작고 우아한 개념은 매우 강력하다. 다양한 I/O 장치에 대해 통일된 시각을 제공해주기 때문이다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.7-os_manage_hardware.html</link><guid isPermaLink="false">articles/chapter1/1.7-OS_manage_Hardware.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/lib/media/abstractions_provided_by_os.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/lib/media/abstractions_provided_by_os.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.8 시스템은 다른 시스템과 "네트워크"를 이용해 통신한다.]]></title><description><![CDATA[ 
 <br><br>하나의 시스템에 있어서 내트워크는 특별한 장치가 아니다. 여타 I/O 장치와 똑같이 판단할 수 있다.<br>
바이트 조합을 메인 메모리에서 디스크가 아닌 "네트워크 어댑터"에 작성하는 것과 똑같이 볼 수 있다.<br>
반대로, 다른 시스템의 데이터를 메인 메모리로 읽는 것도 비슷하게 볼 수 있다.<br>인터넷같은 전세계적 네트워크가 발달하면서, 서로 다른 시스템간의 정보 복사는 컴퓨터의 중요한 업무가 되었다. 이메일, SNS, WWW, FTP 등등 다양하다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.8-system_communicate_system_with_network.html</link><guid isPermaLink="false">articles/chapter1/1.8-System_communicate_System_with_Network.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[1.9 중요한 주제들]]></title><description><![CDATA[ 
 <br><br>시스템은 단순한 하드웨어 그 이상이다.<br>
하드웨어와 소프트웨어가 서로 얽혀, "프로그램을 실행시킨다"는 궁극적인 목표를 달성한다.<br>아래에서는 몇가지 중요한 컨셉을 소개한다. 중요성은 책의 다른 부분에서 더 소개한다.<br><br>시스템의 특정 부분의 발달이 전체 시스템에 끼치는 영향은<br>
해당 시스템을 차지하는 비율과 성능 향샹 폭이다.<br> : 기존에 특정 애플리케이션을 구동하는데 필요한 시간<br>
 : 필요한 시간에서 해당 부분의 발달이 차지하는 비율<br>
 : 해당 부분의 성능 향상 폭(비율)<br>
즉, 해당 부분은 기존에  만큼의 시간이 필요했으며, 성능 향상으로 이제는  의 시간이 필요하다.<br>따라서 성능 향상 이후 걸리는 시간은<br>
따라서, 성능 향상폭  는<br>
이다. 즉, 성능 향상과 차지하는 비율에 비례한다.<br>
성능 향상폭은  로 표현되며,<br>
실질적인 성능 향상이 존재할 경우,  을 넘는다.<br>
간단하게,  로 적으며, 이는 "2.2배의 향상폭"을 의미한다.
<br>재미있는 특이 케이스로는  가 있다.<br>
이 때,  가 무시되므로,<br>
 가 된다.<br><br>: 여러 행위를 동시에 진행하는 시스템의 일반적인 개념<br>
:  를 사용하여 시스템을 빠르게 하는 것<br>
 은 컴퓨터 시스템의 여러 추상화 단계에서 악용될 수 있다.<br>
(여러 오작동을 일으킬 소지가 있다는 의미같다)<br>아래에서는 3가지 단계로 살펴보며, 시스템 계층 상 높은 것에서 낮은 것순으로 살펴본다.<br><br>
스레드를 통해, 하나의 단일 프로세스에서 여러 개의  를 가질 수 있다.<br>
이러한 기능은 단일 컴퓨터가 빠르게 여러개의 컨택스트를 오가며 실행하는 것으로  되면서 가능해졌다.<br>
이는 여러 유저가 하나의 웹 서버에 접근하고, 여러 작업을 동시에 하는 등 큰 역할을 한다.<br>최근까지는 실제로는 단일 프로세서로 구성되어  라고 칭했다.<br>
여러개의 프로세서를 단일 OS 커널로 다루게 되면서, 현대에는  이 되었다.<br>멀티 코어 시스템이 발달하면서,  같은 용어도 생겼다.<br>멀티 코어 프로세서는 여러개의 CPU(cores 라고 지칭되는) 이 하나의 단일 칩에 포함된다.<br>
각 코어별로 각자만의 별도의 cache 가 존재하기도 하며, 코어간에 공유하는 cache도 존재한다.<br> 는  이라고도 불린다.<br>
이는 단일 CPU가 여러 개의  를 조절하는 기술을 의미한다.<br>멀티프로세싱은 2가지 측면에서 성능 향상을 이뤄냈다.<br>
<br>동시성을  할 필요를 감소시켰다.
<br>단일 프로그램 또한 빠르게 실행 가능하다.<br>
단, 이는 해당 프로그램이 멀티프로세싱이 원할하게 이루어질 수 있도록 표현되어야 한다.
<br><br>
현대 프로세서는 여러개의  을 실행 할 수 있고, 이를  이라고 부른다.<br>
최근의 프로세서는 한 클럭에 2~4개의  을 실행시킬 수 있다.<br>프로세서는  이라는 기술을 통해, 훨씬 많은 명령어를 한 클럭에서 실행시킬 수 있다.<br>
하나의 명령어() 을 서로 다른 단계() 으로 나누어,<br>
잘 정렬한 후, 병렬적으로 실행한다.<br>하나의 사이클() 에 하나 이상의 명령어() 을 수행하는 프로세서를  라고 한다.<br><br>
현대 프로세서는 특별한 하드웨어가 존재한다.<br>
이 하드웨어는 단일 명령어() 가 여러개의 연산() 을 병렬적으로 처리하게 해준다.<br>
예를 들어, 8 쌍의 float 더하기 연산을 병렬적으로 한번에 처리한다.<br>이미지, 소리, 영상 등의 처리에서 최적화에 사용된다.<br>일부 컴파일러는 자동적으로 해당 최적화를 시도하지만,<br>
더 좋은 방법은 특별한  타입으로 작성하는 것이다. (단, 해당 컴파일러가 지원할 때)<br><br>추상화는 컴퓨터 과학 전반에서 중요한 역할을 한다.<br>API(Application Program Interface) 는 좋은 예시 중 하나이다.<br>
API 는 프로그래머가 내부 구현을 모르는 채로, 해당 코드를 사용할 수 있도록 해준다.<br>각 언어는 다양한 형태와 레벨의 추상화를 지원한다.<br>
자바의 경우 class 가 있으며, C언어에서는 함수 프로토타입이 있다.<br><a data-href="PARA/Project/CS_APP_organize/chapter1/1.7-OS_manage_Hardware" href="https://cmj7271.github.io/cs-app-organize/para/project/cs_app_organize/chapter1/1.7-os_manage_hardware.html" class="internal-link" target="_self" rel="noopener nofollow">PARA/Project/CS_APP_organize/chapter1/1.7-OS_manage_Hardware</a><br>
에서 이미 다양하면서 중요한 추상화의 예시를 살펴보았다.<br>
ISA() 는 실제 프로세서(하드웨어)의 동작을 코드(소프트웨어)로 추상화한 좋은 예시이다.<br>ISA 를 이용한 코드는 실제 프로세서와 무관하게 실행가능하며,<br>
구현된 프로세서에 따라 다른 비용과 성능을 낼 수 있다.<br>OS에서 3가지의 추상화를 살펴보았다.<br>
<br>: I/O 장치의 추상화
<br>: 프로그램 메모리의 추상화
<br>: 실행중인 프로그램의 추상화
<br>그리고, 여기에 한가지를 추가해서<br>
 이 있다.<br> 는 하나의 컴퓨터 시스템을 추상화한다.<br>
즉, OS, 프로세서, 프로그램 모두를 아우른다.<br>VM은 여러 OS(window, mac OS, Linux) 에서 똑같이 돌아갈 수 있도록 설계된다.<br>]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.9-other_important_themes.html</link><guid isPermaLink="false">articles/chapter1/1.9-Other_important_Themes.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[1.10-Summary]]></title><description><![CDATA[ 
 <br>컴퓨터 시스템은 "하드웨어와 소프트웨어를 결합"해서 애플리케이션을 구동시킨다.<br>
정보는 비트로 저장되며, 이를 해석하는 방법은 그 맥락() 에 따라 다르다.<br>프로그램은 다른 프로그램에 의해 다른 형태로 번역되어, 아스키코드에서 실행가능한 바이너리 코드로 변한다.<br>프로세서는 메인 메모리에 저장되어 있는 이진 명령어를 읽고 해석한다.<br>
컴퓨터는 데이터 읽고 쓰기에 많은 시간을 할당한다.<br>
하드 디스크, 메모리, I/O 장치, CPU 간에 서로 끊임없이 교환된다.<br>
이를 완화하기 위해  와  라는 개념을 도입한다.<br>
상위 계층의 저장장치의 데이터를 하위 계층이 캐싱을 하여, 더 이상 내려가지 않고, 빠르게 접근한다.<br>
상위 계층은 빠르지만, 비싸기 때문에 용량이 작아진다.<br>
L1 cache 는 빠르지만 몇 KB 등 용량이 작으며, 반대로 SSD 는 몇 TB 로 용량이 매우 크지만, 속도가 cache 에 비해 느리다.(절대적인 속도는 기술의 발전으로 빨라지긴 했다.)<br>OS 커널은 애플리케이션(소프트웨어)와 하드웨어의 중간통로이다.<br>
커널은 아래 3가지 추상화를 제공한다.<br>
<br>:  에 대한 
<br>:  에 대한 
<br>:  에 대한 
<br>는 다른 시스템과 상호작용할 수 있는 방법을 제공한다.<br>
하지만, 시스템 입장에서는 다른 I/O 장치와 차이점이 존재하지 않는다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.10-summary.html</link><guid isPermaLink="false">articles/chapter1/1.10-Summary.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[2.1-Infomation_Storage]]></title><description><![CDATA[ 
 <br>컴퓨터는 8bits 단위, 즉  단위(주소로 표현 가능한 가장 작은 단위인) 로 읽는다.<br>machine-level 의 프로그램은 메모리를 기다란 바이트 배열,  로 본다.<br>
모든 바이트는  로 특정된다.<br>
또한, 이러한 가능한  의 모임을  라고 한다.<br>
위의 가상 주소 공간은 하나의 개념적인 이미지로 표현되며, 실제 구현은 DRAM(), flash memory, disk 등등으로 이루어진다.<br>뒤에서, 컴파일러와 실행중인 시스템이 서로 다른 프로그램 객체(프로그램 데이터, 명령어, 컨트롤 정보) 를 저장할 수 있는 관리 가능한 단위로 다루기 위해 메모리를 나누는지 살펴본다.<br>다양한 메카니즘이 프로그램의 다른 저장공간을 할당하고, 다룬다.<br>
이 관리는 virtual address space 에서 이루어진다.<br>
C언어에서의 포인터 값은 해당 데이터의 첫번째를 가르키는 virtual address 이다.<br>C언어 컴파일러는 type 정보와 함께, 적절한 machine-level 코드를 작성한다.<br>
컴파일러는 type 정보를 인식하지만, machine-level 코드는 그렇지 않다.<br>
단지, 바이트 블럭으로, 바이트의 배열로 볼 뿐이다.<br><br>2진법으로 표현하기에는 너무 길기 때문에, A~F 를 10~16 에 대응하여 16진법으로 표현하곤한다.<br>
2진법에서 16진법은 4개를 묶어서 하나로 표현하면 되며,<br>
반대로 16진법에서 2진법은 해당 값을 4bit 로 표현하면 된다.<br>2진법에서는  꼴은 0이  개, 1이 1개 오는 비트 배열로 표현가능하다.<br>
16진법에서는  일 때,  개의 0이 오고,  값에 따라 마지막 숫자가 달라진다.<br><br>모든 컴퓨터에는  가 존재한다. 이는 포인터 데이터의 사이즈를 나타낸다.<br>
따라서, word size 가  일 때,  의 주소가 가능하다.<br>최근에는 32-bit에서 64-bit 로 넘어가며, 주소 공간이 4GB 에서  바이트로 늘어났다.<br>
대부분의 64-bit 머신은 32-bit 머신을 위한 프로그램을 동작시킬 수 있다.<br>C언어에서 자료형에 따라 사용되는 Byte는 컴퓨터 시스템이 32bit인지, 64bit인지에 따라 다르다.<br>
ISO C99 에서는 시스템에 따라 bit 가 달라지는 것을 방지하기 위해,<br>
int32_t, int64_t 라는 고정된 비트를 사용하는 자료형을 만들었다.<br>신기한 점: unsigned long, unsigned long int, long unsigned, long unsigned int 모두 가능하다.<br>개발자는 환경에 무관한 프로그램을 위해 노력한다.<br>
이를 위한 한가지 방법은 환경에 무관한 데이터 타입의 사이즈일 것이다.<br>
그러나, 하한선이 보장되어있지만, 상한선이 보장되어있지 않아, 32bit에서 64bit로 넘어갈 때<br>
일부 버그가 발생하곤 했다.<br>
그 이유 중 하나로, 32bit 에서의 int 를 포인터를 저장하는 용도로 사용했다는 것이다.<br>
이것은 64bit 시스템에서는 오류가 발생한다.<br><br> : MSB(Most Significant Bit) 부터 LSB(Least Significant Bit) 순으로 저장<br>
 : LSB(Least Significant Bit) 부터 MSB(Most Significant Bit) 순으로 저장<br>
ex) 0x1234567 을 저장할 때, 작은 비트부터 Big Endian 은 01 / 23 / 45 / 67 로 저장한다.<br>
반대로 Little Endian 은 67 / 45 / 23 / 01 로 저장한다.<br>주로 인텔 계열 시스템이 Little Endian 을, IBM, Oracle 계열이 Big Endian 을 사용한다.<br>
"주로" 인 이유는 다 그렇지는 않기 때문이다.<br>
최근의 프로세서는 , 양쪽을 다 지원한다. 하지만, 각 OS에서는 한쪽만 지원하기 때문에<br>
주로 고정된다.<br>이 두 방법에는 일방적인 우위가 존재하지 않기 때문에 선택은 임의적이다.<br>
유래가 걸리버 여행기 ㅋㅋ;;<br>같은 방식을 쓰는 시스템 사이에서는 Byte Ordering 이 문제가 되지 않는다.<br>
그러나, Network 등을 통해 서로 다른 방식을 쓰는 시스템간의 통신에서는 문제가 생길 수 있다.<br>이를 해결하기 위해, 네트워크를 사용하는 프로그램은<br>
송신 측은 "해당 시스템에서 네트워크 표준을 맞추는 변환"을 따라야하며,<br>
수신 측도 "네트워크 표준을 해당 시스템으로 맞추는 변환" 을 갖춰야한다.<br>다음으로는 정수 표현에서 생길 수 있다.<br>
이는 주로 machine-level 프로그램에서 관찰된다.<br>
Little-Endian 으로 생성된 machine-level 코드에서 종종 일어난다.<br>
정수 표현의 일반적인 방법은 왼쪽에서 오른쪽으로 쭉 읽는 것이나, Little-Endian 은 그것과는 다르기 때문이다.<br>마지막으로는 프로그램이 일반적인 타입 시스템을 우회할 때이다.<br>
C언어는 ,  으로 가능하다.<br>
생성된 변수의 타입을 임의로 바꿔 사용하는 방법이지만, 이는 일반적으로 권장되지 않는다.<br>
단, system-level 프로그래밍에서는 유용하고 필요한 경우가 있다.<br>int, float 등의 자료형의 값을 출력하기 위해서,<br>
show_bytes 라는 함수에 매개변수만 casting 해서 출력하는 방법이 있다.<br>
이러한 방법을 서로 다른 시스템에 적용할 때, Endian 에 따라 순서가 다르거나<br>
32bit, 64bit 시스템이냐에 따라 포인터의 값이 달라진다.<br>	typedef unsigned char *byte_pointer;

	void show_bytes(byte_pointer start, size_t len) {
		int i;
		for(i = 0; i &lt; len; i++) printf(" %.2x", start[i]);
		printf("\n");
	}

	void show_int(int x) {
		show_bytes((byte_pointer) &amp;x, sizeof(x));
	}
<br>그리고... 같은 값에 대한 int 와 float 간에 비트패턴에 있어서 13개가 겹치는데,<br>
이 이유에 대해서는 후술한다.(우연이 아님)<br><br>대부분은 ASCII 인코딩 방식을 사용한다.<br>
숫자 표현의 경우, 정수 x에 대해, 0x3x 로 인코딩된다.<br>
예를 들어, 숫자 5는 ASCII 로 0x35 로 표현된다.<br>이는 byte ordering 이나 word 사이즈 관습과 무관하다.<br>
그래서 이진 데이터보다 시스템 독립적이다.<br>여담으로 ASCII 는 영어 위주다보니, 더 넓은 범위로서 Unicode 가 등장했다.<br>
32bit를 사용하는 방법으로 UTF(Universal Character Set) 이 존재한다.<br>
이는 ASCII 의 superset으로 ASCII 를 포함한다. 이에 따라 가변적으로 1~2byte 로도 해석한다.<br>machine-level 프로그래밍에서는 주로 machine-dependent 하다.<br>
이진 코드를 해석하는 방법이 machine 마다 다른 경우가 많기 때문이다.<br><br>컴퓨터가 이진 데이터(0 과 1) 을 다루기 때문에,<br>
0과 1을 다루는 Boolean Algebra 에 대한 지식은 중요하다.<br>
대표적인 연산들로 ~, &amp;, |, ^ 이 있다.<br>
또한 XOR 라는 연산은 어느 한쪽만 True 일때, 결과값이 참이다.(= 두 값이 서로 다를 때)<br>
해당 연산은 0과 1로 이루어진 비트문자열에도 비슷하게 확장가능하다.<br>
Boolean 연산은 전반적으로 일반적인 정수 연산과 비슷한 특징을 가진다.<br>
ring 이라는 대수적 구조는 group이라는 구조의 확장이다.<br>
ring은 더하기에 대해서 group이 성립하는데, 여기에 곱하기라는 연산이 추가되며,<br>
곱하기에 대해 결합법칙과 항등원이 존재한다.<br>
실제로 Boolean Rings 에서 더하기는 XOR 에 대응하고, 곱하기는 &amp; 에 대응한다.<br>
또한, Boolean Rings 는  를 만족하는 특수한 ring 이다.
<br>비트 문자열은 집합의 다른 표현으로 생각해볼 수 있다.<br>
예를 들어 A = {0, 3, 5, 6} 을  로 생각하고, B = {0, 2, 4, 6} 을  로 생각할 수 있다. 이에 대해 &amp;, | 연산자가 모두 집합의 교집합, 합집합에 대응한다.<br>
관련된 알고리즘으로 "비트마스킹"이 있다.<br><br>C언어에서의 bit operation은 위에서 언급한 기호를 그대로 사용한다.<br>
흥미로운 에제로 두 변수의 값 교환이 있다.<br>void inplace_swap(int *x, int *y) {
	*y = *x ^ *y;
	*x = *x ^ *y;
	*y = *x ^ *y;
}
<br>이것이 가능한 이유는  이기 때문이다. 각  라고 설정하고 따라가면 확인 가능하다.<br>이것을 응용해서 다음 함수의 문제점을 찾아보자<br>void reverse_array(int a[], int cnt) {
	int first, last;
	for(first = 0, last = cnt - 1; first &lt;= last; first++, last--) {
	inplace_swap(&amp;a[first], &amp;a[last]);
	}
}
<br>길이가 홀수일 때, 배열의 가운데 값이 0인 문제가 생긴다.<br>
그 이유는  일때,  에서 inplace_swap(&amp;a[k], &amp;a[k]) 라는 연산을 하며,<br>
 이기 때문에 정보가 없어진다.<br>
따라서, 해결책은 가운데에서 즉, index 가 같을 때는 바꾸지 않는 것이다.<br>
first &lt;= last =&gt; first &lt; last<br>bit-level 에서는 마스킹 연산이 자주 사용된다.<br>
마스킹 연산은 특정 구간의 값만을 취하는 연산이다.<br>
예를 들어,  에서 0, 1, 2, 3 위치의 값이 무엇인가? 라고 하면 그 결과는  이다.<br>
이는 원하는 구간만큼 1로 채우고 나머지는 0으로 채운 비트문자열과 &amp; 연산을 취함으로서 구할 수 있다.<br><br>Boolean Operation 과는 유사하지만, 다르게 작용한다.<br>
예를 들어, ! 의 결과값은 0 아니면 1만 가능하다.<br>
그 외로 &amp;&amp; 나 || 연산자가 있는데, 이들은 첫번째 operand 로 전체 결과가 결정되면, 2번째 operand 는 고려하지 않는다.<br>
ex) a &amp;&amp; 5/a 는 divided by zero 가 뜨지 않는다. 또한, p &amp;&amp; *p++ 도 null pointer 참조가 일어나지 않는다.<br><br>&lt;&lt; 은 비트를 왼쪽으로 밀면서, 새로운 공간을 0으로 채운다.<br>
ex)  이 된다.<br>그러나, &gt;&gt; 의 경우는 조금 다르게 작동한다. 크게, ,  2가지가 있다.<br>
: 새로운 공간을  으로 채운다.<br>
: 새로운 공간을 MSB 와 동일한 값으로 채운다. 이는 signed int 에서 유용하다.<br>C언어 표준은 Logical, Arithmetic 을 특정하지 않는다.<br>
단, 대부분의 컴파일러가 signed data 에 대해 Arithmetic 을 사용하고, 개발자도 그렇게 받아들인다.<br>
하지만, unsigned data 에 대해서는 Logical 을 사용해야만 한다.<br>
Java 에서는 &gt;&gt; 을 Arithmetic 으로, &gt;&gt;&gt; 을 Logical 로 이용한다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter2/2.1-infomation_storage.html</link><guid isPermaLink="false">articles/chapter2/2.1-Infomation_Storage.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[2.2-Integer_Representations]]></title><description><![CDATA[ 
 <br>bit로 Integer 를 표현하는 2가지 방법을 알아본다.<br>
양의 정수를 표현하는 방법과 음의 정수를 포함한 모든 정수를 표현하는 2가지 방법이다.<br>
사실 이 2가지 방법은 수학적 특성이나 machine-level 구현에서 연관성이 있다.<br>
또한, 기존의 표현에서 다른 길이의 표현으로 옮기는 방법에 대해 살펴본다.<br><br>C언어는 다양한 정수형 데이터 타입이 존재한다.<br>
이들은 32bit, 64bit 에 따라 "전형적인" 정해진 Byte 를 점유한다.<br>
기본적으로 음수 표현을 지원하며, unsigned 키워드를 통해 양수만 표현함으로서 범위를 늘릴 수 있다.<br>한 가지 중요한 점은 음수가 가능한 절댓값이 정수보다 1 크다는 점이다.<br>
ex) short :  ~ <br>machine 에 따라 다르기 때문에,<br>
C언어 표준에서 보장하는 범위가 존재한다.<br>
더 작은 범위이며, 양수와 음수의 절댓값 크기가 같다.<br><br> bit의 정수 표현을 이야기하면서, bit vector를  로 표현하거나,<br>
각각의 bit를 표현하기 위해  라고 표현한다.<br>
각각의  는  또는  의 값을 갖는다.<br>우리는 해당 bit vector를 양의 정수를 표현하는 함수로<br>
 를 정의한다. 해당 함수는  길이의 bit vector 를 양의 정수로 바꿔준다.<br>
(Binary 2 Unsigned)<br>
해당 함수는 다음과 같이 정의될 수 있다.<br><br> ex)  <br> bit에 대해 해당 함수의 최댓값, 즉  bit 로 표현 가능한 최대 정수는<br>
  이다.<br>
따라서,  bit에 대한 표현 가능 범위는  이다.<br>
이 함수의 중요한 특징은 특정 정수값  는 그에 해당하는  bit 표현법이 하나로 유일하다는 것이다.<br>
즉, 일대일 맵핑이 가능하다.<br>
 is .(=  + )<br>
 :  (일대일 함수)<br>
 : for ,  is the  (공역과 치역이 같다)
<br>일대응 대응이기 때문에, 특정 정수는 bit vector 로 변환 가능하며, 반대로 bit vector 를 특정 정수로 표현 가능하다.<br>
이를 역함수  라고 표현한다.<br><br>음수 표현은 보통 2의 보수 방식으로 표현된다.<br>
우리는 이 방식을  라고 칭할 것이다. (Binary 2 Two's complement, length )<br><br>여기서 MSB(Most Significant Bit) 는  라고도 불린다. (부호를 결정하기 때문이다.)<br>
양수 표현에 비해 이 마지막 bit,  번째 bit는  의 가중치를 가진다.<br>이로 인해,  가  이라면, 양수,  이라면 음수이다.<br>해당 가중치로 인해, 최솟값은  이며, 그 값은  이다.<br>
반대로 최댓값은  이며, 그 값은  이다.<br>해당 함수 또한, bit vector 와 일대일 대응이 되는  이다.<br>
 is .(=  + )
<br>역시 역함수를  라고 표현한다.<br>2의 보수 즉, 정수 표현에서는 최솟값이 최댓값보다 절댓값이 크다.<br>
구체적으로,  이다. <br>이 점은 간혹 문제를 일으키는데, 비트패턴의 절반은 음수가, 절반은 비음수가 차지한다.<br>
근데,  이 포함되기 때문에, 양수 측이 표현할 수 있는 방법이 하나 적다.<br>Unsigned value 와 Signed Value 간에 다음과 같은 관계가 성립한다.<br><br>특이한 점으로  의 비트패턴은 Unsigned Value 에서는 최댓값, 즉 UMax 이다.<br>
 은 Signed, Unsigned 양쪽다 동일한 비트패턴을 가진다.<br>부호 비트를 사용하는 방법, 1의 보수 방법 등이 있으나,<br>
2의 보수가 편리하기 때문에 2의 보수를 주로 사용한다.<br>N's Complements
 - 길이의 숫자  에 대해,  의 보수는  이다.
<br>여담으로... 수학적 구조 중에 군의 구조를 이룬다고 볼 수 있다.<br>
특히,  에서의 modulo inverse 랑 비슷하게 더하기에 대한 역원으로 볼 수 있다.<br><br>C언어에서는 같은 사이즈의 데이터 간의 casting 은 비트 표현을 바꾸지 않는다.<br>
단, 해석이 바뀌기 때문에 그 값은 다르게 출력된다.<br>
ex) short v = -12345, (unsigned) v 의 값은 53191 이다. (둘의 비트패턴은 동일하다.)<br>비트표현이 바뀌지 않지만, 값은 바뀐다는 점을 이용해,<br>
 라는 함수를 정의한다.(unsigned value 를 signed value 로 해석하기)<br><br>라고 정의할 수 있다. (정의그대로, 2의 보수로 표현된 값을 비트패턴으로, 그것을 다시 Unsigned value 로 해석한다) 단, 범위에 주의해야한다. <br>바로 계산할 수 있는 형태로는<br><br>성립하는 이유는 MSB 가  로 해석되는 것을  로 바꾸는 것이므로  를 더하면 된다.<br>또는, 비트표현에서  자리의 값으로 부호 판별이 되므로,<br><br>라고 할 수 있다.<br> 도 비슷한 논의로 비슷하게 정의가능하다.<br><br><br><br>C언어 표준은 부호 있는 정수 표현에 대해 규정하지 않지만, 대부분의 machine 은 2의 보수법을 사용한다.<br>
보통 정수는 부호 있는 정수 표현으로 저장된다.<br>C언어는 부호 있는 표현, 없는 표현간의 casting 이 가능하다.<br>
표준은 역시 그 방법에 대해서는 규정하지 않는다.<br>
하지만, 대부분의 machine 은 비트패턴을 변하지 않는 상태로의 변환을 지원한다.<br>
앞에서 계속 C언어의 표준과 그 구현을 같이 보고 있다.<br>
표준은 보통 기능 자체를 제시하며, 그 구현은 구현체에 맡기는 경향이 있다.
이에 대한 GPT의 답변은<br>
표준은 기능 제시 위주이며, 구현은 구현체, 컴파일러에게 맡기는 편이라고 한다.<br>
이를  라고 한다고 한다.<br>
그 이유로는 시스템 프로그래밍에 사용되는 만큼, 각 machine 에 맞게 최적화된 구현을 맡기려는 의도가 있다.
<br>각 타입으로의 변환은 문법에 의해 몀명시적(explicit) 일수도, 암시적(implicit) 일 수 있다.<br>이 암시적 변환은 종종 이해할 수 없는 결과를 내거나, 버그를 일으키는 원인이 되기도 한다.<br>
C언어는 음수가 아니라고 가정하고, 부호 있는 정수를 부호 없는 정수로 암시적으로 형변환한다.<br>
이 때,<br><br>의 결과는 False 가 된다.<br>
그 이유는 뒤의  는 부호없는 정수이다. 이에 따라  을 부호없는 정수로 암시적 형변환이 된다.<br>
따라서,<br><br>이므로 False 이다.<br><br>큰 범위의 데이터를 작은 범위의 데이터 축소는 불가능할 수 있지만,<br>
작은 범위의 데이터를 큰 범위의 데이터로 확장하는 것은 가능하다.<br>
각 자료형의 한계값은 limits.h 에 저장되어 있다.<br>
그 안에는<br>
#define INT_MAX 2147483647<br>
#define INT_MIN = (-INT_MAX - 1)<br>
로 표현되어 있다.<br>
이런 표기에는 2의 보수의 비대칭성, 즉 양수 음수의 표현범위가 다르다는 점이 포함되어있다.
<br>Unsigned Number 에 대한 확장은  을 추가해주면 된다.<br>
이 방법을  이라고 한다. 구체적으로,<br>
,<br>
 는  의 길이,  은  의 길이라고 할 때,<br><br>이다.<br>Signed Number 에 대한 확장은 MSB의 값으로 채워주면 된다.<br>
이를  이라고 한다.<br>
,<br>
 는  의 길이,  은  의 길이라고 할 때,<br><br>이다.<br>조금 더 살펴보면, 양수일때는 MSB 가 0이기 때문에  과 동일하다.<br>
반대로 음수일 때는 MSB 가 1이기 떄문에 1을 나열하는 것과 같다.<br>
이 때, 1을 나열하는 것이 정말 같은 값을 표현하는지 생각해보면,<br>
위의 표기를 이용하면,<br><br>이다. MSB 가 1임을 가정했다.<br>
이때,  가 동일해지는 조건을 찾는다. (비트패턴과 그 값은 일대일 대응이다.)<br><br><br>이므로,  는 자명하게  이다.<br><br>
 , we will prove<br><br><br>변환에도 상대적인 순서가 존재한다.<br>
먼저 size 에 대한 변환 후, 부호에 대한 변환을 거친다.<br>
ex) short -&gt; unsigned int<br>
음수인 short 를 변환하면, 먼저 size 를 맞추기 위해 로 채워진다. 그 후, 부호변환이 일어나서<br>
상대적으로 큰 수로 변한다.<br><br>int 를 short 로, 다시 int 로 형변환을 하면, 저장하는 bit가 한번 줄어들었기 때문에<br>
같은 int 지만 값이 달라진다.<br>더 작은 bit의 데이터로 줄어들 때, 그 차이만큼의 bit가 잘린다(truncate).<br>
그 점 때문에 부호없는 정수에 대해,(Unsigned)<br>
 에 대해 bit가 잘려서 길이가  가 된  은 다음의 관계가 성립한다.<br><br>이유는  이하의 bit가 동일하고,  초과의 bit는 가중치가  를 인수로 가지기 때문에,<br>
 값이 0이다.<br>부호 있는 정수와 부호 없는 정수간 변환에 비트의 패턴이 바뀌지 않기 때문에,<br>
부호 있는 정수에서도 비슷한 관계가 성립한다.<br>
단, 부호 있는 정수에서는  이다.<br>
부호 없는 정수로 값을 계산하고, 비트패턴이 안 변한다는 사실을 이용한 것이다.<br><br>암시적 형변환은 티가 잘 나지 않기 때문에 여러 버그의 원인이 되곤한다.<br>	float sum_elements(float a[], unsigned length) {
		int i;
		float result = 0;
		for(i = 0; i &lt;= length - 1; i++)
			result += a[i];
		return result;
	}
<br>이 코드는 length = 0 일 때, 에러가 발생한다.<br>그 이유는, unsigned 인 length 에 0 이 저장되어 있는데, lenth - 1 은 -1 이 아닌, int_max 가 되기 때문에 의도하지 않은 메모리 접근이 발생한다.<br>
따라서, i &lt;= length - 1 를 i &lt; length 로 바꾸면 해결 가능하다.<br>	// library function
	size_t strlen(const char *s);

	int strlonger(char *s, char *t) {
		return strlen(s) - strlen(t) &gt; 0;
	}
<br>32bit 에서 size_t 는 unsigned 로 정의되어 있다.<br>이 코드는 t 가 더 긴 문자열일 때, 즉, strlen(s) - strlen(t) &lt; 0 일 때 문제가 생긴다.<br>
이 때 해당 식의 값은 음수이나, unsigned 로 계산되기 때문에, True 라고 뜬다.<br>
return strlen(s) &gt; strlen(t) 로 해결 가능하다.<br>이러한 미묘한 버그로 인해, 최근 언어에서는 지원 자체를 안하는 경우가 많다.<br>
java 는 모두 부호 있는 정수이며, &gt;&gt; 와 &gt;&gt;&gt; 로 분리하기도 한다.<br>부호 없는 정수는 우리가 수적 해석 없이 비트패턴으로서 해석할 때 도움이 된다.<br>
이것은 우리가  로 해석하는 예시가 있다. 주소 또한 기본적으로 부호가 없다.<br>
또한, 수학 관련 패키지, modulo, 다중정밀도 산술(큰 수에 대한 연산) 같이 숫자가 words 배열로 이루어진 곳에서 도움이 된다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter2/2.2-integer_representations.html</link><guid isPermaLink="false">articles/chapter2/2.2-Integer_Representations.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[2.3-Integer_Arithmetic]]></title><description><![CDATA[ 
 <br>2개의 양수를 더했는데 결과값이 음수이거나,<br>
x &lt; y 와 x - y &lt; 0 의 결과가 다른 등 종종 컴퓨터는 연산 결과가 상식적이지 않다.<br>
이는 컴퓨터가 표현할 수 있는 수의 범위가 한정적인데서 오는 특징이다.<br>
이러한 특징을 아는 것은 신뢰할 수 있는 코드를 짜는 기반이 된다.<br><br> 인 두  는  bit 로 표현 가능하다.<br>
하지만,  이므로 그 합은  bit 로는 부족하며,  bit 가 필요하다.<br>
 은 산수 연산의 결과값을 온전히 나타낼 수 없다는 의미이다.<br>Lisp 같은 일부 언어는 임의 size 의 산수 연산을 지원하지만,<br>
보통의 언어는 고정된 size 에 대해 지원한다.<br>새로운 더하기 연산자로  를 정의한다.<br>
이 연산자는  bit 에서 + 를 수행하며, 그 결과를 Unsigned 로 표현해준다.<br>
이는 사실 더하기 연산 이후,  를 취하는 것과 같은 결과이다.<br>
 일 때,  로 같은 결과이다.<br>
unsigned 와 int 간의 암시적 형변환을 이유로 허락되지 않은 kernel 데이터에 접근할 수도 있었다.
<br><br><br>산수연산이 해당하는 범위 내로 결과가 나오지 않을 때,  라고 한다.<br> 는  보다 작기 때문에,  ,  는 모두 0보다 작다.<br>
따라서,  가 발생하면 다음이 성립한다.<br><br> 은 을 이룬다. <br>
Group 에서 교환조건(Commutative) 가 추가된 Group 이다.<br>
Group은 어떤 집합이 특정 연산에 대해,

<br>연산 결과가 해당 집합에 있음이 보장(Operation is Closed)
<br>결합법칙이 성립 (Associativity)
<br>항등원이 존재 (Identity element exist)
<br>역원이 존재 (Inverse element exist)

가 성립하는 경우, 해당 연산에 대해 Group 이라고 칭한다.
<br> 이기 때문에 연산의 결과가 예상 범위 내임이 보장되고, 연산에 자유롭게 변형을 가할 수 있다.<br>Group이기 때문에 역원이 존재함이 보장되고 이를  로 정의한다.<br>
이 때,<br><br>로 계산할 수 있다.<br><br>2의 보수에서는  이므로,  가 성립한다.<br>
즉,  bit가 필요할 수 있다.<br>
2의 보수에서는 양극단, 즉 너무 작거나, 클 때의 연산을 잘 정의해야한다.<br><br>해당 연산에서  를 더하고 빼는것은 modulo 연산을 생각하면 유추해낼 수 있다.<br>
너무 큰수에 대해서는 modulo 값이 동일한 채로 줄여야하므로  를 더하고 빼면 된다.<br>2의 보수 표현과 부호없는 정수의 표현 방법이 동일하기 때문에,<br>
피연산자를 부호없는 정수 표현으로 바꿔서 더하기 연산을 실행하고, 다시 2의 보수 표현으로 바꿔도 동일한 값을 얻을 수 있다. 수식으로 정리하면 다음과 같다.<br><br> 라는 점과  가 단순히  라는 점을 감안하면,<br><br>2의 보수법에서는 OverFlow 는<br>
<br> 일때, Positive OverFlow
<br> 일때, Negative OverFlow
<br>	int tadd_ok(int x, int y) {
		int sum = x + y;
		return (sum - x == y) &amp;&amp; (sum - y == x);
	}
<br>위의 예제는 항상 1 을 반환한다.<br>
2의 보수 덧셈은 아벨군이기 때문에, 더하기 연산에 대해 닫혀있다.<br>
따라서, 덧셈의 결과로는 OverFlow 를 감지할 수 없다. 위의 x, y, sum 의 상태를 판단해야한다.<br>	int tsub_ok(int x, int y) {
		return tadd_ok(x, -y);	
	}
<br>이 함수는  일 때, 발생한다.  의 값은 가능한 양수 범위를 벗어난다.<br>
()<br>
따라서  에는 그래도  가 저장된다.<br><br> 에 대하여,<br><br> 에 대하여,  이므로,  가 발생하므로,<br>
 이다. 그 외  에 대하여,  이다.<br>

<br>
<br>find rightmost 1.<br>
 일 때,  을 찾을 수 있다.<br>
이 때,  이다.

<br><br>원래는  인 두  에 대해, 곱하기는 0에서  까지 가능하다.<br>
즉, 이론상  bit 가 필요하다.<br>
C언어에서는 하위  bit 를 알려주는 곱하기 연산이 있다. 이를  로 정의한다.<br>
이는 사실 곱한 값에  를 취한것과 같다.<br><br><br>원래는  인 두  에 대해, 곱하기는  에서  까지 가능하다.<br>
즉, 이론상  bit 가 필요하다.<br>
C언어에서는 하위  bit 를 알려주는 곱하기 연산이 있다. 이를  로 정의한다.<br>
이는 사실 곱한 값에  를 취하고, Unsigned 에서 2의 보수로 변환한 값과 같다.<br><br>사실, Unsigned 에서의 곱하기와 2의 보수에서의 곱하기는 동일하게 작동한다.<br>
양쪽 모두,  방식을 이용한다.<br>
간단하게, 곱셈 연산의 오른쪽 숫자의 비트패턴을 살펴보며, 0이면 패스, 1이면 왼쪽 숫자를 그래도 더하고, 오른쪽 숫자가 왼쪽으로 1 shift 한다.<br>그리고, Unsigned 와 2의 보수법 모두 같은 패턴을 다르게 해석하는 해석의 차이이기 때문에,<br>
같은 비트를 같은 연산으로 처리하므로, 해석법만 맞추면 동일한 값이 나온다.<br>
즉, Unsigned * Unsigned 의 결과값을 bit 로 표현한 것은 signed * signed 을 bit 로 표현한 것과 같다.<br><br>곱하기에 대한 컴파일러 최적화를 위해 상수에 대한 곱을 처리한 다음, 남은 부분을 더하는 것이다.<br>
이를 위해 먼저  꼴의 상수를 먼저 살펴보고, 임의의 상수로 넘어간다.<br>부호 없는 정수 표현에서  에 대해,<br>
,  bit 부호없는 정수 표현으로  는 다음과 같다.<br><br> 이 오른쪽에서  개 추가되었다.<br>
성립하는 이유는  이 추가되면서, 가중치가 정확히  배가 되며, 0으로 채웠기 때문에 연산에서 무시되기 때문이다.<br>이 때,  bit 로 고정된 경우, 일부 정보의 손실이 발생할 수 있지만,<br>
shift 연산도 동일하므로 두 과정을 동일하게 볼 수 있다.<br>
즉,<br><br>이다.<br>2의 보수법에서도 bit-level 연산은 동일하므로,<br><br>이다.<br>
두 경우 모두, OverFlow 가 발생할 수 있다는 점을 조심해야한다.<br>컴파일러는 최적화를 위해, 곱셈을 shifting and adding 으로 처리한다.<br>
예를 들어,   이다.<br>
또는 반대로,  로 표현할 수 있다.<br> 에 대해,  이라고 하고<br>
 중 하나가  의 구간을 가질 때, 다음의 2가지 방법으로 계산할 수 있다.<br>
<br>
<br><br>
위의 2가지 방법과  를 그대로 수행하는 것, 총 3가지 방법 중 가장 빠른 방법은<br>
instruction 의 상대적인 속도 즉, machine-dependant 이기 때문에 machine 마다 다르다.<br>
보통은 적은 수의 연산으로 가능할 때 위의 최적화가 발생한다.
<br>	(x &lt;&lt; (n + 1)) - (x &lt;&lt; m)
	해당 연산 방법에 대해, n 이 MSB 이면 어떻게 되는가?
<br> 의 결과는  이다. 모든 비트 정보가 사라지기 때문이다.<br>
따라서,  이다.<br><br>나누기는 곱셉보다도 훨씬 느리다. 이번에는 오른쪽 shift 를 통해 해결할 수 있다.<br>
logical, arithmetic 은 부호 없는 표현, 부호 있는 표현 각각에 대해 처리해준다.<br>정수 나눗셈은 항상  한다.<br>
이를 명확히 하기 위해 표기를 정리한다.<br>
<br>
<br>
 에 대해,<br>
양수 결과에 대해서는 round down(),<br>
음수 결과에 대해서는 round up() 이다.<br>부호 없는 표현에 대해  shifting 을 이용하는 것은 자연스럽다.<br>
<br><br><br>&lt;&lt; 은 비트를 왼쪽으로 밀면서, 새로운 공간을 0으로 채운다.<br>
ex)  이 된다.<br>그러나, &gt;&gt; 의 경우는 조금 다르게 작동한다. 크게, ,  2가지가 있다.<br>
: 새로운 공간을  으로 채운다.<br>
: 새로운 공간을 MSB 와 동일한 값으로 채운다. 이는 signed int 에서 유용하다.<br>C언어 표준은 Logical, Arithmetic 을 특정하지 않는다.<br>
단, 대부분의 컴파일러가 signed data 에 대해 Arithmetic 을 사용하고, 개발자도 그렇게 받아들인다.<br>
하지만, unsigned data 에 대해서는 Logical 을 사용해야만 한다.<br>
Java 에서는 &gt;&gt; 을 Arithmetic 으로, &gt;&gt;&gt; 을 Logical 로 이용한다.<br>C언어에서는 다음이 성립한다.<br><br> 이다.<br>
이 때,<br>
<br>
<br>
 이다.<br>
따라서,  이다.<br>또한,  shift 의 결과는<br>
  이다.<br>2의 보수법 즉, 부호가 있는 정수에 대한 나눗셈은 조금 더 복잡하다.<br>
우선, 음수에 대해 부호 때문에 MSB 가 보존되는  right shift 가 일어나야한다.<br>2의 보수법으로 표현된 값  와, 부호 없는 정수  에 대해, <br><br>양수에 대해서는 MSB 가 0이므로,  가 동일하게 작동한다.<br>2의 보수에서<br>
 이다.<br>
이 때,<br>
<br>
<br>
 이다.<br>
따라서,  이다.<br>
하지만,  과 다르게,  연산을 사용하므로,<br>
shift 의 결과는   이다.<br>2의 보수법의 음수에 대해서는  이 필요하다.<br>
이는 C언어에서 다음으로 표현된다.<br><br> 은  번째 bit는 0,  이하의 bit에 대해서는  모두 1인 bit 패턴이다.<br>
이를 더하는 것은  이하에서 이 있을 때, 올림을 해준다는 의미이다. 이는 floor 와 의미가 일치한다.<br>또는 다음의 수식으로 이해할 수 있다.<br><br>이는 다음으로 증명가능하다.<br><br> 를 대입하면, 정확히 우리가 원하는 연산을 해준다.<br>이러한 분석을 통해, 2의 보수 표현에 대해  을 사용하는 machine 의 경우,<br>(x &lt; 0 ? x + (1 &lt;&lt; k) - 1: x) &gt;&gt; k = x/2^k
<br>이다.<br>	 function returns x/16 for integer x.
	"No" Division, modulus, multiplication, any conditional, any comparison, any loop.
	x is type int with 32bits, use two's complements. And right shift are performed "arithmetics."
<br>	int div16(int x) {
		int bias = (x &gt;&gt; 31) &amp; 0xF;
		return (x + bias) &gt;&gt; 4;
	}
<br>중요한 포인트는 양수에 대해서는 bias = 0 이며, 음수에 대해서는 16bit의 111...1 이다.<br>
이는 양수, 음수가 MSB 에 의해 판단되며, arithmetic right shift 가 MSB 를 복사한다는 점을 이용한다.<br>2의 보수에서  꼴의 곱셈을 위해,  혹은  을 사용한다는 점은,<br>
대부분의 machine 에서 양쪽 연산을 모두 지원하는 이유 중 하나일 것이다.<br>하지만, 나눗셈에 대해서는 일반적인 방법이 없다.<br>	# define M
	#define N

	int arith(int x, int y) {
		int result = 0;
		result = x*M + y/N;
		return result;
	}
	
	// compile and deCompile...
	
	int optarith(int x, int y) {
		int t = x;
		x &lt;&lt;= 5;
		x -= t;
		if(y &lt; 0) y += 7;
		y &lt;&lt; 3; /* arithmetic shift */
		return x + y;
	}
<br>Answer: <br>
해당 과정을 정리하면,  이며 이는 곱하기에 대한 최적화로  와 같다.<br>
 는  이므로 2의 보수 나눗셈으로 8에 대해 나누고 있다.<br><br>"정수" 연산은 모듈러 연산의 일종이다.<br>
한정된  의 사이즈는 가능한 값의 범위를 제한한다. 또한 이 때문에  가 발생할 수 있다.<br>
2의 보수법은 부호 없는 정수와 똑같은 bit-level 연산을 지원해주는 방법이다.<br>
bit-level 연산에서는 같거나 거의 비슷했다.<br>C언어의 미묘한 행동은 예상치 못한 결과를 낳는다. ]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter2/2.3-integer_arithmetic.html</link><guid isPermaLink="false">articles/chapter2/2.3-Integer_Arithmetic.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[2.4-Floating_Points]]></title><description><![CDATA[ 
 <br>Floating Point 는  형태로 표현한다.<br>
매우 큰 수, 0에 근접한 수, 더 일반적으로 실제 연산의 근삿값으로 유용하다.<br>1980년전에는 각자만의 규격으로 소수를 구현했다.<br>
그 당시 컴퓨터 제작자의 관심사는 정확도가 아닌, 속도와 구현의 난이도 였다.<br>1985년, IEEE Standard 754 가 생기면서, 소수 표현과 연산 방법에 대한 표준이 정립되었다.<br>
1976년, Intel 의 8087 chip, 8086 에서 floating point 를 지원하는 칩,<br>
을 디자인했다.<br>
현대에 와서는 대부분의 컴퓨터가 IEEE floating point 를 지원한다.<br>이 챕터에서는 floating point 를 알아보며, round 관련 이슈를 살펴본다.<br>
이는 숫자를 정확히 표현할 수 없기 때문에, 생기는 올림/내림에 의해 발생한다.<br>이후, 사칙연산, 관계 연산자의 수학적 특성을 살펴본다.<br>
또한, 해당 표준이 작고 일관적인 규칙으로 이루어져있으며, 이로 인해 이해하기 쉽고, 우아하다는 것을 이해한다.<br><br>십진법에서,  을  라고 표현하듯이,<br>
이진법에서는,  을  라고 표현할 수 있다.<br>
"." 의 왼쪽은 지수가 양수, 오른쪽은 지수가 음수로 이해할 수 있다.<br>
"." 의 위치를 왼쪽으로 한 칸 움직이면, 2로 나누는 것이 되며, 오른쪽은 2를 곱하는 것으로 해석할 수 있다.<br> 는 해당 자릿수로 나타낼 수 있는 가장 1에 근접한 소수이다.<br>
예를 들어,  이다. 나중에 이러한 표기로  를 사용한다.<br>
십진수에서 특성 소수() 을 표현하지 못하듯이 이진법에서도 불가능한 숫자들이 있다.<br>
가능한 숫자는 모두  의 형태를 띈다.<br><br>위의 표기는 비효율적이다.  의 경우, 101 개의 bit 가 필요하다.<br>
대신에,  로 표현한다.<br>
<br> : 부호로서, 1이라면 음수를, 0이라면 양수를 나타낸다. 
<br> : 2진수로 표현된 소수이다. 단, 다음 범위를 만족한다.

<br> 과  사이 혹은  과  사이


<br> :  로 표현되는  가 음수가 가능한 가중치를 의미한다.
<br>크게 4가지의 경우의 수가 있다.<br>
<img alt="PARA/Project/CS_APP_organize/chapter2/imgs/floating_point.png" src="https://cmj7271.github.io/cs-app-organize/lib/media/floating_point.png"><br>
single-precision format<br>
<br> : 1번째 bit
<br> : 8(= k) 번째 bit
<br> : 23(= n) 번째 bit
<br>double-precision format<br>
<br> : 1번째 bit
<br> : 11(= k) 번째 bit
<br> : 52(= n) 번째 bit
<br><br>가장 흔한 경우로,  의 bit 패턴이 모두 0이거나 모두 1이 아닌 경우이다.<br>
이 때, exponant value 는  로 해석된다.<br>
 는 부호 없는 bit 표현이며,  는  의 값을 갖는다.<br> 은 그 값을  라고 했을 때,  을 만족한다.<br>
 는  로 정의된다.  이것은  표현이라고 불린다.<br>
해당 값은 항상  을 가지기 때문에,  이며,<br>
1이 항상 지수부분에 오므로, 생략함으로서 비트를 효율적으로 사용한다.<br><br> 의 값이 모두 0 임을 의미한다.<br>
 를 가지며, significand 는  이다.<br>
즉,  의 적용이 되어있지 않다.<br>이 경우는 2가지의 목적이 있다.<br>첫번째는 0을 표현한다.<br>
Case 1 에서는 항상  이 1 이상이므로 0을 표현할 방법이 없다.<br>
모든 bit 가 0 인 것을 , 부호비트가 1이고 나머지가 모두 0인 것을  으로 해석한다.<br>
이 둘의 구분은 어떤 점에선 다르기도 하다.<br>2번째는 0.0 에 매우 가까운 숫자를 표현하는 것이다.<br>
0.0 에 가까워지는 숫자에게  라는 특성을 부여한다.<br><br>exponand 가 모두 1인 경우이다.<br>
fraction 부분이 모두 0이라면, 무한을 의미한다.  이라면  을,  이라면  이다.<br>
이는 결과가 OverFlow 임을 의미한다.<br>fraction 부분이 모두 0이 아니라면,  라고 부른다.<br><br><img alt="PARA/Project/CS_APP_organize/chapter2/imgs/floating_point_range.png" src="https://cmj7271.github.io/cs-app-organize/lib/media/floating_point_range.png"><br>한 가지 재미있는 특성은 이 bit 표현을 부호 없는 정수로 해석할 때,<br>
정렬 순서가 원래 의도인 floating-point 와 동일하다는 것이다.<br>
이는 정수와 정렬하는 방법과 동일한 방법으로 정렬하고자 하는 IEEE 의 의도된 설계이다.<br>앞에서 정수 표현과 소수 표현에서 일부 bit 패턴이 겹친다고 했고, 의도된 사항이라고 했는데,<br>
이는 소수 표현을 만드는 방법을 떠올리면 된다.<br>
먼저 해당하는 숫자를  로 표현하는데, 이 때  부분이 결국 정수 표현과 동일하다.<br>
따라서 소수 부분을 나타내는 부분이 정수와 일치할 수 있다.<br>]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter2/2.4-floating_points.html</link><guid isPermaLink="false">articles/chapter2/2.4-Floating_Points.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/lib/media/floating_point.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/lib/media/floating_point.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[6.1-Storage_Technologies]]></title><description><![CDATA[ 
 <br>상당 양의 컴퓨터 기술의 발전은 메모리 기술의 진보에 그 뿌리를 두고 있다.<br>
초기의 몇 KB 의 RAM(Random Access Memory) 에서, MB 로 빠르게 발전했다.<br>
그 속도는 매번 빨라져, 매년 2배의 증가폭을 보이기도 한다.<br><br>RAM 은 크게 2가지의 종류로 나뉜다. .<br>
SRAM(Static RAM) 은 DRAM에 비해 빠르지만, 비싸다.<br>
SRAM은 주로 Cache Memory 로써 CPU의 안팎에서 사용된다.<br>DRAM(Dynamic RAM)은 Main Memory 혹은 그래픽 시스템의 버퍼로서 사용된다.<br>보통, SRAM 은 몇십 단위의 MB 단위로 컴퓨터에 존재하지만,<br>
DRAM 은 몇백에서 몇천 단위의 MB 단위로 존재하게 된다.<br><br>SRAM 은 각 bit 를 (2가지의 안정된 상태를 가지는) 한 Memory Cell 로 저장한다.<br>각 Cell 은 6개로 이루어진 트랜지스터 회로로 구성되어 있다.<br>
해당 회로는 2가지의 다른 전압 상태를 무기한 가질 수 있는데, 이 상태를  라고도 표현한다.<br>
2가지 상태를 제외한 상태는 unstable 상태이며, 회로는 안정된 상태로 빠르게 움직인다.<br>이에 대한 비유로 반전된 펜듈럼이 있다.<br>
<img alt="articles/chapter6/imgs/inverted_pendulum.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/inverted_pendulum.png"><br>
펜듈럼은 2개의 안정된 상태(Left, Right) 를 가지며, 그 외는 불안정하다.<br>
즉, 어느 한쪽으로 빠르게 기울어져, 안정된 상태로 변한다.<br>
정확히 중앙에 존재해 언뜻 안정된 상태처럼 보이는 경우는  한 상태이다.<br>
아주 작은 자극에도 그 상태가 깨지며, 다시 돌아오지 못한다.<br>이러한 특성 때문에, SRAM 은 해당 정보를 무기한 저장할 수 있다.<br>
전력이 존재하는 한.<br>
외부 방해가 존재하더라도, 방해가 사라지는 순간 안정된 상태로 돌아갈 수 있다.<br><br>DRAM 은 bit 를 Capacitor(축전기) 에 저장한다.<br>
DRAM 은 매우 밀집하게 구성될 수 있는데, 이는 각 Cell 이 하나의 축전기와 단일 접근 트랜지스터(Single Access Transitor) 로 이루어지기 때문이다.<br>SRAM 과는 다르게, 외부 방해에 매우 취약하다.<br>
방해받은 Cell 은 원래 상태로 되돌릴 수 있는 방법이 없다.<br>
디지털 카메라에 사용되는 센서 또한, 근본적으로 축전기인데,<br>
해당 센서가 빛에 의한 변화를 저장한다는 점을 생각하면 이해하기 쉽다.<br>다양한 요인에 의해 DRAM 의 Cell 은 10 ~ 100 ms 마다 정보가 사라진다.<br>
다행히 Clock Cycle 이 ns 단위인 컴퓨터의 시각에서는 꽤 긴 시간이기 때문에 복구할 수 있다.<br>
컴퓨터는 해당 정보를 읽고, 다시 작성함으로서 정보를 보존시킨다.<br>
일부 시스템에서는 bit 를 더 사용하여, 에러를 고치는 기능을 추가하기도 한다.<br>
예시로 64 bit word 는 종종 72 bit 을 사용하곤 한다.<br>아래의 표는 SRAM 과 DRAM 을 비교한 표이다.<br>
<img alt="articles/chapter6/imgs/DRAM_VS_SRAM.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/dram_vs_sram.png"><br>
전반적으로 SRAM 이 성능적으로 뛰어나지만, 더 많은 Transitor 를 사용하기 때문에,<br>
밀집하게 구성하기 어려우며, 더 비싸고, 전력을 더 많이 사용하게 된다.<br><br>DRAM은  개의 SuperCell 로 나뉘어지며,<br>
각 SuperCell은  개의 Cell로 이루어져있다.<br>
즉, DRAM 은 총  의 bit 를 저장한다.<br>SuperCell은  개의 행과  개의 열로 이루어져있어,  가 성립한다.<br>
주소 형태  는  번째 행과  번째 열을 나타낸다.<br>
컴퓨터 분야에서는 Cell 이라는 용어를,<br>
회로 분야에서는 Word 라는 용어를<br>
Cell 과 SuperCell 의 구분없이 사용하기 때문에<br>
여기서는 SuperCell 이라는 임의의 용어를 만들어 사용하고 있다.
<br>정보는  이라는 것을 통해 Memory 의 정보가 입력/출력된다.<br>
하나의 Pin 은 1bit 의 정보를 전달한다.<br><img alt="articles/chapter6/imgs/DRAM_view.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/dram_view.png"><br>
해당 그림에서 data 는 8개의 Pin을 통해, 8bit 즉 1byte 의 정보를 주고받는 통로이다.<br>
addr 는 2개의 Pin으로 한번에 행 또는 열의 정보를 전달한다.<br>
여기서는 0~3 까지이기 때문에 2bit 로 충분하다.<br>초기의 DRAM 은 Memory Controller 로 알려진 회로에 연결되어 있다.<br>
이 회로는 한번에  bit 의 정보를 주고받을 수 있다.<br> 의 정보를 읽기 위해, 행 정보  를 그 다음에 열 정보  를 전달한다.<br>
DRAM 은 응답으로서,  의 정보를 보낸다.<br>
행 주소 를 (Row Access Strobe) Request,<br>
열 주소  를 (Column Access Strobe) Request 라고 한다.<br>
2개의 요청은 같은 Pin을 통해 전달된다.<br>예를 들어<br>
 의 DRAM 에서  에 접근하기 위해,<br>
<img alt="articles/chapter6/imgs/DRAM_ex.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/dram_ex.png"><br>
행 주소 2를 전달한다.<br>
이 때, 2행의 모든 정보를 row buffer 에 저장하게 된다.<br>
그 다음, 열 주소 1 을 받으면, buffer 에서 1에 해당하는 값을 전달하게 된다.<br>선형 배열이 아닌, 2차원의 배열로 되어있는 이유는,<br>
address Pin의 bit 숫자를 줄이기 위해서이다.<br>2차원으로 전달함으로써, 필요한 bit 숫자는 절반이 되지만,<br>
2번에 걸처서 전달하기 때문에 접근 속도가 느려진다는 단점이 존재한다.<br><br>메인보드에는 확장 슬롯이 존재하는데, 이 곳에는 Momory Module 을 끼게 된다.<br>
Memory Module 에는 DRAM Chip 이 패캐징 되어 있다.<br>
I7 시스템은 240 Pin 의 Dual Inline Memory Module(DIMM) 으로 구성되어있다.<br>
이 시스템에서는 64bit 단위로 데이터가 전달된다.<br><img alt="articles/chapter6/imgs/memory_module.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/memory_module.png"><br>
해당 예시는 8MB 의 DRAM 8개로 구성된 총 64MB의 Memory Module 을 나타낸다.<br>
각 SuperCell은 Main Memory 의 1Byte 를 담당하게 된다.<br>
Main Memory 의  의 정보는<br>
각 0번 DRAM 의 , 1번 DRAM의 , ... 순으로 8개의 정보를 합친 것을 의미한다.<br>예를 들어 메모리 주소  에 대해 접근하면,<br>
 를  로 변환한 다음,  에 대한 broadcast 를 DRAM 에 전달한다.<br>
각 DRAM 의 출력값을 64-bit word로 모아 Memory Controller 가 외부로 전달하게 된다.<br>Main Memory 는 여러개의 Module 을 Memory Controller 에 연결함으로서 확장될 수 있다.<br>
이 때의 접근은 주소  에 대해  가 담긴 module   에 접근하는 과정이 추가된다.<br><br>프로세서의 속도를 높이기 위해, 다양한 DRAM 이 발전하게 되었다.<br>
기본적으로 DRAM의 Cell 개념은 남아있지만, 그 접근 속도에 따른 최적화를 진행하였다.<br>아래에 이름만 언급하고 자세한 내용은 나중에 추가한다.<br><br><br><br><br><br><br>DRAM 과 SRAM 은 volatile 로서, 전력을 잃게 되면 그 정보가 소실된다.<br>
반면에 Nonvolatile Memory 는 전력을 잃어도 남으며, 그 종류가 다양하다.<br>
역사적인 이유로 그것들은 ROM(Read Only Memory) 로 칭해진다.<br>
사실일부 ROM 은 Write 도 가능하다.<br>
ROM 은 가능한 Write 의 횟수, Write 를 하는 방법에 따라 분류된다.<br>PROM(Programmable ROM), EPROM(Erasable Programmable ROM),<br>
EEPROM(Electrically Erasable PROM), Flash Memory, SSD(Solid State Disk) 등이 있다.<br><br>프로세서와 메인 메모리간 데이터 이동통로를  라고 한다.<br>
데이터의 이동은 Bus Transition 이라는 여러 개의 단계에 걸처서 이루어진다.<br>
Read Transition 은 Main Memory 에서 CPU로,<br>
Write Transition 은 CPU에서 Main Memory 로의 데이터 이동을 뜻한다.<br>Bus 는 여러개의 평행한 선들로 주소, 데이터, 제어신호 등을 보낸다.<br>
디자인에 따라, 데이터와 주소가 같은 선을 혹은 다른 선을 사용할 수 있다.<br>
2개 이상의 장치가 같은 Bus 를 공유하기도 하며,<br>
통제선(Control Wire)는 전달 동기화를 위한 또는 어떤 전달이 이루어지는지 알려주는 신호를 전달하기도 한다.<br><img alt="articles/chapter6/imgs/bus_structure.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/bus_structure.png"><br>위의 그림과 함께 movq A, %rax 가 실행되는 과정을 살펴본다.<br>
위의 명령어는 A 주소에 존재하는 내용을 레지스터 rax 에 옮기는 과정이다.<br>CPU Chip의 bus interface 에서, Read Transition 을 시작한다.<br>
Read Transition은 3개의 단계로 이루어진다.<br>
<br>CPU 는 A 주소를 System Bus 에 옮긴다.<br>
I/O Bridge 는 Memory Bus 를 통해 신호를 전달한다.
<br>Main Memory 는 Memory Bus 의 주소 신호를 감지하고,<br>
Memory Bus 로부터 주소를 읽는다. DRAM으로부터 그 데이터를 읽고,<br>
정보를 Memory Bus 에 Write 한다.<br>
I/O Bridge 는 Memory Bus 의 신호를 System Bus 신호로 번역하여,<br>
System Bus 로 전달한다.
<br>CPU 는 System Bus의 신호를 감지하고, 읽은 다음,<br>
해당 데이터를 rax 에 복사한다.
<br>반대로 Write Transition의 경우, 즉 movq %rax, A 일 때,<br>
CPU는 Write Transition 을 시작한다.<br>
역시 3개의 단계로 이루어진다.<br>
<br>
CPU는 A의 주소를 System Bus 에 옮긴다.<br>
Memory 는 Memory Bus로부터 해당 주소를 읽고, 데이터가 오기를 기다린다.

<br>
CPU는 rax 의 데이터를 System Bus 로 옮긴다.

<br>
Main Memory 는 해당 정보를 읽고, DRAM에 정보를 저장한다.

<br><br>Disk 는 아주 많은 양의 데이터를 저장할 수 있지만,<br>
DRAM, SRAM 보다 훨씬 느리다.<br>요즘에는 SSD를 위주로 사용한다는 점에서 생략한다.<br><br>I/O 장치, 그래픽카드, 모니터, 마우스, 키보드 등의 장치는 CPU와 Main Memory에<br>
I/O Bus 를 통해 연결된다.<br>System Bus 나 Memory Bus는 CPU-specific 이지만,<br>
I/O Bus 는 CPU 와 무관하다.<br>비록, I/O Bus 는 느리지만, 포괄적으로 third-party 장치에 접근할 수 있다.<br>
예를 들어, USB(Universal Serial Bus) Controller, Graphics Card(or Adapter),<br>
Host Bus Adapter 등이 있다.<br>
네트워크 장치 같은 추가 장치는 motherBoard 의 빈 확장슬롯을 이욤함으로서,<br>
I/O Bus에 접근할 수 있다.<br><br>여기서는 포괄적인 아이디어를 보여준다.<br>CPU는 memory-mapped I/O 라는 기술을 통해, I/O 장치에 명령어를 전달한다.<br>
이 기술에서 각 장치는 I/O Port 라는 곳을 통해 CPU와 소통하게 된다.<br>
장치는 경우에 따라 1개 이상의 Port 를 가질 수도 있다.<br>CPU는 각 포트로 명령어를 전달한다. 여기서는 0xa0 라고 가정한다.<br>첫번째로, 매개변수와 함께 읽기를 시작하라는 명령어를 전달한다.<br>
매개변수에는 Read 가 끝나고 언제 CPU에 interupt 할지에 대한 정보도 있다.<br>두번째로, 어느 구역의 정보를 읽어야할지 전달해준다.<br>세번째로, 어느 Main Memory의 주소에 저장해야하는지 전달해준다.<br>전달한 후, CPU는 다른 일을 진행한다.<br>
Disk의 Read 속도는 CPU의 Cycle 속도보다 훨씬 느리다는 점에서,<br>
효율적으로 운영하기 위함이다.<br>Disk Controller 가 CPU로부터 Read 명령어를 받으면,<br>
Logical Block Number 를 구역 주소로 바꾸고, 해당 구역의 정보를 읽어서,<br>
CPU의 명령 없이 바로 Main Memory 에 전달한다.<br>
이 CPU없이 전달하는 과정을 DMA(Direct Memory Access) 라고 한다.<br>
이 데이터의 전달을 DMA Transfer 라고 한다.<br>정보 전달이 완료되고, 정보가 Main Memory 에 저장되었을 때,<br>
Disk Controller 는 CPU에 interupt 신호를 보낸다.<br>
이 신호는 외부 Pin을 통해 CPU에 전달되어, CPU가 현재 하던 작업을 멈추게 한다.<br>
그 후 OS의 Routine으로 Jump하게 되고, 그 Routine 에서 I/O 작업이 끝났음을 기록하고, 다시 CPU하던 작업에게 통제권을 넘겨준다.<br><br>생략<br><br>생략]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.1-storage_technologies.html</link><guid isPermaLink="false">articles/chapter6/6.1-Storage_Technologies.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:53 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/inverted_pendulum.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/inverted_pendulum.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[6.2-Locality]]></title><description><![CDATA[ 
 <br>잘 작성된 프로그램은 좋은 지역성(Locality)를 가지는 경향이 있다.<br>
그 말은, 프로그램이 데이터를 참조할 때, 이미 전에 참조한 데이터 자체 혹은 그 근처로 접근하는 경향성이 있다는 의미이다.<br>
이 경향성은  라고 알려져있다.<br>
이는 수많은 하드웨어, 소프트웨어의 디자인과 성능에 영향을 끼친 중요한 개념이다.<br>Locality 는 크게 2가지의 형태로 구분된다.<br>
 로 구분된다.<br>좋은 Temporal Locality 를 가지면, 한번 참조된 메모리 위치가 가까운 미래에 여러번 참조된다.<br>
좋은 Spatial Locality를 가지면, 한번 참조된 메모리 위치와 가까운 곳에 참조된다.<br>좋은 Locality 를 지닌 프로그램은 일반적으로 더 빠른 경향이 있다.<br>하드웨어, OS, 프로그램까지 모든 단계에서의 설계는 Locality 를 고려하게 된다.<br>
하드웨어는 Cache Memory 의 도입을 통해,<br>
OS는 Main Memory에 Caching 의 기능 도입을 통해,<br>
애플리케이션 단계에서는 예를 들어, 웹 브라우저는 최근의 문서를 로컬 Disk 에 임시로 저장하곤한다.<br><br>다음 코드의 Locality 를 판단해보자.<br>	int sumvec(int v[N]) {
		int sum = 0;
		
		for(int i = 0; i &lt; N; i++)
			sum += v[i];
		
		return sum;
	}
<br>sum 변수의 경우, 매 Loop 에서 1번씩 참조되므로, Temporal Locality 가 높다.<br>
반면에 Scalar, 즉 주변 메모리 위치를 참조하지 않기 때문에, Spatial Locality 는 낮다.<br>vector v 에는 각 원소가 순서대로 메모리에 저장되어있다.<br>
그리고 해당 vector 를 앞에서 순차적으로 접근하므로,<br>
함수는 Spatial Locality 가 높다.<br>
하지만, 각 원소는 한번만 접근되기 때문에, Temporal Locality 는 낮다.<br>해당 함수는 각 변수가 Locality 를 잘 만족하기 때문에, 좋은 Locality 를 갖는 함수라고 결론지을 수 있다.<br>sumvec 처럼 배열의 원소를 순차적으로 접근하는 것을,<br>
 이라고 한다.<br>
이 패턴은 가장 흔하면서, Spatial Locality 에서 중요한 역할을 한다.<br>
Stride-1 Rerference Pattern 은 종종  라고도 불린다.<br>
순차적이 아닌, 매  번째 원소를 접근하는 것은  이라고 불린다. <br>Stride 는 다차원 배열을 다룰 때 중요하게 작용한다.<br>
다음의 2가지 C언어 예제를 살펴보자.<br>	int sumarrayrows(int a[M][N]) {
		int sum = 0;
		
		for(int i = 0; i &lt; M; i++) {
			for(int j = 0; j &lt; N; j++)
				sum += a[i][j];
		}
		return sum;
	}
<br>	int sumarraycols(int a[M][N]) {
		int sum = 0;

		for(int j = 0; j &lt; N; j++) { // !! i, j 의 순서가 바뀜 !!
			for(int i = 0; i &lt; M; i++)
				sum += a[i][j];
		}
		return sum;
	}
<br>첫번째 예제(sum_array_rows) 는 높은 Locality 를 가지고 있다.<br>
왜냐하면, C언어는 row-wise 방식의 배열을 처리하기 때문에,<br>
주소가 0, 4, 8, 12, 16, 20 으로 Stride-1 Reference Pattern 을 지니고 있다.<br>반면에 두번째 예제(sum_array_cols) 는 낮은 Locality 를 가지고 있다.<br>
row-wise 이기 때문에, 주소에 대한 접근이 0, 12, 4, 16, 8, 20 으로 Spatial Locality 가 낮다.<br><br>명령어는 Memory 에 저장되어 있고, 이를 CPU가 Read(Fetch) 해야 하므로,<br>
이에 대한 Locality 를 판단할 수 있다.<br>sumvec 함수에 대해,<br>
for loop가 메모리를 연속된 순서로 실행되기 때문에, Spatial Locality 가 높다.<br>
Loop 내부의 명령어가 여러번 실행되기 때문에, Temporal Locality 또한 높다.<br>코드가 데이터와 구별되는 특징은, 코드는 run-time에는 잘 변하지 않는다는 점이다.<br>
run-time 에 CPU는 Memory 의 명령어를 읽게 되는데,<br>
이 때, CPU는 이 명령어를 변화시키는 경우가 거의 없다.<br><br>이 챕터에서는 Locality 에 대한 근본적인 아이디어와 그것을 평가할 수 있는 간단한 방법을 알아봤다.<br>
<br>같은 변수에 대해 여러번 참조하는 프로그램은 좋은 Temporal Locality 를 가진다.
<br>Stride-k Reference Pattern 은 k가 낮을수록, Spatial Locality 가 높다.
<br>Loop 는 명령어 Read 관점에서, Temporal, Spatial Locality 를 모두 가진다.<br>
Loop Body 에 명령어가 적을수록, Loop Iteration의 수가 많을수록 Locality 가 높다.
<br>뒤에서 Cache Memory 에 대해 배우고 나서, Cache Hit 과 Miss 관점에서 다시 평가해볼 것이다.<br>
또한 왜 높은 Locality 가 빠른 속도를 가지는지 알아본다.<br>Practice Problem 6.8<br>
p[N] 은 vel 에서 3개, 그 이후로 acc 3개가 오는 것이 가장 가깝다.<br>
따라서, d, c, b 순서로 Locality 가 높다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.2-locality.html</link><guid isPermaLink="false">articles/chapter6/6.2-Locality.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[6.3-The_Memory_Hierarchy]]></title><description><![CDATA[ 
 <br><a data-href="articles/chapter6/6.1-Storage_Technologies" href="https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.1-storage_technologies.html" class="internal-link" target="_self" rel="noopener nofollow">articles/chapter6/6.1-Storage_Technologies</a> 와 <a data-href="articles/chapter6/6.2-Locality" href="https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.2-locality.html" class="internal-link" target="_self" rel="noopener nofollow">articles/chapter6/6.2-Locality</a> 에서<br>
저장 기술과 컴퓨터 소프트웨어에 대한 중요한 특성들을 공부했다.<br>Storage Technology<br>
다른 기술은 다른 접근 속도를 가진다.<br>
일반적으로 빠르면 빠를수록, 더 비싸며 가능한 용량이 작아진다.<br>Computer Software<br>
잘 작성된 프로그램은 좋은 Locality 를 가진다.<br>위의 2가지 특성은, 자연스럽게 메모리 시스템의 구조화를 유도한다.<br>
이를  라고 부른다.<br><img alt="articles/chapter6/imgs/memory_hierarchy.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/memory_hierarchy.png"><br>일반적으로, 더 낮은 Level 일수록, 더 느리고, 더 싸고, 더 크다.<br>
상위 계층부터 차례대로,<br>
Register, SRAM-based Cache, DRAM-based Main Memory, DIsk 등이 존재한다.<br>
가장 아래에는 외부 분산 파일 시스템(Distributed File System) 도 존재한다.<br>
또한, 네트워크를 통한 파일 접근, 예컨데 WWW 도 메모리 계층의 관점에서 볼 수 있다.<br><br>일반적으로  는 작지만 더 빠른 저장공간을 의미한다.<br>
이 저장공간은 더 크고 느린 장치의 상태를 캡쳐해둔다. (a Staging Area)<br>
Cache 를 사용하는 과정은  이라고 한다.<br>메모리 계층 구조의 핵심 아이디어는 다음과 같다.<br>
용량이 작지만, 더 빠른 k단계의 저장장치는<br>
용량은 크지만, 느린 k + 1 단계의 저장장치의 Cache 역할을 한다.<br>
다르게 말하자면, 각 레벨은 그 다음 레벨의 장치의 데이터를 Caching 한다.<br>예를 들어,<br>
Local Disk는 네트워크의 원격 Disk의,<br>
Main Memory 는 Local Disk의 Cache 역할을 한다.<br><img alt="articles/chapter6/imgs/principle_of_memory_hierarchy.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/principle_of_memory_hierarchy.png"><br>
k + 1 레벨의 장치는 데이터를 데이터 덩어리(Chunks of Data Object),  으로 나눈다.<br>
각 Block은 고유의 주소와 이름을 가져, 서로 구분된다.<br>
Block 의 사이즈는 상황에 따라 고정(보통의 경우) 혹은 가변(원격 HTML 파일)이다.<br>k 레벨의 장치는 k+1 장치의 Block 과 같은 크기의 Block 을 가지며,<br>
k + 1 장치의 Block 집합의 부분집합을 저장하게 된다.<br>k, k + 1 레벨 장치간의 데이터 이동은 이 block 단위로 이루어진다.<br>
하지만, Block 의 사이즈가 같은 것은 이웃한 레벨일 때만 적용된다.<br>
예를 들어, L0 와 L1 간의, L4 와 L5 간의 Block 의 크기는 서로 다르다.<br>일반적으로 더 낮은 레벨일수록, 접근 속도가 느리기 때문에, 큰 사이즈의 Block 을 사용하게 된다.<br><br>프로그램이 k + 1 레벨 장치의 d 데이터가 필요할 때,<br>
k 레벨에 이미 d 데이터가 있는 경우,  이라고 부른다.<br>
프로그램은 더 빠르게 d 데이터를 k 레벨 장치에서 읽게 된다.<br><br>반대로, k 레벨 장치에서 찾지 못한 경우,  라고 한다.<br>
Miss 가 발생한 경우, k 레벨 장치는 해당 데이터를 포함하는 block 을 Caching 한다.<br>
이 과정에서 기존의 block 에서 덮어씌울 수도 있다.<br>덮어씌우는 과정은 ,  the Block 이라고 한다.<br>
이 때 덮어씌워지는 Block 은  이라고 불린다.<br>
어떤 Block 이 덮어씌워질지는  에 의해 결정된다.<br>그저 무작위로, 혹은 사용한지 가장 오래된 Block 등 다양한 정책이 존재한다.<br>덮어씌우는 과정을 통해 해당 데이터는 미래에 다시 접근이 일어나길 기대하면서,<br>
k 레벨 장치에 남게 된다.<br><br>Cache Miss 에는 다양한 요인이 있다.<br>만약 k 레벨 장치가 비어있다면, 어떤 데이터에 대해서도 Miss 가 발생한다.<br>
이러한 비어있는 상태를  혹은  라고 한다.<br>
Cold Miss 는 중요한데, 이 Miss 는 보통 일시적인 현상이기 때문이다.<br>
특히 안정된 상태 즉, 반복된 메모리 접근에 의해 Cache 가 Warmed up 된 상태에서는 잘 일어나지 않는다.<br>Miss 가 발생할 때, k 레벨 장치는 Placement Policy 에 따라 해당 데이터를 Caching 해야한다.<br>
가장 유연한 방법은 모든 k + 1 레벨의 Block 에 대해 모든 k 레벨의 Block 에 저장할 수 있도록 허용하는 것이다.<br>
하지만, 무작위적으로 저장하는 방법은 높은 레벨의 장치(CPU에 가까운) 에서 허용하기엔 너무 비싸다.<br>그래서, 하드웨어적 Cache 는 보통 더 간단하고, 제한적인 Placement Policy 를 채택한다.<br>
예를 들어, "k + 1 레벨 장치의 Block i 는 k 레벨 장치의 i mod 4 에 저장한다" 가 있다.<br>
이에 따르면, 0, 4, 8, 12 Block 은 0 에만 저장될 수 있다.<br>이러한 종류의 제한 정책은  를 일으킬 수 있다.<br>
이는 Cache 가 충분히 Hit 할 수 있을 정도로 크지만, 정책에 의해 같은 Block 에 저장되서<br>
실패하는 경우이다.<br>예를 들어, 0, 8, 0, 8 순서로 Block 에 접근하고자 한다면,<br>
i mod 4 에서는 계속 다른 Block 을 Caching 하게 되어, Miss 가 발생하게 된다.<br>프로그램은 Loop 같이 Sequence of Phases 로 작동하며,<br>
특히 각 Phase 는 일정한 수의 고정된 Cache Block 에 접근하는 경우가 있다.<br>
예를 들어, Loop 는 같은 배열을 계속 참조하는 경우가 많다.<br>
이러한 고정된 Cache Block 집합을  라고 부른다.<br>이 Working Set 의 크기가 Cache 의 크기를 초과할 때,<br>
 를 겪게 된다.<br>
즉, 이 Miss 는 Cache 가 해당 Working Set 을 다루기엔 너무 작아서 생기는 문제이다.<br><br>메모리 계층구조는 각각의 저장장치는 다음 레벨의 장치의 Cache 역할을 한다는 것이다.<br>
각 레벨에서는 이 Cache 를 관리하는 무언가가 필요하다.<br>
이 무언가는 Cache 장치를 Block으로 나누고, 다른 레벨간에 Block 을 전달하고, Hit 또는 Miss 가 발생했는지 결정하고, 그 결과에 따라 처리한다.<br>
이 무언가는 하드웨어적 혹은 소프트웨어적 또는 2개 모두를 합친 방식으로 구현된다.<br>예를 들어, 컴파일러는 레지스터 파일을 관리한다.<br>
L1, L2, L3 는 Cache 안에 존재하는 하드웨어적 논리 회로가 관리한다.<br>
Virtual Memory 는 OS의 소프트웨어와 CPU의 주소변환 하드웨어에 의해 관리된다.<br>
대부분의 경우, Cache 는 자동적으로 작동하여, 프로그램에서 특별히 조작할 필요가 없다.<br><br>Caching 에 기반한 메모리 계층구조가 작동하는 이유는,<br>
느린 저장장치가 빠른 저장장치보다 싸기 때문에 그리고,<br>
프로그램이 Locality 라는 성질을 보이려는 경향 때문이다.<br>Exploiting Temporal Locality<br>
Temporal Locality 때문에, 같은 데이터는 여러번 재사용된다.<br>
한번 Miss 가 발생한 이후 Caching 이 일어나기 때문에,<br>
이후의 접근은 휠씬 빠르다고 기대할 수 있다.<br>Exploiting Spatial Locality<br>
Block 은 여러 데이터를 가지고 있기 때문에,<br>
Spatial Locality 를 만족하는 프로그램에서 근접한 데이터에 대한 접근은<br>
그 전에 이미 Caching 된 Block 에 존재할 것이라고 기대할 수 있다.<br>Cache 는 다양한 곳에서 사용된다.<br>
이들은 다양한 하드웨어와 소프트웨어의 조합으로 만들어질 수 있다.<br>
<img alt="articles/chapter6/imgs/many_cache.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/many_cache.png">]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.3-the_memory_hierarchy.html</link><guid isPermaLink="false">articles/chapter6/6.3-The_Memory_Hierarchy.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:53 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/memory_hierarchy.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/memory_hierarchy.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[6.4-Cache_Memories]]></title><description><![CDATA[ 
 <br>초기에는 3가지 레벨의 계층구조, Register, Main Memory, Disk 로 존재해왔다.<br>
그러나, CPU 와 Main Memory 간의 성능 차이가 점점 커지면서,<br>
CPU 와 Main Memory 사이에 하나의 계층을 추가해야한다는 목소리가 커졌다.<br>
이에 작은 SRAM Cache Memory 가 추가되었고, 이는  라고 불렸다.<br>
보통 4 Cycle 정도의 빠르기로 Register 와 비슷하다.<br>CPU와 Register 간의 성능 차이가 점점 늘어가면서, 더 큰 Cache 에 대한 필요성이 대두되었다.<br>
이에 L2 Cache 가 L1 Cache 와 Main Memory 사이에 추가되었다.<br>
L2 Cache 는 10 Cycle 정도의 속도를 가진다.<br>현대 시스템은 여기서 더 큰 L3 Cache 를 L2 와 Main Memory 사이에 두기도 한다.<br>
이는 50 Cycle 정도의 속도를 가진다.<br>여기서는 논의를 간단하게 하기 위해, L1 Cache 만 가정하고 이야기한다.<br>
하지만, 역시 그 기본적인 내용은 L2, L3 등등에 대해 똑같이 적용된다.<br><br>Cache 는 Set, Line, Data Block 으로 이루어진다.<br>
Cache 는  개의  의 배열로 이루어져있다.<br>
각각의 Set 은  개의  으로 이루어져있다.<br>
각각의 Line 은 <br>
<br> 개의 Byte 로 이루어진  과
<br>Cache 가 정보를 저장하는지 알려주는  과
<br>Cache Line 에서 Block 을 식별해주는  로 구성된  로<br>
구성되어있다.
<br>Cache 의 구조는  으로 표현할 수 있다.<br>
이 때 Cache 의 사이즈  는 가능한 모든 Block 의 총합이기 때문에,<br>
tab bit 와 valid bit 는 제외된다. 따라서,  로 표현된다.<br>CPU가 Main Memory 의 A 주소의 값을 원할 때, CPU는 A 주소를 Cache 로 보낸다.<br>
Cache 가 만약 A를 가지고 있다면 바로 전달해주는데,<br>
Cache 는 어떻게 가지고 있다는 것을 알고 있을까?<br>Cache 는 주소를 간단하게 검사하는 것으로 원하는 Word 가 존재하는지 찾을 수 있게 정렬되어있다. 이는 마치, Hash Table 에서 매우 간단한 Hash 함수를 쓰는 것과 유사하다.<br>,  가  길이의 주소를 3부분으로 나눈다.<br>
<img alt="articles/chapter6/imgs/organization_of_cache.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/organization_of_cache.png"><br>
 는 S set 배열에서 어느 set 에 존재하는지 알려준다.<br>
set 을 알고나서는 t tag bit 는 어느 Line 에 존재하는지 알려준다.<br>
이 때, valid bit 가 설정되어있어야만, 해당 정보를 가지고 있다고 판단한다.<br>
마지막으로 b Block Offset Bit 는 원하는 Word 가 존재하는 Block 까지의 거리를 알려준다.<br>아래는 지금까지 나온 매개변수를 정리한 것이다.<br>
<img alt="articles/chapter6/imgs/summary_of_cache_parameters.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/summary_of_cache_parameters.png"><br><br>Cache 는 하나의 Set 당 몇개의 Line 을 가지는지, 즉  에 따라 서로 다른 종류로 분류할 수 있다.<br>
정확히 1개의 Line 을 가지는 Cache 를  라고한다.<br>
<img alt="articles/chapter6/imgs/direct_mapped_cache.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/direct_mapped_cache.png"><br>이 Direct - Mapped Cache 를 통해, 앞으로 이야기를 진행한다.<br>
우리에게 CPU, Register, L1 Cache, Main Memory 가 있다고 가정해보자.<br>CPU 가 Memory 에서 Word w 를 읽고자한다고 했을 때,<br>
L1 Cache 에 요청하게 되고, 존재한다면(Cache Hit) 빠르게 w 를 반환해준다.<br>
없다면(Cache Miss), L1 Cache 가 Main Memory 에 요청할 때까지 기다린다.<br>
요청에 의해 도착하면 L1 Cache 는 해당 내용이 담긴 Block 을 Caching 하고,<br>
w 를 추출해 전달한다.<br>Cache 가 요청에 대해 Hit 인지 Miss 인지 판단하고, Word 를 추출하는 과정은 아래의 3단계로 나뉜다.<br>
<br>Set Selection
<br>Line Matching
<br>Word Extraction
<br><br>Cache 는 w 를 위한 주소에서 s Set Index 를 추출한다.<br>
이를 Unsigned Integer 즉, Set Index 로 해석한다.<br>
우리는 Cache 가 Set 에 대한 1차원 배열로 이루어져있다고 생각해볼 수 있다.<br>
<img alt="articles/chapter6/imgs/set_selection.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/set_selection.png"><br><br>전 단계에서 어느 Set 을 살펴봐야하나 결정했다.<br>
다음 단계로는 Line 을 결정하는 일이지만, Direct - Mapped Cache 는<br>
Line 이 하나이므로 간단하다.<br>
w 를 가지고 있는지의 여부는 Valid Bit 와 tag 가 올바른지 확인하면 알 수 있다.<br><img alt="articles/chapter6/imgs/line_matching.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/line_matching.png"><br>
위 그림에서 Vaild Bit, Tag Bit 를 확인하는 것을 알 수 있다.<br>
2개 모두 올바르면 Cache Hit 이고, 아니라면 Cache Miss 임을 알 수 있다.<br><br>만약 Cache Hit 임을 전 단계에서 확인했다면, 우리는 w 가 어느 Block 에 존재함을 알 수 있다.<br>
정확한 위치는 Block Offset 을 통해 구할 수 있으며, 이를 통해 Word 크기만큼 복사하면 된다.<br>
위의 그림에서는 Word 가 4Byte 임을 가정하고, 4개의 Block 을 복사한다.<br><br>Cass Miss 임을 확인하게 된다면, 다음 레벨의 Block 에게 요청하고,<br>
그 정보를 Cache Line 에 저장해야한다.<br>
일반적으로 해당 Set에서 이미 가능한 Line 이 가득차면, 어느 Line 이 제거되어야한다.<br>
Direct - Mapped Cache 는 Line 이 1개이므로 제거되어야할 Line 은 자명하다.<br><br>Cache 가 Set 과 Line 을 결정하는 과정은 매우 단순하다.<br>
왜냐하면, 하드웨어가 이를 ns 안에 해결해야하기 때문이다.<br>그러나, 그 과정이 사람에게는 혼란을 줄 수 있기 때문에 예제를 통해 설명한다.<br><br>라고 가정한다. 즉,<br>
<br>4개의 Set
<br>Set 당 1개의 Line
<br>2  Byte 로 구성된 Block
<br>4 Bit 로 구성된 주소<br>
이다.<br>
또한, Word 는 1 Byte 로 구성된다고 가정한다.
<br>tag와 index bit 을 통해, block 을 일대일로 맵핑할 수 있다.<br>
예를 들어, tag, index 가 0 이라면, 0번 Block 이다.<br>8개의 Memory Block 이 존재한다.<br>
하지만 4개의 Cache Set 이 존재하므로, 여러개의 Block 이 같은 Cache Set 을 이용할 수 있다.<br>
예를 들어, 0, 4 Block 은 Set 0 으로 포함된다.<br>같은 Set 에 포함되는 Block 은 Tag Bit 을 통해 구분된다.<br>
0과 4 Block 은 Tag Bit 가 각각 0, 1 인것으로 구분된다.<br>
<img alt="articles/chapter6/imgs/4_bit_address_ex.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/4_bit_address_ex.png"><br>이러한 조건 속에서 Cache 의 행동을 시뮬레이션 해본다.<br>
Word 크기는 1 Byte 임을 기억하고 진행한다.<br>초기의 Cache 는 비어있다. 즉 Valid Bit 은 모두 0이다.<br>
<img alt="articles/chapter6/imgs/cache_0.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/cache_0.png"><br>
각 줄은 하나의 Cache Line 을 의미한다.<br>
<br>
Read Word at Address 0.<br>
모든 Valid Bit 이 0이므로 Cache Miss 이며,<br>
다음 레벨의 장치에서 데이터를 가져오고, Caching 을 진행한다.<br>
그 후, m[0] 을 반환하고 저장한다. (m[0] 은 Memory 주소 0에서의 데이터를 의미한다.)<br>
<img alt="articles/chapter6/imgs/cache_1.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/cache_1.png">

<br>
Read Word at Address 1<br>
이것은 Cache Hit 으로 바로 m[1] 을 반환하게 된다.

<br>
Read Word at Address 13<br>
Set 2 가 Invalid 하기 때문에, Cache Miss 이다.<br>
Block 6을 가져와서 저장하고 반환한다.<br>
<img alt="articles/chapter6/imgs/cache_2.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/cache_2.png">

<br>
Read word At Address 8<br>
Set 0 은 Valid 하지만, Tag 가 맞지 않으므로 Cache Miss 이다.<br>
Block 4 를 가져와서 저장하고, 반환한다.<br>
이 과정에서 기존의 Block 0 은 제거된다.<br>
<img alt="articles/chapter6/imgs/cache_3.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/cache_3.png">

<br>
Read Word at Address 0<br>
바로 직전에 Block 0 이 제거되었기 때문에 Cache Miss 이다.<br>
Cache 는 충분하지만, 다른 Block 이 참조되고 있기 때문에 발생한 Miss 이므로,<br>
Conflict Miss 이다.<br>
<img alt="articles/chapter6/imgs/cache_4.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/cache_4.png">

<br><br>Direct - Mapped Cache 에서 2의 거듭제골꼴의 길이를 가진 배열에 접근할 때,<br>
Conflict Miss 가 발생하곤한다. 다음의 예제를 살펴보자.<br>	float dotprod(float x[8], float y[8]) {
		float sum = 0.0;
		for(int i = 0; i &lt; 8; i++) 
			sum += x[i] * y[i];
		return sum;
	}
<br>위의 함수는 좋은 Locality 를 가졌으므로, Cache Hit 이 잘 일어날거라고 기대되지만,<br>
그렇지 않을 수 있다.<br>다음을 가정해보자.<br>
x 는 각 원소가 0부터 4Byte 단위로 이어진다. 즉, 0, 4, 8, ... 28 의 주소를 갖는다.<br>
y 는 32부터 60까지의 주소를 갖는다.<br>Cache 는 Block 이 16Byte 의 크기이며, 2개의 Set 을 가진다고 가정한다.<br>
즉, 총 크기는 32 Byte 이다. 이때, 주소에 해당하는 Set Index는 다음과 같다.<br>
<img alt="articles/chapter6/imgs/conflict_miss_ex.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/conflict_miss_ex.png"><br>x[0] 에 대해서, x[0] 부터 x[3] 까지가 Caching 된다.<br>
다음으로 y[0] 에 대해서, y[0] 부터 y[3] 까지 Caching이 되는데,<br>
이 때, x[0] 와 y[0] 가 같은 공간을 차지하게 된다.<br>
이 때문에 모든 x[] 와 y[] 에 대한 참조는 Cache Miss 특히, Conflict Miss 가 발생한다.<br>이런 식으로 Cache 가 같은 데이터에 대해 계속해서 저장되고, 지워지는 과정을<br>
 이라고 한다.<br>
자연스러운 형태로 앞의 Bits 을 Index로 잡으면, Cache 저장에 비효율적이다.<br>
특히, Locality 가 높아 그 주변에 대해 참조하는 경우에는, Cache 에 많은 정보가 저장될 수 없다.
<img alt="articles/chapter6/imgs/why_cache_has_middle_index.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/why_cache_has_middle_index.png"><br>
위의 그림에서 배열을 순차적으로 순회한다고 가정해보자.<br>
첫번째 경우에 대해서는 처음 4개의 Block 을 같은 Set 에 저장하게 된다.<br>
이것이 반복되어서, 결국 매 순간에 한 Set 만 사용하게 되는 비효율이 발생한다.<br>
이것을 Middle-Order Index 과 비교하면, 더 효율적임을 알 수 있다.
<br>결론적으로 좋은 Locality 에도 불구하고, 같은 Cache Set 을 사용하게 되어,<br>
Conflict Miss 가 발생한다.<br>
이는 간단한 예시로 살펴보았지만, 충분히 현실에서도 발생할 수 있다.<br>다행히 원인을 안다면, 해결방법은 상대적으로 쉽다.<br>
한가지 쉬운 해결책은  Byte 의 padding 원소를 각 배열에 추가한다.<br>
예를 들어, x[8] 이 x[12] 이 되도록 늘려준다.<br>
이는 Set Index를 아래와 같이 바꾼다.<br>
<img alt="articles/chapter6/imgs/padding_ex.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/padding_ex.png"><br>
이를 통해, Thrashing 을 제거할 수 있다.<br><br>이전에 Conflict Miss 가 발생한 이유는 근본적으로 Set 이 오직 하나의 Line 만을 가졌기 때문이다.<br>
 은 여러개의 Line() 를 가지고 있다.<br>
특히  개의 Line 을 가짐을 강조하여,  라고 한다.<br>
우리는 정확히  인 경우는 나중에 살펴볼 것이다.<br><br>Set 을 고르는 과정은 direct - mapped Cache 와 동일하다.<br>
<img alt="articles/chapter6/imgs/asso_cache.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/asso_cache.png"><br><br>여러개의 Line 이 존재하기 때문에 Direct - Mapped Cache 와는 달리,<br>
Tag Bit 를 검사한다.<br>
전통적인 Memory 는 주소를 입력으로서 받으면, 그 값을 돌려준다.<br>
반면에 Associative Memory 는 (Key, Value) 의 배열로 되어있다.<br>
즉, Key 를 입력받아 (Key, Value) 를 반환해준다.<br>따라서 우리는 Associative Cache 에 존재하는 Set 을 작은 Associative Memory로 생각해,<br>
Tag 와 Valid Bit 을 합친 것을 Key 로, Block 의 내용을 Value 로 생각할 수 있다.<br>Line 이 가질 수 있는 Memory Block 에는 제한이 없기 때문에,<br>
모든 Line 에 대해 검사해야만 한다.<br>
만약 찾게 되면, Block Offset 을 통해 그 결과를 반환해준다.<br>
<img alt="articles/chapter6/imgs/line_match_in_asso_cache.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/line_match_in_asso_cache.png"><br><br>Cache Miss 가 발생할 때, 어느 Line 을 제거해야할까?<br>
만약 빈 Line 이 존재한다면, 그 Line 은 좋은 후보지만, 모두 차있을 경우에는 어떻게 할까?<br>
그렇다면 고른 Line 이 더이상 참조되지 않기를 기대해야한다.<br>프로그래머가 해당 Replacement Policy 를 코드에 적용시키는 것은<br>
어렵기 때문에 자세히 설명하지 않는다.<br>
가장 간단한 방법은 랜덤으로 지정하는 것이다.<br>
좀 더 정교하게는 Princicple of Locality 에 기대어, 이후에 참조될 가능성이 가장 적은 Line 을 고른다.<br>
예를 들어 LFU(Least Frequently Used) Policy 는 가장 적게 참조된 Line 을 제거한다.<br>
또는 LRU(Least Recently Used) Policy 는 가장 마지막으로 접근된 Line을 제거한다.<br>
이는 하드웨어적으로 더 시간이 걸리지만, CPU에서 먼 장치로 가는 것보다는 빠르다.<br><br>Fully Associative Cache 는 단 하나의 Set 으로 구성되어 있다.<br>
<img alt="articles/chapter6/imgs/full_asso_cache.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/full_asso_cache.png"><br><br>Set 선택은 단순하다. 왜냐하면 Set 이 1개밖에 없기 때문이다.<br>
또한, Index bit 이 없기 때문에, 주소는 tag 와 Block Offset 으로만 나뉘어진다.<br><br>이는 Associative Cache 와 동일하게 작동한다.<br>
그러나, 일치하는 Tag 를 병렬적으로 찾아야하기 때문에, 용량이 크면서 빠르게는 만들기 어렵다. 그래서 작은 Cache 나 TLB(Transition Lookside Buffer) 정도에서 사용된다.<br><br>Cache 의 Read 는 직관적이다.<br>
Cache Hit 의 경우, 바로 반환하며, Miss 의 경우 저장한 다음 반환한다.<br>반면에 Cache Write 의 경우는 좀 더 복잡하다.<br>
Write Hit, Cache 에 저장된 데이터에 대해 Write 가 일어나면 어떻게 하는가?<br>가장 간단한 방법은 write 마다 다음 단계의 장치도 write 하는  이지만,<br>
이는 Write 로 인한 Bus Traffic 을 증가시킨다.<br>다른 방법은  이라는 방법이다.<br>
이는 해당 데이터가 Cache 에서 없어질 때, 다음장치에 write 를 시도하는 것이다.<br>
이는 Locality 가 좋을수록 그 효율이 증가한다.<br>
하지만, 추가적인 복잡도, Cache Block 이 변했는지 확인하는 Dirty Bit 가 필요한 등<br>
단점이 존재한다.<br>또 다른 문제는 Write Miss 에서 발생한다.<br>
한가지 접근은  라고 알려진 방법이다.<br>
다음 레벨 장치에서 해당하는 Block 의 데이터를 Cache 로 가져와서 Cache 에서 Update 한다.<br>
이는 Locality 에 기대하는 동작이지만, 매 Miss 마다 다음 레벨 장치의 Block 이동이 있다는 단점이 있다.<br>다른 방법으로  가 있다.<br>
이는 Cache 를 건너띄고, 바로 다음 레벨 장치에 Write 하는 것이다.<br>보통 Write-through Cache 는 no-write-allocate 를,<br>
Write-back Cache 는 write-allocate 를 사용한다.<br>Write 를 최적화하는 작업은 미묘하고 어려운 작업으로,<br>
여기서는 간단하게 살펴보았다.<br>프로그래머로서 Cache-friendly 한 코드를 작성하고 싶다면,<br>
Write-back, Write-allocate Cache 방식이라고 가정하고 작성하는 것을 추천한다.<br>
낮은 계층의 메모리는 전송 시간이 길기 때문에 write-back 을 많이 사용하기 때문이다.<br>
또한, Write-back, Write-allocate 는 Read 를 다루는 방법과 유사하기 때문에 통일된 시각으로 볼 수 있다.<br><br>여태까지는 데이터만 저장하는 것으로 이야기했지만, 명령어도 Cache 에 저장할 수 있다.<br>
명령어(Instruction) 만 저장한 Cache 를  라고 한다.<br>
반면에 데이터만 저장한다면  라고 한다.<br>
만약 둘다 존재한다면  라고 한다.<br>현대의 프로세서는 분리된 i-cache 와 d-cache 를 가진다.<br>
이에 대한 이유로,<br>
분리되어있기 때문에 동시에 2개의 Cache 를 읽을 수 있다.<br>
또한, 보통 I-Cache 는 Read-Only 이기 때문에 간단하다.<br>
2개의 Cache 는 접근 방식에 대해 다른 최적화를, 다른 Block 크기 등등을 가질 수 있다.<br>
또한 분리됨으로서 서로 간의 Conflict Miss 가 발생하지 않게 해준다.<br>다음은 i7 CPU에 대한 전체적인 이미지이다.<br>
<img alt="articles/chapter6/imgs/i7_ex.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/i7_ex.png"><br><br>Cache 의 성능은 보통 아래의 지표를 통해 평가된다.<br>
<br>
Miss Late<br>
프로그램이 동작하는 동안, Miss 한 비율을 나타낸다.<br>
 로 나타낸다.

<br>
Hit Rate<br>
Hit 한 비율을 나타낸다.  로 표현할 수 있다.

<br>
Hit Time<br>
Cache 에서 CPU로 Word 를 전달하는데 걸리는 시간을 의미한다.<br>
이는 Set Selection, Line Identification, Word Selection 을 포함한다.<br>
이는 L1 Cache 의 Cycle 에 비례한다.

<br>
Miss Penalty<br>
Miss 로 인해 필요한 추가시간이다.<br>
L1 에 대해 L2 는 10, L3 는 50, Main Memory 에 대해서는 200 Cycle 에 비례한다.

<br>비용과 성능에 대한 trade-off 를 최적화하는 것은<br>
수많은 시뮬레이션과 실제 벤치마크가 필요한, 우리의 범위를 넘어선다.<br>
하지만, 일부 trade-off 관계를 살펴볼 수 있다.<br><br>큰 Cache 사이즈는 Hit Rate 의 비율을 높여준다.<br>
하지만, 그 속도는 느려질 것이다. 즉 Hit Time 이 커지게 된다.<br>
이것은 L1 이 L2 보다, L2가 L3 보다 용량이 작은 이유를 설명해준다.<br><br>큰 Block 사이즈는 복합적이다.<br>
Spatial Locality 에 기대어 Hit Rate 를 늘려주지만,<br>
큰 Block 사이즈는 적은 수의 Line 을 암시하기 때문에 Temporal Locality 를 낮춰<br>
Hit Rate 를 낮출 수도 있다.<br>
또한, 전송시간을 늘리기 때문에 Miss Penalty 에도 악영향을 끼친다.<br><br>매개변수 , 즉 Set 당 Line 의 개수가 끼치는 영향이다.<br>
 가 클수록, Conflict Miss 로 인한 Thrashing 이 줄어든다.<br>
하지만,  가 큰 Cache 는 만들기 비싸며, 빠르게 만들기 어렵다.<br>
더 많은 Tag bit, 추가적인 LRU(Least Recently Used) 상태 Bit, 추가적인 통제 로직을 필요로하기 때문이다.<br>
또한, 증가된 복잡성 때문에 Hit Time 을 증가시킬 수 있다.<br>
Miss Penalty 측면에서도 제거할 Line 을 찾기 위한 로직의 복잡성 증가로 증가할 수 있다.<br><br>Write-Through 방식은 더 구현하기 쉽고,<br>
Cache 를 업데이트하는데 무관하며 따로 동작하는 Write Buffer 를 사용할 수 있다.<br>
그리고, Read Miss 는 추가적인 Write 가 발생하진 않기 때문에 비교적 싸다.<br>반면에 Write-back 방식은 더 적은 이동으로, DMA 를 사용하는 I/O 장치에게 넓은 대역폭을 제공할 수 있다. 또한 이동의 횟수를 줄이는 것은 이동의 비용이 많이 드는 낮은 레벨의 장치에서 중요하다. 일반적으로 낮은 레벨일수록 Write-back 을 사용하는 경향이 있다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.4-cache_memories.html</link><guid isPermaLink="false">articles/chapter6/6.4-Cache_Memories.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:53 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/organization_of_cache.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/articles/chapter6/imgs/organization_of_cache.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[6.5-Writing_Cache_Friendly_Code]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="articles/chapter6/6.2-Locality" data-href="articles/chapter6/6.2-Locality" href="https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.2-locality.html" class="internal-link" target="_self" rel="noopener nofollow">6.2-Locality</a> 에서 우리는 Locality 에 대한 개념과 좋은 Locality 의 기준을 알아보았다.<br>
이제 Cache Memory 의 작동을 알게 되었으므로, 좀 더 정확하게 이해할 수 있다.<br>좋은 Locality 를 가지면, Miss Rate 를 낮추기 때문에 더 빠르게 동작할 수 있다.<br>
즉 좋은 코드를 위해서는 Cache friendly 하게, 같은 말로 Locality 가 좋게 작성해야 한다.<br>아래는 코드가 Cache-friendly 하게 만들 수 있는 접근을 알려준다.<br>
<br>
Make the Common Case go Fast.<br>
보통의 프로그램은 몇가지의 중요한 함수에서 주로 작동하며,<br>
이 중요한 함수들은 몇가지의 Loop 에서 주로 작동한다.<br>
이 Loop 의 Body 에 집중해야한다.

<br>
Minimize the Number of Cache Misses in each inner Loop.<br>
Loop 내에서 Miss Rate 가 더 적은 프로그램이 더 빠르다.

]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.5-writing_cache_friendly_code.html</link><guid isPermaLink="false">articles/chapter6/6.5-Writing_Cache_Friendly_Code.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[7.1-Compiler_Drivers]]></title><description><![CDATA[ 
 <br> 는 필요에 따라<br>
preprocessor, compiler, assembler, linker 를 불러 사용한다.<br><br><br><img class="code-styler-icon" src="https://cmj7271.github.io/cs-app-organize/blob://d4142029-0432-493d-932f-d68ffd6c217b">code/link/main.c1	int sum(int *a, int n);2	int array[2] = {1, 2};3<br>4	int main() {5		int val = sum(array, 2);6		return val;7	}<br><br><br><img class="code-styler-icon" src="https://cmj7271.github.io/cs-app-organize/blob://d4142029-0432-493d-932f-d68ffd6c217b">code/link/sum.c1	int sum(int *a, int n) {2		int i, s = 0;3		for(i = 0; i &lt; n; i++) {4			s += a[i];5		}6		return s;7	}<br>2개의 파일을 이용해 하나의 실행파일 prog 를 만드는 과정을 살펴보자.<br>
이를 위해 명령어 gcc -Og -o prog main.c sum.c 를 실행시키게 된다.<br>driver는 첫번째로,  를 실행시킨다.<br>
이는 C 소스코드를 중간파일(ASCII intermediate file) 인,  로 만든다.<br>그 다음으로,  을 실행시킨다.<br>
이는 중간파일을 어셈블리 파일(ASCII assembly-language) 인,  로 만든다.<br> 을 실행시킨다.<br>
이는 어셈블리 파일을 재할당 가능한 이진 목적파일() 로 만든다.<br>sum.c 에 대해 동일한 과정을 거쳐, 목적파일을 만든다.<br>마지막으로,  을 실행시킨다.<br>
main.o, sum.o 그리고 다른 필요한 시스템목적파일과 함께, 실행가능한 이진파일() 을 만든다.<br>마지막으로 실행을 위해, ./prog 를 입력하는데, 이는<br>
터미널이 OS의 loader 라는 함수를 사용하는 것으로 이루어진다.<br>
loader 는 코드와 데이터를 메모리에 복사하고, 통제권을 프로그램의 시작부분으로 넘겨준다.<br><img alt="PARA/Project/CS_APP_organize/chapter7/imgs/static_linking.png" src="https://cmj7271.github.io/cs-app-organize/lib/media/static_linking.png">]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.1-compiler_drivers.html</link><guid isPermaLink="false">articles/chapter7/7.1-Compiler_Drivers.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/blob:app://obsidian.md/d4142029-0432-493d-932f-d68ffd6c217b" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/blob:app://obsidian.md/d4142029-0432-493d-932f-d68ffd6c217b&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[7.2-Static_Linking]]></title><description><![CDATA[ 
 <br>Static Linker 는 input 으로 재할당 가능한 목적 파일들과 옵션 매개변수를 받아,<br>
실행 가능한 목적 파일을 생성한다.<br>재할당 가능한 목적파일은 내부에 코드와 데이터 영역(code, data section) 이 존재하는데,<br>
각 부분은 연속적인 바이트의 나열일 뿐이다.<br>명령어도 어떤 영역에 존재하는데, 다른 영역에 존재하는 전역변수를 초기화한다.<br>
또한 초기화되지 않은 변수는 또 다른 영역에 존재한다.<br>실행가능한 목적 파일을 위해, linker 는 아래의 2가지 일을 한다.<br>
<br>
<br>
목적 파일은  을 정의하고, 참조(reference) 한다.<br>
참조는 함수, 전역변수 등 다양하다.<br>
Symbol Resolution 은 각 symbol의 참조를 "정확히" 1개의 정의로 대응시키기 위함이다.

<br>
<br>
컴파일러와 어셈블러는 코드, 데이터 영역을 주소 0에서부터 시작한다.<br>
각 symbol 정의, 메모리 위치(Memory Location)를 고려하여, 각 영역을 재배치한다.<br>
재배치된 symbol 정의에 따라 참조 또한 그에 맞춰 변경한다.<br>
linker 는 어셈블러가 만들어준 명령어를 통해 재할당을 하는데,<br>
이 때 만들어진 명령어를 Relocation Entries 라고 한다.

<br>목적 파일은 바이트 덩어리(Blocks of Bytes) 의 조합일 뿐이다.<br>
이 덩어리는 코드를, 데이터를 다른 데이터 구조 등등을 가지고 있을 수 있다.<br>
linker 는 이 덩어리들을 합치고, run-time 위치를 결정하며, 덩어리 안의 위치 또한 변경한다.<br>linker 는 해당 machine 에 대해 거의 이해하지 못한다.<br>
컴파일러와 어셈블러가 이미 대부분의 필요한 작업을 했기 때문이다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.2-static_linking.html</link><guid isPermaLink="false">articles/chapter7/7.2-Static_Linking.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[7.3-Object_Files]]></title><description><![CDATA[ 
 <br>목적 파일은 크게 3가지 형태가 있다.<br>
<br>
<br>
이진 코드와 데이터를<br>
compile-time 에 다른 Relocatable Obj File 과 합칠 수 있는 형태로<br>
저장한다.

<br>
<br>
이진 코드와 데이터를<br>
메모리로 바로 복사될 수 있고, 실행가능한 형태로<br>
저장한다.

<br>
<br>
특별한 형태의 Relocatable Obj File이다.<br>
load-time, run-time 에<br>
메모리에 저장가능하며, liking 이 동적으로(Dynamic) 이루어질 수 있다.

<br>실제 바이트 덩어리는  이며,<br>
Object Module이 disk 에 저장되어 있을 때  이라고 한다.<br>
용어가 구분되어있지만, 혼용해서 사용한다.<br>Obj 파일은 specific Object File Format 이 존재하는데, 이는 시스템마다 다르다.<br>
그 중에서 해당 교재는 최신 Linux, Unix 시스템에서 사용하는<br>
Executable and Linkable Format(ELF) 형식을 사용하여 설명한다.<br>
하지만, 기본 개념은 특정 형식과 무관하게, 비슷하다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.3-object_files.html</link><guid isPermaLink="false">articles/chapter7/7.3-Object_Files.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[7.4-Relocatable_Object_Files]]></title><description><![CDATA[ 
 <br><img alt="PARA/Project/CS_APP_organize/chapter7/imgs/ELF_relocatble_obj.png" src="https://cmj7271.github.io/cs-app-organize/lib/media/elf_relocatble_obj.png"><br>
ELF Header는<br>
16바이트 배열로 word 사이즈와 이 파일을 생성한 시스템의 바이트 순서가 저장되어있다.<br>
header 의 나머지 부분은 linker 가 목적파일을 파싱하고 해석하는데 필요한 정보가 담겨있다.<br>
이것은 ELF Header 의 사이즈, Obj 파일의 형식(relocatable, executable, shared),<br>
machine-type(x86-64...), section header table에 대한 file offset(base 주소로부터의 거리),<br>
section header table 로 향하는 entries 의 개수와 사이즈 가 있다.<br>section header table에는<br>
다양한 section에 대한 위치와 사리즈가 저장되어 있다.<br>
또한, 각 section 에 대한 고정된 크기의 entry 도 존재한다.<br>ELF Header 와 Section header Table 사이에는 실제 section 이 존재한다.<br>
보통은 아래와 같은 section 을 갖는다.<br>
<br><br>
컴파일된 프로그램이 machine code 형태로 저장되어있다.
<br><br>
Read-Only 데이터, Printf의 형식지정자, switch 문의 jump tables 등이 존재한다.
<br><br>
 된 전역, static 변수가 저장되어있다.<br>
지역변수는 stack 에 run-time 시에 존재하므로, data 나 아래의 bss에 존재하지 않는다.
<br><br>
 된 전역, static 변수, 0으로 초기화된 전역 static 변수가 저장되어있다.<br>
이 구역은 실제로는 공간을 차지하지 않는다.<br>
단순한 임시공간(PlaceHolder) 로 Obj 파일 형식은 공간효율을 위해 초기화, 비초기화 변수들을 구분한다.(초기화되지 않은 변수는 공간을 차지할 필요가 없다.)<br>
run-time 시에 이 변수들은 메모리에 0으로 초기화되면서 할당된다.
<br><br>
 이 저장되어있다.<br>
해당 테이블에는 프로그램에서 정의되고 사용되는(참조되는) 함수와 전역변수에 대한 정보가 담겨있다.<br>
모든 relocatable 목적파일은 symbol table 이 .symtab 에 존재한다.<br>
하지만, 컴파일러에 있는 symbol table 과 달리, 지역변수에 대한 접근은 존재하지 않는다.
<br><br>
.text 영역 중 linker 가 다른 목적파일과 연결할 때, 변경되어야하는 위치들의 모음이다.<br>
보통 전역변수나 외부 함수에 대한 call 을 나타내는 명령어가 해당된다.<br>
이 정보는 실제 실행목적파일에 필요하지 않기 때문에, 따로 linker에 포함해달라는 요청이 있지 않는 한, 제거된다.
<br><br>
전역변수에 대한 재할당 정보, 그중에서 모듈에 의해 참조되거나 정의된 정보에 해당한다.<br>
보통 전역변수나 외부 함수에 대한 주소를 초기값으로 갖는 초기화된 전역변수에 해당한다.
<br><br>
컴파일러에 -g 옵션(debugging information 생성 요청) 이 있을 경우, 만들어진다.<br>
지역변수, 프로그램 내 타입 정의, 프로그램 내에 정의되고 참조된 전역변수, C언어 소스코드 에 대한 entries 가 저장된 debugging symbol table 이 존재한다.
<br><br>
컴파일러에 -g 옵션(debugging information 생성 요청) 이 있을 경우, 만들어진다.<br>
line number 와 C언어 소스코드 간의 맵핑을 저장한다.
<br><br>
string table로, .symtab, .debug 영역의 symbol table, section header 에 존재하는 section 이름을 위해 존재한다.<br>
이 테이블은 null-terminated 문자열의 배열이다.
]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.4-relocatable_object_files.html</link><guid isPermaLink="false">articles/chapter7/7.4-Relocatable_Object_Files.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/lib/media/elf_relocatble_obj.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/lib/media/elf_relocatble_obj.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[7.5-Symbols_and-Symbol_Tables]]></title><description><![CDATA[ 
 <br>각각의 Relocatable Object Module 에는 Symbol Table 이 존재한다.<br>
이 테이블은 해당 Module 에서 정의되고 참조되는 Symbols 에 대한 정보가 포함되어있다.<br>
Linker 의 관점에서는 3가지의 서로 다른 형태가 존재한다.<br>이하에서 살펴볼 특정 Relocatbale Object Module 1개를 "m" 이라고 지칭한다.<br>
<br><br>
m에 의해 정의되어있지만, 다른 module 에서 사용가능하다.<br>
Global Linker Symbol 은 C언어에서 nonstatic function 과 전역변수에 대응된다.
<br><br>
Global Symbol 의 일종이나, 다른 module 에 의해 정의되어 있으며, m은 참조하는 경우이다. 이는 C언어에서 다른 module 에 정의된 nonstaic function 과 전역변수에 대응된다.
<br><br>
module m 에서 정의되며, m에서만 참조되는 경우이다.<br>
이는 C언어의 static function 과 static 으로 정의된 전역변수에 해당한다.<br>
이 Symbols 는 오직 m에서만 참조 가능하다.
<br>Local Linker Symbols 는 Local Program Variables 와 동일하지 않다.<br>
.symtab 에 있는 Symbol Table 은 local nonstatic program variable 을 가지고 있지 않다.<br>
nonstatic program variable 은 run-time 시, stack 에 의해 관리되며, Linker 의 관심사가 아니다.<br>그러나 반대로, static 이 붙은 지역변수는 stack 이 아닌 .data 나 .bss 에 공간을 할당한다.<br>
즉 Symbol Table에 들어가기 때문에 각 이름은 Unique 하다.<br>	int f() {
		static int x = 0;
		return x;
	}

	int g() {
		static int x = 1;
		return x;
	}
<br>위의 두 함수에 정의된 x 는 Symbol Table에 저장되는데, 이름을 구별하기 위해, 컴파일러가 임의로 이름을 변경한다. 예컨데, x.1, x.2 등등으로 변경하여 어셈블러에게 전달한다.<br>컴파일러에 의해 얻은 .s 파일(어셈블리어 파일)을 이용해 에셈블러는 Symbol Table 을 만든다.<br>
ELF Symbol Table 은 .symtab 영역에 포함되어있다.<br>
Table 은 아래의 entries 배열을 가지며, 각 entry 는 아래와 같은 구조이다.<br>
<img alt="articles/chapter7/imgs/ELF_Symbol_Table.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter7/imgs/elf_symbol_table.png"><br>
name 은 String Table에서 이름에 해당하는 Symbol 까지의 거리이다.<br>
String Table(.strtab 의 경우) 각 Symbol에 해당하는 이름이 담겨있다.<br>value 는 Symbol의 주소로,<br>
relocatable 일 때는 Obj가 정의된 Section 의 시작점으로부터의 거리(offset)이며,<br>
executable 일 때는 run-time의 실제 주소이다.(absolute run-time address).<br>type 은 일반적으로는 data 혹은 function이다.<br>
그러나, Symbol Table 은 각 section 에 대한 entry 나,<br>
원본 소스코드에 대한 경로(Ex. src/foo.c)에 대한 enrty 또한 가진다.<br>각 Symbol 은 특정 Section 에 존재하는데, 해당하는 Section 의 index 가 section 에 표현되어있다.<br>section header table 에 entry 가 없는 특별한 3개의 Pseudosections 가 있다.<br>
<br><br>
위치가 바뀌면 안되는(not be relocated) Symbol 이 저장되어있다.
<br><br>
정의되지 않은 Symbol 이 저장되어 있다.<br>
즉, 이 Obj 에서 참조되지만, 다른 곳에 정의되어있는 Symbol이다.
<br><br>
할당되지 않은 초기화되지 않은 데이터 객체에 대한 Symbol 이 저장되어있다.<br>
여기에 저장되어 있는 Symbol 의 value 는 alignment requirement 가 담겨있다.<br>
이는, 어떤 배수의 주소에 놔야하는지를 나타내는 값이다.<br>
size 는 최소 사이즈를 나타낸다.<br>
이 pseudoSection은 Relocatable 에서만 존재한다. executable 에서는 존재하지 않는다.
<br>COMMON 과 .bss 그 차이가 미묘하다.<br>
최신 GCC 는 아래의 관례를 따라 할당한다.<br>
<br> : Uninitialized gloabal variables
<br> : uninitailized static variables, gloabal or static variables that initialized to zero<br>
위의 관례는 linker 가 symbol resolution 을 하는 과정에 그 뿌리를 두고 있다.(Ch7.6에서 살펴본다.)
<br>GCC의 READELF 는 obj 파일의 내용을 볼 수 있는 도구이다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.5-symbols_and-symbol_tables.html</link><guid isPermaLink="false">articles/chapter7/7.5-Symbols_and-Symbol_Tables.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:53 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/articles/chapter7/imgs/elf_symbol_table.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/articles/chapter7/imgs/elf_symbol_table.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[7.6-Symbol_Resolution]]></title><description><![CDATA[ 
 <br>Linker 는 symbol reference 를 정확히 하나의 definition 과 연결하여, 해결한다.<br>
이 때의 definition 은 입력받은 relocatable obj 파일에 담겨있다.<br>local Symbol에 대해서는 같은 module 에 정의와 참조가 있기 때문에,<br>
직관적으로 해결 가능하다.<br>
static local variable 에 대해서도 컴파일러가 정확히 하나의 정의가 있음을 보장해주기 때문에,<br>
직관적으로 해결 가능하다.<br>하지만, Global Symbol 는 조금 복잡하다.<br>
컴파일러가 현재 module 에 정의되지 않은 symbol 을 만날 때,<br>
다른 module 에 정의되어있다고 가정하고, "linker Symbol Table Entry" 를 만들고,<br>
Linker 에게 그 책임을 전가한다.<br>
Linker 가 입력받은 obj 파일 중 어디에서도 찾지 못하면, 에러를 반환한다.<br>여러 obj 파일은 동일한 이름의 global symbol을 가질 수 있다는 문제가 존재한다.<br>
이 때, Linker 는 에러를 반환하거나, 여러 개 중 1개를 선택하고 나머지는 무시해야한다.<br>
C++ 과 Java 는 함수 오버로딩이 가능한 언어이다.<br>
이 경우에는, Symbol 을 어떤 식으로 관리할까?
이는 컴파일러가 특별한 방법으로<br>
메소드 이름과 파라미터를 연결지어 이름을 짓는 방식으로 해소한다.
이 때, 이름을 짓는 것을 ,<br>
지은 이름을 해석하는 것을  이라고 한다.
C++ 과 Java 는 서로 호환가능한 방법을 이용한다.
<br><br>Linker 의 입력은 여러개의 Relocatable obj 파일이다.<br>
만약 여러 개의 module 이 같은 이름의 global Symbol 을 정의하면 어떻게 될까?<br>
Linux 의 Compilation System 은 다음과 같이 작동한다.<br>compile-time 에 컴파일러는 어셈블러에게 global symbol가 ,  둘중에 하나의 상태를 전달한다. 그리고 이 정보를 암시적으로 relocatable obj 파일의 symbol table 에 담아둔다.<br>
Function, Initialized global variable 에 대해서는  로,<br>
Uninitialized global variable 에 대해서는  로 저장한다.<br>
<br>Rule 1. 여러개의 Strong symbol은 허용하지 않는다.
<br>Rule 2. 1개의 Strong symbol 과 여러개의 weak symbol 이 있다면, Strong Symbol 을 고른다.
<br>Rule 3. 여러개의 weak symbol 에 대해서는 아무거나 고른다.
<br>2번, 3번 규칙에 의해, 미묘한 버그가 종종 발생한다.<br>	/* foo3.c */
	#include &lt;stdio.h&gt;
	void f(void);
	int x = 15123;

	int main() {
		f();
		printf("x = %d\n", x); // !! x = 15212 !!
		return 0;
	}

	/* bar3.c */
	int x;
	void f() {
		x = 15212;
	}
<br>main 의 출력값은 x = 15212 로 미묘하다.<br>
비슷하게, foo3.c 의 x의 초기화를 main 의 f() 이전에 시행해도 결과는 동일하다.<br>
weak definition 2개가 있을 때는 아무거나 고르기 때문에 에러가 나지 않는다.<br>만약 weak definition 이면서, type 이 다르면 어떻게 될까?<br>	// foo.c
	#include &lt;stdio.h&gt;
	void f();
	
	int x = 15123;
	int y = 15212;
	
	int main() {
	    f();
	    printf("x = 0x%x y = 0x%x \n", x, y);
	    printf("x = %d y = %d \n", x, y);
	    return 0;
	}
	
	// bar.c
	double x;
	
	void f() {
	    x = -0.0;
	}
// OUTPUT
// x = 0x0 y = 0x80000000 
// x = 0 !! y = -2147483648 !!
<br>y 에 대해서는 접근이 없는 것처럼 보이지만, 의도치 않는 값이 발생한다.<br>
이는 x = -0.0 이 8byte write 를 하게 되고,<br>
메모리 상 붙어있는y 에 오염을 일으키게 된다.<br>
이를 4byte 씩 끊어서 읽게 되기 때문에 의도치 않는 값으로 출력된다.<br>이는 코드 작성과 실행이 시점 차이가 큰, 규모가 거대한 프로젝트에서 심각한 버그를 일으킬 수 있다.<br><a data-href="articles/chapter7/7.5-Symbols_and-Symbol_Tables" href="https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.5-symbols_and-symbol_tables.html" class="internal-link" target="_self" rel="noopener nofollow">articles/chapter7/7.5-Symbols_and-Symbol_Tables</a> 에서 COMMON, .bss 에 symbol 을 할당하는 방법에 대해 확인해봤다.<br>
사실 이 방법은 몇몇 경우에서는, linker 가 여러 개의 module 을 허용하며,<br>
이 때 여러 개의 같은 이름의 global symbol 이 가능할 수 있다.<br>컴파일러가 module 을 번역할 시, weak global symbol(이후 x 라고 가칭) 을 만났을 때,<br>
이 x 가 다른 module 에 있을 지 알 수 없다. 즉, 어떤 instance 를 고를지 예측할 수 없다.<br>
이 때문에 linker 에게 책임을 넘기기 위해, COMMON 부분에 x 를 할당하게 된다.<br>반면에, x 가 zero 로 초기화되어있다면, 이는 strong symbol 이기 때문에,<br>
.bss 에 저장한다.<br>
비슷하게, static symbol 은 유일하기 때문에, .bss 에 할당할 수 있다.<br><br>linker 가 relocatable obj files 을 읽어서, output executable file 로 반환하는 것으로 가정했다.<br>
사실은, 컴파일 시스템은 여러 관련된 obj module 을 하나로 묶는 mechanism 을 제공한다.<br>
이 묶인 파일은  로 불리며, linker 의 input 으로 사용될 수 있다.<br>executable 파일을 만들 때, linker는 library 에 있는 module 중, 프로그램이 참조한 module 만 복사한다.<br>이러한 Library 의 개념이 왜 사용되는지, ISO C99 로 알아보자.<br>
C99는 Standard I/O, String manipulation, Integer Math Function 등등 다양한 함수가<br>
정의되어 있고, 이는 libc.a 라이브러리에 저장되어있다.<br>만약, Library 라는 개념을 쓰지 않는다면 다음과 같은 방법이 가능하다.<br>
<br>
컴파일러는 표준 함수에 대한 Call 을 인식하고, 올바른 코드를 바로 생성한다.<br>
이는 Pascal 같이 표준 함수가 적은 경우에는 적절할 수 있지만,<br>
C언어 같이 표준 함수가 많은 경우에는 적절하지 않다.
이는 컴파일러의 부담이 커진다.<br>
즉, 복잡도가 증가하며, 새로운 표준함수가 늘어날 때마다 새로운 버전이 필요해진다.
한편으로는 사용자 입장에서는 표준함수가 언제나 가능하다는 점에서 편리하긴하다.

<br>다른 방법으로는 <br>
<br>
모든 표준 함수를 하나의 relocatable obj 파일에 담는다. 예컨데, libc.o 라고 하자.<br>
이는 컴파일러의 구현과 표준함수의 구현을 분리할 수 있으며,<br>
여전히 개발자에게는 유용해보인다.
하지만, 여전히 큰 문제점이 있다.<br>
executable file 을 만들 때마다, 모든 표준함수가 구현되어있는 목적파일을 사용한다.<br>
실행하는 프로그램에서도, 메모리에 함수가 복사되어 낭비하게 된다.
또한, 표준 함수에 변화가 생길 때마다, library 개발자는 전체 소스코드를 다시 컴파일해야한다. 이는 유지보수에서 시간을 소모하게 만든다.
이 문제는 relocatable obj 파일을 나눠서 well-known 디렉토리에 저장할 수 있지만,<br>
executable file 을 만들 때, 명령어가 복잡해질 수 있다.

<br>Static Library 의 개념은 위의 단점을 해소할 수 있다.<br>
관련된 함수는 분리된 module 에 컴파일되고, 하나의 static library 로 포장된다. (packaged)<br>프로그램은 command line 에 file name 을 적음으로서, library 안의 함수를 사용할 수 있다.<br>link time에, linker 는 프로그램이 referenced 한 obj module 만 복사해온다.<br>
이를 통해, disk 와 memory 공간을 아낄 수 있다.<br>
동시에 개발자는 몇개의 library 이름만 command line 에 추가하면 된다.<br>리눅스에서는 static library 는 disk 에 archive 형태로 저장된다.<br>
archive 은 relocatable obj 파일을 모아둔 것이다.<br>
추가로 header 가 존재하는데, 각 obj 파일의 사이즈와 위치가 저장되어 있다.<br>
확장자로는 .a 을 쓴다.<br>library 에 대한 논의를 시작하기 전에 아래의 2개의 파일을 정의하고 간다.<br>	int addcnt = 0;

	void addvec(int *x, int *y, int *z, int n) {
		addcnt++;

		for(int i = 0; i &lt; n; i++) 
			z[i] = x[i] + y[i];
	}
<br>	int mulcnt = 0;

	void mulvec(int *x, int *y, int *z, int n) {
		mulcnt++;

		for(int i = 0; i &lt; n; i++) 
			z[i] = x[i] * y[i];
	}
<br>해당 파일로 library 를 만들기 위해, 아래의 명령어를 수행한다.<br>	gcc -c addvec.c multvec.c
	ar rcs libvector.a addvec.o multvec.o
<br>해당 library 를 사용하기 위한 main2.c 을 다음과 같이 작성한다.<br>	#include &lt;stdio.h&gt;
	#include "vector.h"

	int x[2] = {1, 2};
	int y[2] = {3, 4};
	int z[2];

	int main() {
		addvec(x, y, z, 2);
		printf("z = [ %d %d]\n", z[0], z[1]);
		return 0;
	}
<br>vector.h 는 libvector.a 의 함수를 정의해둔 헤더파일이다.<br>executable 로 만들기 위해 다음의 명령어를 수행한다.<br>	gcc -c main2.c
	gcc -static -o prog2c main2.o ./libvector.a
	# gcc -static -o prog2c main2.o -L. -lvector
<br>-static : 정적 링킹을 강제한다. 즉, 외부의 추가적인 linking 이 필요하지 않게 만든다.<br>
-L: 라이브러리 검색 경로를 추가하는데, . 이므로 현재 디렉토리 위치가 된다.<br>
-lvector 는 vector 라는 이름의 library 를 -L 의 경로에서 찾는다.<br><img alt="articles/chapter7/imgs/Linking_with_static_libraries.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter7/imgs/linking_with_static_libraries.png"><br>
위 그림은 linker 의 행동을 요약해서 보여준다.<br>linker 는 addvec 이라는 symbol 이 main2.c 에서 필요하고, 이것이 addvec.o 에 존재함을 파악하여 해당 addvec.o 를 executable 에 복사해온다.<br>
반면에, multvec.o 는 필요하지 않으므로 복사해오지 않는다.<br><br>static library 는 유용하지만, 개발자의 복잡도를 증가시키는 요인 중 하나이다.<br>
리눅스가 외부 참조를 해결하는 방법 때문이다.<br>Symbol Resolution Phase에, linker 는 왼쪽에서 오른쪽으로, 입력으로 받은 obj 파일과 archive 파일을 확인한다. 그동안에 3개의 집합을 관리하게 된다.<br>
<br> : executable 을 만들기 위해 포함할 relocatable obj 파일
<br> : 아직 해결되지 않은 symbols (참조되어있지만, 아직 정의되어있지 않은)
<br> : 전의 input file 에서 정의된 symbols
<br>input file  에 대해 다음과 같은 행동이 발생한다.<br>
<br> 가 obj 인지, archive 인지 확인한다.
<br> 가 obj 인 경우,  에 추가되며,  를 업데이트한다.
<br> 가 archive 인 경우, linker 는  의 해결되지 않은 symbol 을 해결하고자 시도한다.<br>
만약 member m이  의 symbol 을 해결한다면,  에 추가된다.<br>
그리고,  를 업데이트한다.<br>
member obj 에 대해, 이 작업은  가 업데이트 되지 않을 때까지 반복한다.
<br> 가 input file 에 대한 탐색이 끝나도 비어있지 않다면, error 를 반환하고 종료된다.<br>
아니라면,  의 파일과 함께 executable output file 을 만들어낸다.
<br>이 알고리즘은 순서가 중요하기 때문에, 이상한 에러를 만날 수 있다.<br>	gcc -static ./libvector.a main2.c
<br>위 명령어는 error, 특히 addvec 을 참조할 수 없다고 나온다.<br>
처음 libvector.a 를 검사할 때,  는 비어있기 때문에, 어떤 member obj 도 포함하지 않기 때문에 발생하게 된다.<br>따라서, 배치의 순서에는 관례적인 규칙이 존재한다.<br>
library 는 보통 가장 마지막에 배치한다.<br>
만약 여러 library 간의 의존관계가 존재할 경우, 적절하게 참조되도록 순서에 주의해야한다.<br>
만약, main.c 가 libx.a 에 의존하며, libx.a 가 다시 liby.a 를 의존한다면,<br>	gcc -c main.c libx.a liby.a
<br>식으로 작성해야한다.<br>혹은, 안전을 위해 archive 파일을 여러번 적는 것도 가능하며, 2개의 library 를 합치는 것도 방법이다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.6-symbol_resolution.html</link><guid isPermaLink="false">articles/chapter7/7.6-Symbol_Resolution.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:53 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/articles/chapter7/imgs/linking_with_static_libraries.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/articles/chapter7/imgs/linking_with_static_libraries.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[9.1-Physical_and_Virtual_Addressing]]></title><description><![CDATA[ 
 <br>Main Memory 는  개의 연속된 Byte-Size Cell 로 구성되어 있다.<br>
첫번째를 0번 주소, 그 다음을 1번 주소... 이런 식으로 주소를 매길 수 있다.<br>CPU가 Memory 에 접근하는 가장 간단한 방법은 이 주소를 바로 이용하는 것이다.<br>
이러한 접근을  이라고 한다.<br><img alt="articles/chapter9/imgs/physical_address.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/physical_address.png"><br>
위의 그림은 CPU가 4번 주소에서 4Byte 를 읽는 과정을 나타낸 것이다.<br>
CPU는 Load Instruction 을 실행하여, Memory Bus 를 통해 Memory 에 물리적 주소를 요청한다. Main Memory 는 해당 정보를 읽어 CPU에 돌려준다. 즉, Register 에 저장된다.<br>초기의 시스템은 이러한 Physical Addressing 을 사용했지만,<br>
현대의 시스템은 Virtual Addressing 을 사용한다.<br><img alt="articles/chapter9/imgs/virtual_address.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/virtual_address.png"><br>
Virtual Addressing 에서는 CPU는 Main Memory 에  를 이용해서 접근한다. 그 주소는 Main Memory 에 전달되기 전에 Physical Address 로 변환되는데,<br>
이를  이라고 한다.<br>
이 주소 변환은 CPU 하드웨어와 OS 간의 협력이 필요하다.<br>
  는 Virtual Address 를 변환해준다.<br>
이는 Main Memory 에 저장되어있으며 OS가 관리하는 LookUp Table 을 통해 이루어진다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.1-physical_and_virtual_addressing.html</link><guid isPermaLink="false">articles/chapter9/9.1-Physical_and_Virtual_Addressing.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:53 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/physical_address.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/physical_address.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[9.2-Address_Spaces]]></title><description><![CDATA[ 
 <br> 는 양의 정수로 이루어진 정렬된 주소들이다.<br>
만약 주소가 빠짐없이 연이은 자연수로 이루어져있으면,  라고 한다.<br>
논의를 간단하게 하기 위해, 우리는 Linear Address Space 를 가정하고 이야기한다.<br>Virtual Memory 를 사용하는 시스템에서는, CPU는 Address Space 로부터<br>
 사이즈의 Virtual Address 를 만들고 이 주소공간을   라고 부른다.<br>
주소 공간의 크기는 가장 큰 주소를 표현하는데 필요한 Bit 에 의해 결정된다.<br>
예를 들어,  개의 주소가 필요한 Virtual Address Space 는<br>
 라고 부른다,<br>
대부분의 시스템은 32-bit 혹은 64-bit 의 Address Space 를 지원한다.<br>시스템은 또한 M Bytes 에 대응하는 Physical Address Space 를 가질 수 있다.<br>
 은 2의 지수꼴일 필요는 없지만, 논의를 위해  을 가정한다.<br>주소 공간의 개념은<br>
데이터 객체(Bytes) 와 속성(Address) 간의 분명한 구분을 위해<br>
중요하다.<br>
이 개념을 통해, 하나의 데이터 객체에 여러개의 주소, 각각이 다른 주소공간에 속하는<br>
그런 상태를 이해할 수 있다.<br>이것이 Virtual Memory 의 기본 개념이다.<br>
Main Memory 의 각 Byte 는 Virtual Memory Space 에서 선택된 Virtual Address 를 가지고,<br>
Physical Address Space 에서 선택된 Physical Address 를 가진다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.2-address_spaces.html</link><guid isPermaLink="false">articles/chapter9/9.2-Address_Spaces.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:32 GMT</pubDate></item><item><title><![CDATA[9.3-VM_as_a_Tool_for_Caching]]></title><description><![CDATA[ 
 <br>개념적으로 VM 은  개의 연속된 Byte-size 의 Cell 로 Disk 에 저장된다.<br>
각 Byte 는 index처럼 작동하는 고유한 Virtual address 를 가진다.<br>Disk 의 내용은 Main Memory 에 Caching 되어있다.<br>
즉, Block 으로 관리되어 Disk 와 Main Memory 사이로 이동한다.<br>VM 은 이를  라고 불리는 고정된 크기의 Block 을 통해 다룬다.<br>
각 VP 는  Byte의 크기를 가진다.<br>
비슷하게, Physical Memory 도  로  Byte 단위로 관리된다.<br>VP 는 아래의 3개의 부분집합으로 나뉜다.<br>
<br>
<br>
아직 VM에 의해 할당되지 않은 Page 이다.<br>
어떤한 데이터도 연관되어있지 않기 때문에 Disk 에서 공간을 차지하지 않는다.

<br>
<br>
할당된 Page로, Physical Memory 에 Caching 되어 있다.

<br>
<br>
할당된 Page 이나, Caching 되어있지 않다.

<br><img alt="articles/chapter9/imgs/VM_ex.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/vm_ex.png"><br>
실제로 Caching 된 Cached Page 만 Physical Memory 에 할당되어있음을 알 수 있다.<br><br>앞으로의 논의를 위해,<br>
SRAM Cache 는 L1, L2, L3 Cache Memory, 즉 CPU 와 Main Memory 사이의 Cache를<br>
DRAM Cache 는 VM System 의 Cache Memory, 즉 Main Memory 에서 Virtual Page 를 Caching 한다고 정해둔다.<br>DRAM 의 메모리 계층구조상의 위치는 중요하다.<br>
DRAM 은 SRAM 에 비해 10배 정도 느리지만,<br>
Disk 는 100,000 배 정도 느리기 때문에 DRAM 에서의 Cache Miss 는 매우 비싸다.<br>
심지어, Disk 의 Read 속도는 경우에 따라 100,000배 정도 더 느려질 수 있다.<br>
즉, DRAM 은 비용이 매우 큰 Cache Miss를 대비한 Cache 임을 알 수 있다.<br>이러한 배경 하에,<br>
Virtual Page 의 크기는 매우 크다. 보통 4KB ~ 2MB 정도이다.<br>
또한, DRAM 은 Fully Associative 하다.(Set 이 1개이다.)<br>
Replacement Policy 또한, Miss에 대한 Penalty 가 높기 때문에 훨씬 정교하다.<br>
SRAM 보다 정교하게 OS 에 의해 관리되는데, 그 알고리즘은 여기서 이야기하진 않는다.<br>
Disk 에 대한 접근 시간이 길기 때문에 DRAM Cache 는 Write-back 방법을 사용한다.<br><br>다른 Cache 처럼, VM 도 Virtual Page 가 DRAM 어딘가에 Caching 되어있는지 알아야한다.<br>
만약 Caching 되어있다면, 어느 Physical Page 인지 알아야하며,<br>
Caching 이 되어있지 않다면, Disk의 어느 Virtual Page 인지 알아야하며,<br>
Victim Page 를 결정해서, 복사해 Victim Page 를 없애야한다.<br>이러한 기능은  소프트웨어와<br>
주소변환 하드웨어인  와<br>
 로 알려진, VP와 PP 를 맵핑해주는 Physical Memory 에 존재하는 자료구조로 관리된다.<br>MMU 는 Page Table 을 읽어, Virtual Address 를 Physical Address 로 변환해준다.<br>
OS 는 Page Table의 내용을 관리하며, Page 를 Disk 와 DRAM 사이로 전달해주는 역할을 한다.<br><img alt="articles/chapter9/imgs/page_table.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/page_table.png"><br>
위 그림은 Page Table 의 기본적인 구조를 보여준다.<br>
Page Table 은  의 배열로 이루어져있다.<br>
Virtual Address Space 에 있는 각 Page 는 Page Table의 특정 Offset 위치에 PTE가 존재한다.<br>
여기서는 PTE 는 Valid Bit 와 n-bit Address Field 로 구성되어있다고 가정한다.<br>
Valid bit 은 현재 해당 Page 가 DRAM 에 Caching 되어있는지 알려준다.<br>
Valid bit 가 설정되어있을 때, Address Field 는 해당 VP 가 Caching 된 DRAM 상의 Physical Page 의 시작점으로 설정되어 있다.<br>Vailid Bit 가 설정되어있지 있을 때는,<br>
Address Field 가 Null 이라면 아직 Allocated 되지 않은 것이고,<br>
Null 이 아니라면, 주소는 Disk 의 Virtual Page 를 가르킨다.<br><br><img alt="articles/chapter9/imgs/page_hit.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/page_hit.png"><br>
CPU가 VP2 에 존재하는 word 를 읽고자 한다고 해보자.<br>
Address Transfer Hardware 는 Virtual Address 를 PTE 2로 향하는 Index로 바꾸고, 읽는다.<br>
Vaild Bit 이 설정되어 있기 때문에, VP2 가 Memory 에 Caching 되어있음을 알 수 있고,<br>
PTE 에 있는 Physical Memory Address 를 사용하여 접근한다.<br><br><img alt="articles/chapter9/imgs/page_fault.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/page_fault.png"><br>
VM 에서의 Cache Miss 는 Page Fault 라고 불린다.<br>
위의 그림은 VP3, Caching 되지 않은 Page 에 대한 접근 시도 전후를 나타낸 그림이다.<br>
Address Translate Hardware 는 PTE3 를 읽으려고 하는데,<br>
Valid Bit 가 설정되어 있지 않으므로 Page Fault Exception 을 일으킨다.<br>
이것은 Kernel 의 Page Fault Exception Handler 를 유도하게 된다.<br>
Handler 는 Victim Page 를 고르게 되는데, 위의 예제에서는 PP3 에 존재하는 VP4에 해당한다.<br>
VP4 에 변경사항이 있다면, Kernel 은 복사본을 Disk 에 전달한다.<br>
없다면, Kernel 은 VP4 에 대한 PTE 를 변경하여, VP4 가 더이상 Caching 되고 있지 않다는 사실을 반영한다.<br>그 다음 Kernel 은 Disk 에 있는 VP3 를 메모리의 PP3 로 복사하고, PTE3 를 업데이트하고 반환한다.<br>
Handler 가 반환되고 나서는 실패한 명령어를 다시 실행한다. 즉, 실패했던 Virtual Address 를 Address Translation Hardware 로 재전송한다.<br>
이제는 VP3 가 Caching 되어있기 때문에 Page Hit 가 정상적으로 발생한다.<br>VM 은 1960년대 초기, 즉 CPU-Memory 간의 성능차이가 크지 않아서 SRAM Cache 가 없었을 때 생겼다. 이로 인해 VM과 Cache 간의 아이디어가 비슷함에도 다른 용어를 사용하게 되었다.<br>
Cache 의 Block 은 VM의 Page 와 유사하다.<br>
Page 를 Disk 와 Memory 사이로 전달하는 것은 Swapping 과 Paging 이라는 용어를 사용한다.<br>
Page 는 Disk 에서 DRAM 으로  되고,<br>
DRAM에서 Disk 로  된다.<br>Miss 가 발생할 때까지 기다리다가 Swap In 을 하는 전략을  이라고한다.<br>
미리 Miss 를 예측해서 Swap 을 하는 것도 가능하지만,<br>
현대의 시스템은 Demand Paging 을 사용한다.<br><br><img alt="articles/chapter9/imgs/allocate_page.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/allocate_page.png"><br>
위의 그림은 OS 가 새로운 Page 를 할당할 때의 모습이다. (예를 들어 malloc)<br>
해당 예제에서는 VP5가 Disk에 할당되어, PTE5가 해당 Disk 를 가르키게 된다.<br><br>Miss Penalties 를 고려하면, 프로그램의 성능에 우려가 있을 수 있다.<br>
그러나 프로그램의 Locality 덕분에 VM 은 잘 작동한다.<br>프로그램 전체에서 사용하는 Page 는 physical Memory 가 실제 가능한 Page 를 넘을 수도 있지만, Locality 는 smaller set of Active Page, 즉 Working Set or Resident Set 으로 작업하게 해준다.<br>
초기에 Working Set 을 Read 하는 OverHead 를 제외하면, 그 후 참조는 Disk 참조를 덜 할 수 있다.<br> 프로그램이 Temporal Locality 를 잘 지키는 한, VM 은 잘 작동한다.<br>
만약 어떤 프로그램이 Temporal Locality 를 잘 지키지 못한다면,<br>
Working Set 이 가능한 Physical Memory 를 초과할 수 있다.<br>
이 때,  이라는 상황이 발생하는데, 이는 Page 가 Swapped In 되고 다시 Out 되는 것이 반복되는 상황이다.<br>
VM은 보통 효율적이지만, 프로그램이 느리다면 Thrashing 은 아닌지 고려해봐야한다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.3-vm_as_a_tool_for_caching.html</link><guid isPermaLink="false">articles/chapter9/9.3-VM_as_a_Tool_for_Caching.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:54 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/vm_ex.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/vm_ex.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[9.4-VM_as_a_Tool_for_Memory_Management]]></title><description><![CDATA[ 
 <br><a data-href="articles/chapter9/9.3-VM_as_a_Tool_for_Caching" href="https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.3-vm_as_a_tool_for_caching.html" class="internal-link" target="_self" rel="noopener nofollow">articles/chapter9/9.3-VM_as_a_Tool_for_Caching</a>에서는 VM이 상대적으로 큰 Virtual Address space 에서 Page 를 DRAM 에 Caching 하는 과정을 살펴보았다.<br>지금까지는 단일의 Page Table 을 가정하고 진행했지만,<br>
OS는 분리된 Page Table 을, 즉 분리된 Virtual Address Space 를 각각의 Process 마다 제공한다.<br>
<img alt="articles/chapter9/imgs/separate_address_space.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/separate_address_space.png"><br>
위 그림은 그 예시를 나타내고 있다.<br>
여러개의 Virtual Page 가 하나의 Physical Page 에 맵핑되기도 한다. (PP7)<br>Demand Paging 과 분리된 Virtual Address Space 는 메모리의 사용과 관리 측면에서 많은 영향을 끼쳤다. 특히 VM은 Linking 과 Loading, Code 와 Data 의 공유, 서비스에 메모리 할당 측면에서 유용하다.<br>
<br>
<br>
분리된 Address Space 는 각 Process 마다 통일된 규격을 사용하게 해준다.<br>
실제 Code 나 Data 가 Physical Memory 어디에 있든 간에.<br>
예를 들어, Code Segment 는 항상 0x400000 에서 시작하고,<br>
Data Segment 는 Code Segment 뒤에 따라온다.<br>
이런 식으로 통일된 시각으로 Process 를 보는 것이 가능하다.
결과적으로 Linker 의 디자인과 구현을 단순화하고,<br>
Physical Memory 와 무관하게 Fully Linked Executable 을 만들 수 있게 해준다.

<br>
<br>
VM은 또한 Executable 과 Shared Object file 을 쉽게 Load 할 수 있게 해준다.<br>
새로 생성된 Process 에 Object File 의 .text 와 .data 부분을 load 하기 위해,<br>
Linux Loader 는 Code 와 Data Segment 를 위한 Virtual Page 를 할당한다.<br>
이 때, 이 Page 는 Invalid(Not Cached) 인 상태이다.<br>
그리고 그 Page의 PTE 를 적절한 Object 파일 내의 위치로 설정한다.
Loader 는 실제 데이터를 Disk 에서 Memory 로 복사하지 않는다.<br>
실제 참조가 일어나는 순간 혹은 CPU가 해당 위치를 참조하는 명령어를 가져올 때 일어난다.
연속된 Virtual Page 들을 File 에서 임의의 위치에 맵핑하는 것을  이라고 한다. Linux 는 mmap 이라는 System Call 을 통해 서비스가 직접 매핑할 수 있도록 해준다.

<br>
<br>
분리된 Address Space 는<br>
사용자의 Process 와 OS 간의 공유를 관리하는 작업에 대해<br>
OS가 일관된 작동방식을 가지게 해준다.<br>
일반적으로 Process 는 자신만 사용하는 사적인 공간에 Code, Data, Heap 등을 사용한다.<br>
즉, OS 는 Page Table 에 각각의 Virtual Page 를 겹치지 않는 Physical Page 에 연결해 작성한다.
그러나, 간혹 코드나 데이터를 공유해야하는 경우가 있다.<br>
예를 들어, 모든 Process 는 Kernel 코드를 이용해야하고, C 프로그램은 standard C Library 를 사용하곤 한다.<br>
이 경우에, OS 는 하나의 단일된 Physical Page 에 여러개의 Virtual Page 를 연결한다.<img alt="articles/chapter9/imgs/sharing.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/sharing.png">

<br>
<br>
VM 은 User Process 의 추가적인 메모리 할당 요청에 대해 간단한 메카니즘을 가지고 있다.<br>
실행중인 프로그램이 추가적인 Heap Space 를 요청할 때(malloc 등),<br>
OS 는 적당한 숫자  에 대해, 연속된 VM Page  개를 할당해준다.<br>
그리고 Page 는  개의 임의의 Physical Page 에 연결된다.<br>
Page Table 의 작동방식 덕분에, Physical Page 는 연속되지 않고, 파편적으로 다룰 수 있다.

]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.4-vm_as_a_tool_for_memory_management.html</link><guid isPermaLink="false">articles/chapter9/9.4-VM_as_a_Tool_for_Memory_Management.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:54 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/separate_address_space.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/separate_address_space.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[9.5-VM_as_a_Tool_for_Memory_Protection]]></title><description><![CDATA[ 
 <br>현대의 컴퓨터 시스템은 OS 가 Memory 에 접근할 수 있는 수단을 제공해야만 한다.<br>User Process 가 Read-Only 인 코드 부분을 변경하면 안된다.<br>
Kernel 내부의 코드나 데이터는 Read 조차 안되야한다.<br>
다른 Process 의 코드나 데이터에 관여하면 안되며,<br>
다른 Process 가 모두 허락하기 전에는 모두에게 공유된 Page 를 변경하면 안된다.<br>분리된 Address Space 는 서로 다른 Process 간의 메모리를 분리하는데 용이했다.<br>
여기서 Address Translation Mechanism 은 자연스럽게 접근을 더 세밀하게 조정할 수 있다.<br>
왜냐하면 Address Translation Hardware 가 PTE 를 읽어서 CPU 가 주소를 생성하기 때문에,<br>
PTE 에 Permission Bit 를 추가하는것이 자연스럽다.<br><img alt="articles/chapter9/imgs/memory_protection.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/memory_protection.png"><br>
위의 예시에서 3가지의 Permission Bit 를 추가했다.<br>
SUP bit 는 Kernel Mode 에만 읽을 수 있다는 점을 표현한다.<br>
즉, User Mode 에서는 읽을 수 없다.<br>READ, WRITE Bit 는 해당 Page 에 대한 read, write 접근을 의미한다.<br>만약 명령어가 이러한 접근 권한을 지키지 않는다면,<br>
CPU 는 General Protection Fault 를 유발시킨다.<br>
해당 Fault 는 통제권을 Kernel 의 Exception Handler 로 넘기고, Handler 는<br>
해당 명령어가 실행된 Process 에 SIGSEGV 신호를 전달한다.<br>
Linux 는 이 Exception 에 대해 보통 "Segment Fault" 를 출력한다.]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.5-vm_as_a_tool_for_memory_protection.html</link><guid isPermaLink="false">articles/chapter9/9.5-VM_as_a_Tool_for_Memory_Protection.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:54 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/memory_protection.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/memory_protection.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[9.6-Address_Translation]]></title><description><![CDATA[ 
 <br>이 챕터에서는 주소변환의 기본을 다룬다.<br>
여기서 VM을 도와주는 하드웨어의 역할을 예제를 직접 다룰 수 있을 정도로 다룬다.<br>
하지만, 여기서는 일부 세부적인 부분, 특히 시간적인 부분은 무시되어있다.<br><img alt="articles/chapter9/imgs/address_translation_symbols.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/address_translation_symbols.png"><br>
주요한 키워드를 요약해두었다.<br>Address Translation 은<br>
 와<br>
 의 Mapping 으로 이해할 수 있다.<br><br>이 때 실제 값은<br><br>이다.<br><img alt="articles/chapter9/imgs/address_trans.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/address_trans.png"><br>
MMU(Memory Management Unit) 가 어떻게 Page Table 을 이용해서 이 맵핑을 수행하는지 보여준다.<br>CPU 안의 Control Register 인  가 현재의 Page Table 을 가르키고 있다.<br>
 bit 의 Virtual Address 는 2가지 부분으로 나뉜다.<br>
 bit 의  와  bit 의  으로 이루어져있다.<br>VPN 은 올마른 PTE 를 고를 때 사용된다.<br>
예를 들어 VPN 0 은 PTE 0 을 가르키게 된다.<br>대응하는 Physical Addrss 는 2개의 부분을 합쳐서 구할 수 있다.<br>
Page Table Entry 의  과 Virtual Address 의  로 이루어진다.<br>이 때, Physical, Virtual 모두  byte 를 사용하기 때문에,<br>
Physical Page Offset(PPO) 가 동일하다.<br><br><img alt="articles/chapter9/imgs/page_hit_detail.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/page_hit_detail.png"><br>
Page Hit 일 때는 Hardware 가 처리해준다.<br>
<br>Processor 는 Virtual Address 를 생성해 MMU 로 보내준다.
<br>MMU 는 PTE 주소를 만들고, Cache/Main Memory 에 요청한다.
<br>Cache/Main Memory 는 PTE 를 MMU로 반환한다.
<br>MMU 는 Physical Address 를 만들고, Cache/Main Memory 에 보낸다.
<br>Cache/Main Memory 는 요청받은 data word 를 CPU로 보낸다.
<br><br><img alt="articles/chapter9/imgs/page_miss_ex.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/page_miss_ex.png"><br>
Page Hit 은 하드웨어 만으로 관리되지만,<br>
Miss 의 경우, OS의 Kernel 과 하드웨어의 협력에 의해 다뤄진다.<br>1~3 번까지는 동일하다. PTE 를 가져온다.<br>
4. Valid bit 가 0 인 경우로, MMU 는 exception 을 유발시킨다. 이는 통제를 CPU에서 OS 내부의 Kernel 에 존재하는 Page Fault Exception Handler 에 넘긴다.<br>
<br>
Fault Handler 는 Physical Memory 에 있는 Victim Page 을 인지하고,<br>
만약 내용이 변했다면, Disk 에 반영한다.

<br>
Fault Handler 는 Disk 의 내용을 다시 가져오고,<br>
Memory 의 PTE 업데이트한다.

<br>
Fault Handler 는 원래 Process 에게 통제를 넘겨준다. 이후에 실패했던 명령어를 다시 실행한다.<br>
CPU 는 Virtual Address 를 MMU 에게 다시 보낸다.<br>
Handler 에 의해 Caching 되었으므로,<br>
Page Hit의  4번부터 진행하게 된다.

<br><br><img alt="articles/chapter9/imgs/VM_and_Cache.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/vm_and_cache.png"><br>Virtual Memory 와 SRAM Cache 를 같이 쓰는 시스템에서,<br>
Virtual 또는 Physical Address 가 SRAM Cache 에 접근할 수 있는지에 대한 논의가 있다.<br>자세한 trade-off 는 우리의 범위를 넘어서지만,<br>
대부분의 시스템은 Physical Address 가 SRAM 에 접근한다.<br>이는 여러 Process 가 동시에 각자의 Block을 Caching 하고, 같은 Virtual Page 을 통해 Block 을 공유하는 상황을<br>
직관적으로 만들어주기 때문이다.<br>그리고, Cache 는 Protection 관련 이슈는 다룰 수 없다.<br>
접근 권한은 Address Translation Process 의 일부이기 때문이다.<br>그림은 Physical Address 와 Cache 가 어떻게 통합되어 있는지 보여준다.<br>
핵심 아이디어는 Address Translation 이 Cache Lookup보다 먼저 일어난다는 것이다.<br><br>CPU 가 Virtual Address 를 생성할 때마다, MMU 가 Virtual Address 를 Physical Address로 바꾸기 의해서는 PTE 를 가져와야 한다.<br>
최악의 경우, Memory 에서 추가적인 Fetch 가 필요할 수 있다. 이는 천단위의 Cycle 이 필요하다.<br>
PTE 가 L1 Cache 에 Caching 되어있으면 비용을 절감할 수 있다.<br>
현대의 시스템은 MMU 안에  를<br>
PTE 를 위한 Cache 로 그 비용을 더 줄이고자 한다.<br>TLB 는<br>
작고, 각 Line 은 하나의 PTE에 해당하는 Block 을 가진 Cache 이다.<br>
<img alt="articles/chapter9/imgs/TLB_index.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/tlb_index.png"><br>
위와 같이 Virtual Page Number 에서 바로 Tag 와 Index 를 구한다.<br>
Block 에는 하나의 PTE 가 있기 때문에 Offset 은 필요하지 않다.<br><br><img alt="articles/chapter9/imgs/TLB_Hit.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/tlb_hit.png"><br>
<br>CPU 가 Virtual Address 를 만든다.
<br>MMU 가 PTE 를 TLB 에 요청한다.
<br>TLB 가 PTE 를 반환한다.
<br>MMU 는 해당 PTE 를 이용해, Physical Address 로 바꿔, Cache/Main Memory 로 전달한다.
<br>Cache/Main Memory 를 해당하는 데이터를 CPU에게 전달한다.
<br>이 과정들은 MMU 내부에서, on-chip 으로 진행되기 때문에 빠르다.<br><br><img alt="articles/chapter9/imgs/TLB_Miss.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/tlb_miss.png"><br>이 때는, MMU가 L1 Cache 에서 PTE 를 가져와야한다.<br>
새로운 PTE 는 TLB 에 저장되는데, 기존의 PTE 가 사라질 수 있다.<br><br>하나의 Page Table 을 가지고 논의했지만, 다음과 같은 상황을 고려해보자.<br>
32bit 주소체계에서, 4KB Page, 4byte PTE 라면, 우리는 늘 4MB의 Page Table 이 Memory 에 존재해야한다.<br>
 개의 주소는 4KB 의 Page  개가 필요하다.<br>
이에 대해 Page Table Entry 가 4Byte 이므로, 총  Byte 가 필요하다.<br>이를 위해서 Page Table 에 대한 계층구조를 활용한다.<br>
이를 이해하기 위해서, 구체적인 예시로 살펴본다.<br>32bit 의 주소체계에서, 주소공간은 4KB 의 Page 로 이루어져있다.<br>
PTE 는 각각 4Byte 로 구성된다.<br>
처음 2K 개의 Page 는 Code 와 Data, 다음 6K는 할당되어있지 않고,<br>
다음 1023개의 Page 역시 할당되어있지 않으며, 마지막 Page 에 User Stack 이 할당되어있다고 가정한다.<br><img alt="articles/chapter9/imgs/two_level_page.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/two_level_page.png"><br>
2단계의 계층으로 위와 같이 구성한다.<br>
level-1 의 Page Table 은 4MB 의 Virtual Address Space 를 담당한다.<br>
4MB 는 1024개의 Page 를 갖게 된다. (1개의 Page 는 4KB의 주소를 담당한다.)<br>
총 주소공간이 4GB 이기 때문에 level-1 은 1024개면 충분하다.<br>만약 담당한 Chunk 가 모두 비어있다면, 해당 level-1 의 PTE는 Null 이다.<br>
만약 Chunk 내부에 1개라도 Page 가 할당되면, level-1 PTE 는 level-2 의 PTE 를 가르킨다.<br>level-2 의 PTE 는 Virtual Memory의 4KB 의 Page 를 맵핑해줘야하는 책임이 있다.<br>
level-1, level-2 의 Page Table 이 4KB 인 점은 Page 와 같은 사이즈로 편리함을 위해서이다.<br>이러한 방식은 Memory 측면에서 2가지로 유리하다.<br>
level-1 의 PTE 가 Null 이라면, 그에 대응하는 level-2 의 Page Table 은 존재하지 않아도 된다. 이것은 대부분의 Virtual Address Space 가 실제로 필요하지 않다는 점에서 유용하다.<br>level-1 의 Table 만이 Main Memory 에 항상 있으면 된다.<br>
level-2 의 Table 은 필요에 의해 VM System 이 동적으로 할당 및 제거할 수 있다.<br>
많이 사용되는 level-2 의 경우는 Main Memory 에 Caching 된다.<br><img alt="articles/chapter9/imgs/k_level_address_trans.png" src="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/k_level_address_trans.png"><br>
위의 그림은 지금까지의 Address Translation 을 요약해준다.<br>Virtual Address 는 k개의 VPN(Virtual Page Number) 과 VPO(Virtual Page Offset) 으로 나뉜다.<br>
각 k 이하의 PTE에서는 다음 단계의 Page Table 의 시작점을 가르킨다.<br>
k-level Table 은 PPN 을 가져, MMU 는 이 PPN 과 PPO(VPO 와 같은) 을 조합해 Physical Address 를 구성한다.<br>k개의 PTE 에 접근하는게 비효율적으로 보일 수 있지만,<br>
TLB 를 통한 Caching 이 이를 효율적으로 만들어준다.<br>
실제로 Multi-level Table 는 Single-level Table 과 거의 유사한 속도를 낸다.<br>]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.6-address_translation.html</link><guid isPermaLink="false">articles/chapter9/9.6-Address_Translation.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:54 GMT</pubDate><enclosure url="https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/address_translation_symbols.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cmj7271.github.io/cs-app-organize/articles/chapter9/imgs/address_translation_symbols.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[ch1-A_Tour_of_Computer_Systems]]></title><description><![CDATA[ 
 <br>컴퓨터 시스템은 하드웨어 + 소프트웨어의 조합으로 프로그램을 구동한다.<br>
특정 구현은 바뀔 수 있지만, 그 밑의 개념은 바뀌지 않는다.<br>
이 책은 프로그래머가 더 나은 프로그램 작성을 위해 필요한 지식을 정리한다.<br><a data-tooltip-position="top" aria-label="articles/chapter1/1.1-Info=Bits+Context" data-href="articles/chapter1/1.1-Info=Bits+Context" href="https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.1-info=bits+context.html" class="internal-link" target="_self" rel="noopener nofollow">1.1-Info=Bits+Context</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter1/1.2-Translate_Program" data-href="articles/chapter1/1.2-Translate_Program" href="https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.2-translate_program.html" class="internal-link" target="_self" rel="noopener nofollow">1.2-Translate_Program</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter1/1.3-Importance_of_Understanding_Compiler" data-href="articles/chapter1/1.3-Importance_of_Understanding_Compiler" href="https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.3-importance_of_understanding_compiler.html" class="internal-link" target="_self" rel="noopener nofollow">1.3-Importance_of_Understanding_Compiler</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter1/1.4-Proccessor_reads_Instruction_in_Memory" data-href="articles/chapter1/1.4-Proccessor_reads_Instruction_in_Memory" href="https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.4-proccessor_reads_instruction_in_memory.html" class="internal-link" target="_self" rel="noopener nofollow">1.4-Proccessor_reads_Instruction_in_Memory</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter1/1.5-Cache_is_important" data-href="articles/chapter1/1.5-Cache_is_important" href="https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.5-cache_is_important.html" class="internal-link" target="_self" rel="noopener nofollow">1.5-Cache_is_important</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter1/1.6-Hierarchy_of_Memory" data-href="articles/chapter1/1.6-Hierarchy_of_Memory" href="https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.6-hierarchy_of_memory.html" class="internal-link" target="_self" rel="noopener nofollow">1.6-Hierarchy_of_Memory</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter1/1.7-OS_manage_Hardware" data-href="articles/chapter1/1.7-OS_manage_Hardware" href="https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.7-os_manage_hardware.html" class="internal-link" target="_self" rel="noopener nofollow">1.7-OS_manage_Hardware</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter1/1.8-System_communicate_System_with_Network" data-href="articles/chapter1/1.8-System_communicate_System_with_Network" href="https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.8-system_communicate_system_with_network.html" class="internal-link" target="_self" rel="noopener nofollow">1.8-System_communicate_System_with_Network</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter1/1.9-Other_important_Themes" data-href="articles/chapter1/1.9-Other_important_Themes" href="https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.9-other_important_themes.html" class="internal-link" target="_self" rel="noopener nofollow">1.9-Other_important_Themes</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter1/1.10-Summary" data-href="articles/chapter1/1.10-Summary" href="https://cmj7271.github.io/cs-app-organize/articles/chapter1/1.10-summary.html" class="internal-link" target="_self" rel="noopener nofollow">1.10-Summary</a>]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/ch1-a_tour_of_computer_systems.html</link><guid isPermaLink="false">articles/ch1-A_Tour_of_Computer_Systems.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:47:17 GMT</pubDate></item><item><title><![CDATA[ch2-Representing_and_Manipulating_Info]]></title><description><![CDATA[ 
 <br>컴퓨터는 정보를 2가지 값을 가지는 신호, 즉  로 표현한다.<br>
10진법은 오래동안 사용되었고, 우리에게 매우 익숙하지만, 정보를 표현하고 가공하는 기계에서는 2진법이 유용하다.<br>
예를 들어, 펀치카드릐의 구멍 유무, 전압의 고저, 자석의 시계, 반시계 반향 등등 다양하게 표현가능하다.<br>단일 bit만으로는 유용한 정보를 표현하기 어렵다.<br>
여러개의 bit가 모이고,  되면, 의미있게 사용될 수 있다.<br>
예를 들어 여러개의 bit 로 정수로 해석하여, 특정한 정수를 얻을 수 있다.<br>
그 외 다양한 해석 방법을 공부할 것이다.<br>
다룰 해석방법 중 중요한 아래 3가지 해석 방법을 공부한다.<br>
<br> 인코딩(자연수 표현)
<br> 인코딩(정수 표현)
<br> 인코딩(실수 표현)
<br>컴퓨터의 저장공간은 한정되어 있기 때문에, 숫자의 저장에는 한계가 있다.<br>
이로 인해 overflow 가 발생해 원치 않는 에러가 발생하곤 한다.<br>예시로, 200 * 300 * 400 * 500 은 -884,901,888 이 나오는등 수학과는 다른 점이 있다.<br>
또 다른것으로는<br>
이다. (교환 법칙이 성립하지 않았다!)<br>컴퓨터가 표현하는 방법을 공부함으로서, 표현가능한 범위와 수학과는 다른 연산 특징을 알 수 있다. 이 특성을 이해하는 것은 올바른 프로그램에 중요하다.<br>
이 교묘한 특성은 간혹 보안상의 문제의 원인이 되곤한다.<br>이 방법을 익히는 것은 또한 컴파일러가 연산을 최적화하는 방법을 이해하는데 필요하다.<br><a data-tooltip-position="top" aria-label="articles/chapter2/2.1-Infomation_Storage" data-href="articles/chapter2/2.1-Infomation_Storage" href="https://cmj7271.github.io/cs-app-organize/articles/chapter2/2.1-infomation_storage.html" class="internal-link" target="_self" rel="noopener nofollow">2.1-Infomation_Storage</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter2/2.2-Integer_Representations" data-href="articles/chapter2/2.2-Integer_Representations" href="https://cmj7271.github.io/cs-app-organize/articles/chapter2/2.2-integer_representations.html" class="internal-link" target="_self" rel="noopener nofollow">2.2-Integer_Representations</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter2/2.3-Integer_Arithmetic" data-href="articles/chapter2/2.3-Integer_Arithmetic" href="https://cmj7271.github.io/cs-app-organize/articles/chapter2/2.3-integer_arithmetic.html" class="internal-link" target="_self" rel="noopener nofollow">2.3-Integer_Arithmetic</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter2/2.4-Floating_Points" data-href="articles/chapter2/2.4-Floating_Points" href="https://cmj7271.github.io/cs-app-organize/articles/chapter2/2.4-floating_points.html" class="internal-link" target="_self" rel="noopener nofollow">2.4-Floating_Points</a>]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/ch2-representing_and_manipulating_info.html</link><guid isPermaLink="false">articles/ch2-Representing_and_Manipulating_Info.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:47:37 GMT</pubDate></item><item><title><![CDATA[ch6-The_Memory_Hierarchy]]></title><description><![CDATA[ 
 <br>보통 메모리는 어떤 선형의 배열로서, 각 메모리에 상수시간에 접근할 수 있는 어떤 시스템으로,<br>
간단하게 그려진다.<br>
이는 꽤 효과적인 모델이지만, 현대 시스템에서 작동하는 방식은 아니다.<br>실제로는, 계층구조를 이루며 상위 계층, CPU와 가까울수록 빠르지만, 그 용량이 작다.<br>
하위 계층일수록 속도는 느리지만, 그 용량은 커진다.<br>개발자로서 메모리 계층구조는 잘 이해해야한다.<br>
왜냐하면, 제일 가까운 CPU Register 는 0 Cycle에 접근가능하지만,<br>
작게는 4~75 Cycle, 많게는 몇천만의 Cycle 이 필요할 수 있기 때문이다.<br>컴퓨터 시스템에서 중요한 아이디어는 다음과 같다.<br>
시스템이 어떻게 데이터를 계층구조 상 위아래로 움직이는지 이해한다면,<br>
작성하는 프로그램의 데이터가 더 위로 가도록, 즉 더 빠르게 접근할 수 있도록 만들 수 있다.<br>컴퓨터 시스템은  라는 근본적인 특성을 가지고 있다.<br>
높은  을 가지는 프로그램은 같은 위치 혹은 비슷한 위치에 있는 데이터에 계속 접근한다. 또한 더 상위 계층의 메모리에서 접근하는 경향이 있기 때문에,<br>
낮은  의 프로그램보다 훨씬 빠르게 작동하게 된다.<br>이 챕터에서 우리는 기본적인 저장 기술을 살펴본다.<br>
SRAM, DRAM, ROM, Rotating and Soild State Disks 등을 다루며,<br>
이들이 어떻게 계층구조를 가지나 살펴본다.<br>특히 CPU와 Main Memory 사이에서 stage area 의 역할을 하는<br>
 에 집중한다.<br>
 는 프로그램 성능에 가장 큰 영향을 끼치는 요인 중 하나이기 때문이다.<br>C 언어 프로그램의  를 분석하고, 높이는 방법을 살펴본다.<br>
특정 machine 에서 메모리 계층구조의 성능을 흥미롭게 다루는 "Memory Moutain" 에 대해 알아본다.<br><a data-tooltip-position="top" aria-label="articles/chapter6/6.1-Storage_Technologies" data-href="articles/chapter6/6.1-Storage_Technologies" href="https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.1-storage_technologies.html" class="internal-link" target="_self" rel="noopener nofollow">6.1-Storage_Technologies</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter6/6.2-Locality" data-href="articles/chapter6/6.2-Locality" href="https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.2-locality.html" class="internal-link" target="_self" rel="noopener nofollow">6.2-Locality</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter6/6.3-The_Memory_Hierarchy" data-href="articles/chapter6/6.3-The_Memory_Hierarchy" href="https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.3-the_memory_hierarchy.html" class="internal-link" target="_self" rel="noopener nofollow">6.3-The_Memory_Hierarchy</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter6/6.4-Cache_Memories" data-href="articles/chapter6/6.4-Cache_Memories" href="https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.4-cache_memories.html" class="internal-link" target="_self" rel="noopener nofollow">6.4-Cache_Memories</a><br>
<a data-href="articles/chapter6/6.5-Writing_Cache_Friendly_Code" href="https://cmj7271.github.io/cs-app-organize/articles/chapter6/6.5-writing_cache_friendly_code.html" class="internal-link" target="_self" rel="noopener nofollow">articles/chapter6/6.5-Writing_Cache_Friendly_Code</a>]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/ch6-the_memory_hierarchy.html</link><guid isPermaLink="false">articles/ch6-The_Memory_Hierarchy.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:40:53 GMT</pubDate></item><item><title><![CDATA[ch7-Linking]]></title><description><![CDATA[ 
 <br> 이란, 여러 코드 조각들을 모아서 하나의 단일 파일로 만드는 것이다.<br>
 은<br>
<br>, 소스코드가 machine code 로 변환될 때, 
<br>, 메모리로 이동되고,  에 의해 실행될 때,
<br>, 프로그램이 실행될 때<br>
이루어진다.
<br>과거에는 수동으로 이루어졌지만, 현대에서는  에 의해 자동으로 이루어진다.<br>
 는  을 가능하게 해준다.<br>
이는 하나의 크고 긴 소스코드를 한번에 컴파일 하는 것이 아닌,<br>
더 작고 다루기 쉬운 모듈() 로 다룰 수 있게 해준다.<br>어떤 부분에서의 수정은 해당 모듈에 대한 수정, 즉 재컴파일만 이루어지면 된다.<br> 는  에 의해 자동적으로 수행되어지지만, 아래의 이유로 배워야한다.<br>
<br>
<br>
 의 작동원리를 아는 것은 라이브러리, 모듈의 연결 과정에서의 에러를 해결하는데 도움을 줄 수 있다.

<br>
<br>
linking 과정에서 프로그램의 정당성(correctness) 에 영향을 줄 수 있다.<br>
잘못 정의된 여러 전역변수는 linker 가 어떠한 에러도 보여주지 않는다.<br>
이것이 어떻게 발생하는지, 어떻게 해결하는지 살펴본다.

<br>
<br>
전역변수와 지역변수의 차이, static 으로 정의한 것의 의미가 무엇인지 등을 살펴본다.

<br>
<br>
linker 에 의해 만들어진 목적파일(object file)은 시스템 함수에서 중요한 역할을 한다.<br>
프로그램 로딩, 실행, 가상 메모리 등등이 있다.

<br>
<br>
과거에는 직관적인 일이었지만,<br>
shared libraries, dynamic linking 의 중요성이 부각되면서, 그 과정은 좀 더 정교해졌다.<br>
이에 따라 linking 은 유용한 도구가 되었다.<br>
예를 들어,  을 업데이트하는데에는, shared libraries 가 사용된다.<br>
 란, 중간 바이너리 파일로서, 시스템 종속성이 제거되어있어,<br>
여러 시스템에서 같은 파일로 사용할 수 있다는 장점이 있다. 각 시스템에서 linking 을 통해 시스템용 실행 파일로 변환된다.<br>
 dynamic linking 을 이용한다.

<br>이 챕터에서는 모든 linking 의 양상을 살펴본다.<br>
여기서는 특정 환경에 종속적으로 확인하지만, 주요한 컨셉은 다른 시스템에서도 동일하다.<br><a data-tooltip-position="top" aria-label="articles/chapter7/7.1-Compiler_Drivers" data-href="articles/chapter7/7.1-Compiler_Drivers" href="https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.1-compiler_drivers.html" class="internal-link" target="_self" rel="noopener nofollow">7.1-Compiler_Drivers</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter7/7.2-Static_Linking" data-href="articles/chapter7/7.2-Static_Linking" href="https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.2-static_linking.html" class="internal-link" target="_self" rel="noopener nofollow">7.2-Static_Linking</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter7/7.3-Object_Files" data-href="articles/chapter7/7.3-Object_Files" href="https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.3-object_files.html" class="internal-link" target="_self" rel="noopener nofollow">7.3-Object_Files</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter7/7.4-Relocatable_Object_Files" data-href="articles/chapter7/7.4-Relocatable_Object_Files" href="https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.4-relocatable_object_files.html" class="internal-link" target="_self" rel="noopener nofollow">7.4-Relocatable_Object_Files</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter7/7.5-Symbols_and-Symbol_Tables" data-href="articles/chapter7/7.5-Symbols_and-Symbol_Tables" href="https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.5-symbols_and-symbol_tables.html" class="internal-link" target="_self" rel="noopener nofollow">7.5-Symbols_and-Symbol_Tables</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter7/7.6-Symbol_Resolution" data-href="articles/chapter7/7.6-Symbol_Resolution" href="https://cmj7271.github.io/cs-app-organize/articles/chapter7/7.6-symbol_resolution.html" class="internal-link" target="_self" rel="noopener nofollow">7.6-Symbol_Resolution</a><br>아래는 해당 챕터에서 계속 살펴볼 2개의 소스코드이다.<br>	int sum(int *a, int n);
	int array[2] = {1, 2};

	int main() {
		int val = sum(array, 2);
		return val;
	}
<br>	int sum(int *a, int n) {
		int i, s = 0;
		for(i = 0; i &lt; n; i++) {
			s += a[i];
		}
		return s;
	}
]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/ch7-linking.html</link><guid isPermaLink="false">articles/ch7-Linking.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:48:24 GMT</pubDate></item><item><title><![CDATA[ch9-Virtual_Memory]]></title><description><![CDATA[ 
 <br>Process 는 다른 Process 와 CPU와 Main Memory 를 공유한다.<br>
이는 몇가지 문제점을 만들 수 있다.<br>CPU의 일이 많아지면서, process 의 속도는 줄어들게 된다.<br>
같은 자원을 공유하기 때문이다.<br>
하지만 Process 여러개가 너무 많은 Memory 를 사용한다면, 일부는 더이상 실행하기 어려워질 것이다.<br>만약 Process 가 다른 Process 의 메모리를 사용한다면,<br>
그 다른 Process 는 Process 의 문제가 아닌, 외부의 문제로 실패할 수 있다.<br>메모리를 더 효율적으로, 더 적은 에러로 다루기 위해, 현대의 시스템은<br>
 에 대한 추상화로  를 제공한다.<br>VM 은 하드웨어 예외, 하드웨어 주소 변환, Main Memory, Disk, 커널 과의 상호작용을 담당한다. 이를 각 Process 에게 크고, 통일된 형태의 사적인 Address Space 를 제공함으로서 수행한다.<br>한 가지의 깔끔한 메커니즘으로 3가지 중요한 기능을 제공한다.<br>
<br>Main Memory 를 Disk 에 존재하는 주소공간에 대한 Cache 로 다뤄<br>
효율적으로 사용한다.<br>
이는 사용하는 Main Memory 와 Disk 간의 데이터 이동을 필요한 만큼만 함으로서 수행한다.
<br>메모리 관리를 각 Process 에게 통일된 주소 공간을 제공함으로서 간단하게 만든다.
<br>각 Process 의 주소 공간을 다른 Process 에 의한 침범으로부터 보호한다.
<br>VM은 가장 휼륭한 아이디어 중 하나이다.<br>
VM 은 자동으로, 뒤에서 서비스 개발자의 관여없이 조용히 이루어지기 때문에 편리하다.<br>
그렇다면 서비스 개발자가 VM을 알아야하는 이유가 무엇일까?<br>
<br>
<br>
컴퓨터 시스템의 모든 곳에서 관여하기 때문에, 다른 시스템을 이해하는데 중요하다.

<br>
<br>
VM 은 서비스가 강력한 기능을 수행할 수 있게 해준다.<br>
예를 들어, Memory 덩어리를 만들고, 없앨 수 있으며,<br>
그 덩어리를 Disk 에 맵핑하며, 다른 Process 와 메모리를 공유하기도 한다.
Memory 의 주소를 읽거나 쓰는것으로 Disk 의 내용을 읽거나 바꿀 수도 있다.

<br>
<br>
프로그램은 변수를 참조, 포인터를 해체, 동적할당 등을 할 때마다 VM과 작용하게 된다.<br>
이때, 프로그램이 적절하게 VM을 사용하지 못하면, 메모리 관련 버그에 걸리기 쉽다.<br>
segment, protection error 는 직접 실행되기 전까지는 알기 어렵다.

<br>이번 챕터에서는 VM을 2가지 시각으로 살펴본다.<br>
<br>VM은 어떻게 작동하는가?
<br>프로그램은 VM 을 어떻게 사용되고 관리하는가?
<br>2번째 시각인 프로그램이 어떻게 사용하는지에 대해서는 1번째를 기반으로 설명한다.<br><a data-tooltip-position="top" aria-label="articles/chapter9/9.1-Physical_and_Virtual_Addressing" data-href="articles/chapter9/9.1-Physical_and_Virtual_Addressing" href="https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.1-physical_and_virtual_addressing.html" class="internal-link" target="_self" rel="noopener nofollow">9.1-Physical_and_Virtual_Addressing</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter9/9.2-Address_Spaces" data-href="articles/chapter9/9.2-Address_Spaces" href="https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.2-address_spaces.html" class="internal-link" target="_self" rel="noopener nofollow">9.2-Address_Spaces</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter9/9.3-VM_as_a_Tool_for_Caching" data-href="articles/chapter9/9.3-VM_as_a_Tool_for_Caching" href="https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.3-vm_as_a_tool_for_caching.html" class="internal-link" target="_self" rel="noopener nofollow">9.3-VM_as_a_Tool_for_Caching</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter9/9.4-VM_as_a_Tool_for_Memory_Management" data-href="articles/chapter9/9.4-VM_as_a_Tool_for_Memory_Management" href="https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.4-vm_as_a_tool_for_memory_management.html" class="internal-link" target="_self" rel="noopener nofollow">9.4-VM_as_a_Tool_for_Memory_Management</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter9/9.5-VM_as_a_Tool_for_Memory_Protection" data-href="articles/chapter9/9.5-VM_as_a_Tool_for_Memory_Protection" href="https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.5-vm_as_a_tool_for_memory_protection.html" class="internal-link" target="_self" rel="noopener nofollow">9.5-VM_as_a_Tool_for_Memory_Protection</a><br>
<a data-tooltip-position="top" aria-label="articles/chapter9/9.6-Address_Translation" data-href="articles/chapter9/9.6-Address_Translation" href="https://cmj7271.github.io/cs-app-organize/articles/chapter9/9.6-address_translation.html" class="internal-link" target="_self" rel="noopener nofollow">9.6-Address_Translation</a>]]></description><link>https://cmj7271.github.io/cs-app-organize/articles/ch9-virtual_memory.html</link><guid isPermaLink="false">articles/ch9-Virtual_Memory.md</guid><dc:creator><![CDATA[cmj7271]]></dc:creator><pubDate>Sat, 07 Jun 2025 04:48:52 GMT</pubDate></item></channel></rss>